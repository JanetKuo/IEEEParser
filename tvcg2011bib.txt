@ARTICLE{5487515,
author={Hutson, M. and Reiners, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={JanusVF: Accurate Navigation Using SCAAT and Virtual Fiducials},
year={2011},
month={Jan},
volume={17},
number={1},
pages={3-13},
abstract={Several critical limitations exist in the currently available tracking technologies for fully enclosed virtual reality (VR) systems. While several 6DOF tracking projects such as Hedgehog have successfully demonstrated excellent accuracy, precision, and robustness within moderate budgets, these projects still include elements of hardware that can interfere with the user's visual experience. The objective of this project is to design a tracking solution for fully enclosed VR displays that achieves comparable performance to available commercial solutions but without any artifacts that can obscure the user's view. JanusVF is a tracking solution involving a cooperation of both the hardware sensors and the software rendering system. A small, high-resolution camera is worn on the user's head, but faces backward (180 degree rotation about vertical from the user's perspective). After acquisition of the initial state, the VR rendering software draws specific fiducial markers with known size and absolute position inside the VR scene. These virtual markers are only drawn behind the user and in view of the camera. These fiducials are tracked by ARToolkitPlus and integrated by a single-constraint-at-a-time (SCAAT) filter algorithm to update the head pose. Experiments analyzing accuracy, precision, and latency in a six-sided CAVE-like system show performance that is comparable to alternative commercial technologies.},
keywords={rendering (computer graphics);virtual reality;Hedgehog tracking project;JanusVF solution;SCAAT filter algorithm;fully enclosed VR displays;single-constraint-at-a-time filter algorithm;software rendering system;virtual fiducials;virtual reality system;Cameras;Displays;Filters;Hardware;Layout;Navigation;Robustness;Sensor systems;Software systems;Virtual reality;Virtual reality;input devices and strategies;stereo;tracking.;Algorithms;Computer Graphics;Data Display;Equipment Design;Humans;Imaging, Three-Dimensional;Software;User-Computer Interface},
doi={10.1109/TVCG.2010.91},
ISSN={1077-2626},}
@ARTICLE{5374395,
author={Babu, S.V. and Grechkin, T.Y. and Chihak, B. and Ziemer, C. and Kearney, J.K. and Cremer, J.F. and Plumert, J.M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={An Immersive Virtual Peer for Studying Social Influences on Child Cyclists' Road-Crossing Behavior},
year={2011},
month={Jan},
volume={17},
number={1},
pages={14-25},
abstract={The goal of our work is to develop a programmatically controlled peer to bicycle with a human subject for the purpose of studying how social interactions influence road-crossing behavior. The peer is controlled through a combination of reactive controllers that determine the gross motion of the virtual bicycle, action-based controllers that animate the virtual bicyclist and generate verbal behaviors, and a keyboard interface that allows an experimenter to initiate the virtual bicyclist's actions during the course of an experiment. The virtual bicyclist's repertoire of behaviors includes road following, riding alongside the human rider, stopping at intersections, and crossing intersections through specified gaps in traffic. The virtual cyclist engages the human subject through gaze, gesture, and verbal interactions. We describe the structure of the behavior code and report the results of a study examining how 10- and 12-year-old children interact with a peer cyclist that makes either risky or safe choices in selecting gaps in traffic. Results of our study revealed that children who rode with a risky peer were more likely to cross intermediate-sized gaps than children who rode with a safe peer. In addition, children were significantly less likely to stop at the last six intersections after the experience of riding with the risky than the safe peer during the first six intersections. The results of the study and children's reactions to the virtual peer indicate that our virtual peer framework is a promising platform for future behavioral studies of peer influences on children's bicycle riding behavior.},
keywords={behavioural sciences computing;virtual reality;action-based controllers;behavior code structure;child cyclists road-crossing behavior;immersive virtual peer framework;keyboard interface;reactive controllers;social influences;social interactions;virtual bicycle;virtual bicyclist actions;Animation;Bicycles;Decision making;Humans;Injuries;Keyboards;Motion control;Road accidents;Traffic control;Virtual reality;3D human-computer interaction.;Virtual humans;applied perception;virtual reality;Accidents, Traffic;Age Factors;Bicycling;Child;Child Behavior;Child, Preschool;Emotional Intelligence;Humans;Judgment;Social Environment;User-Computer Interface;Visual Perception},
doi={10.1109/TVCG.2009.211},
ISSN={1077-2626},}
@ARTICLE{5406519,
author={Sewall, J. and van den Berg, J. and Lin, M.C. and Manocha, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Virtualized Traffic: Reconstructing Traffic Flows from Discrete Spatiotemporal Data},
year={2011},
month={Jan},
volume={17},
number={1},
pages={26-37},
abstract={We present a novel concept, Virtualized Traffic, to reconstruct and visualize continuous traffic flows from discrete spatiotemporal data provided by traffic sensors or generated artificially to enhance a sense of immersion in a dynamic virtual world. Given the positions of each car at two recorded locations on a highway and the corresponding time instances, our approach can reconstruct the traffic flows (i.e., the dynamic motions of multiple cars over time) between the two locations along the highway for immersive visualization of virtual cities or other environments. Our algorithm is applicable to high-density traffic on highways with an arbitrary number of lanes and takes into account the geometric, kinematic, and dynamic constraints on the cars. Our method reconstructs the car motion that automatically minimizes the number of lane changes, respects safety distance to other cars, and computes the acceleration necessary to obtain a smooth traffic flow subject to the given constraints. Furthermore, our framework can process a continuous stream of input data in real time, enabling the users to view virtualized traffic events in a virtual world as they occur. We demonstrate our reconstruction technique with both synthetic and real-world input.},
keywords={data visualisation;traffic engineering computing;virtual reality;car motion reconstruction;continuous traffic flows visualization;discrete spatiotemporal data;dynamic virtual world;high density traffic;immersive visualization;traffic flows reconstruction;traffic sensors;virtual cities;virtualized traffic;Automated highways;Cities and towns;Data visualization;Kinematics;Layout;Road transportation;Spatiotemporal phenomena;Traffic control;Vehicle safety;Virtual reality;Animation;kinematics and dynamics.;virtual reality;Acceleration;Accidents, Traffic;Algorithms;Automobile Driving;Automobiles;Computer Simulation;Environment Design;Humans;Probability;Risk Assessment;Safety;Time;Transportation;User-Computer Interface},
doi={10.1109/TVCG.2010.27},
ISSN={1077-2626},}
@ARTICLE{5342415,
author={Yu Sheng and Yapo, T.C. and Young, C. and Cutler, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Spatially Augmented Reality Sketching Interface for Architectural Daylighting Design},
year={2011},
month={Jan},
volume={17},
number={1},
pages={38-50},
abstract={We present an application of interactive global illumination and spatially augmented reality to architectural daylight modeling that allows designers to explore alternative designs and new technologies for improving the sustainability of their buildings. Images of a model in the real world, captured by a camera above the scene, are processed to construct a virtual 3D model. To achieve interactive rendering rates, we use a hybrid rendering technique, leveraging radiosity to simulate the interreflectance between diffuse patches and shadow volumes to generate per-pixel direct illumination. The rendered images are then projected on the real model by four calibrated projectors to help users study the daylighting illumination. The virtual heliodon is a physical design environment in which multiple designers, a designer and a client, or a teacher and students can gather to experience animated visualizations of the natural illumination within a proposed design by controlling the time of day, season, and climate. Furthermore, participants may interactively redesign the geometry and materials of the space by manipulating physical design elements and see the updated lighting simulation.},
keywords={architectural CAD;augmented reality;computer animation;data visualisation;daylighting;rendering (computer graphics);animated visualizations;architectural daylight modeling;augmented reality sketching interface;hybrid rendering technique;interactive global illumination;per-pixel direct illumination;virtual 3D model;virtual heliodon;Animation;Augmented reality;Buildings;Cameras;Computer graphics;Daylighting;Hybrid power systems;Layout;Lighting;Rendering (computer graphics);Spatially augmented reality;and daylighting design.;global illumination;radiosity;Algorithms;Computer Graphics;Computer-Aided Design;Environment Design;Humans;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Lighting;User-Computer Interface},
doi={10.1109/TVCG.2009.209},
ISSN={1077-2626},}
@ARTICLE{5332227,
author={Tze-Yiu Ho and Liang Wan and Chi-Sing Leung and Ping-Man Lam and Tien-Tsin Wong},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Unicube for Dynamic Environment Mapping},
year={2011},
month={Jan},
volume={17},
number={1},
pages={51-63},
abstract={Cube mapping is widely used in many graphics applications due to the availability of hardware support. However, it does not sample the spherical surface evenly. Recently, a uniform spherical mapping, isocube mapping, was proposed. It exploits the six-face structure used in cube mapping and samples the spherical surface evenly. Unfortunately, some texels in isocube mapping are not rectilinear. This nonrectilinear property may degrade the filtering quality. This paper proposes a novel spherical mapping, namely unicube mapping. It has the advantages of cube mapping (exploitation of hardware and rectilinear structure) and isocube mapping (evenly sampling pattern). In the implementation, unicube mapping uses a simple function to modify the lookup vector before the conventional cube map lookup process. Hence, unicube mapping fully exploits the cube map hardware for real-time filtering and lookup. More importantly, its rectilinear partition structure allows a direct and real-time acquisition of the texture environment. This property facilitates dynamic environment mapping in a real time manner.},
keywords={computer graphics;real-time systems;Unicube;cube mapping;dynamic environment mapping;filtering quality;graphics applications;hardware support;isocube mapping;lookup vector;nonrectilinear property;real-time filtering;rectilinear structure;sampling pattern;six face structure;spherical surface;Degradation;Filtering;Graphics;Hardware;Mirrors;Reflection;Sampling methods;Shadow mapping;Shape;Strips;Unicube mapping;dynamic environment mapping;equal-area strip;filtering quality.;Algorithms;Computer Graphics;Computer-Aided Design;Environment Design;Equipment Design;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Numerical Analysis, Computer-Assisted;User-Computer Interface},
doi={10.1109/TVCG.2009.205},
ISSN={1077-2626},}
@ARTICLE{5453360,
author={Xin Sun and Qiming Hou and Zhong Ren and Kun Zhou and Baining Guo},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Radiance Transfer Biclustering for Real-Time All-Frequency Biscale Rendering},
year={2011},
month={Jan},
volume={17},
number={1},
pages={64-73},
abstract={We present a real-time algorithm to render all-frequency radiance transfer at both macroscale and mesoscale. At a mesoscale, the shading is computed on a per-pixel basis by integrating the product of the local incident radiance and a bidirectional texture function. While at a macroscale, the precomputed transfer matrix, which transfers the global incident radiance to the local incident radiance at each vertex, is losslessly compressed by a novel biclustering technique. The biclustering is directly applied on the radiance transfer represented in a pixel basis, on which the BTF is naturally defined. It exploits the coherence in the transfer matrix and a property of matrix element values to reduce both storage and runtime computation cost. Our new algorithm renders at real-time frame rates realistic materials and shadows under all-frequency direct environment lighting. Comparisons show that our algorithm is able to generate images that compare favorably with reference ray tracing results, and has obvious advantages over alternative methods in storage and preprocessing time.},
keywords={image texture;matrix algebra;pattern clustering;ray tracing;rendering (computer graphics);bidirectional texture function;direct environment lighting;lossless compression;radiance transfer biclustering;ray tracing;real-time algorithm;real-time all-frequency biscale rendering;realistic materials;shading;shadows;transfer matrix;Computational efficiency;Graphics;Hardware;Image generation;Image storage;Ray tracing;Rendering (computer graphics);Runtime;Sun;Transfer functions;Illumination;graphics hardware.;rendering;shadow algorithm;Algorithms;Computer Graphics;Computer-Aided Design;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Lighting},
doi={10.1109/TVCG.2010.58},
ISSN={1077-2626},}
@ARTICLE{5406517,
author={Kagaya, M. and Brendel, W. and Qingqing Deng and Kesterson, T. and Todorovic, S. and Neill, P.J. and Zhang, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Video Painting with Space-Time-Varying Style Parameters},
year={2011},
month={Jan},
volume={17},
number={1},
pages={74-87},
abstract={Artists use different means of stylization to control the focus on different objects in the scene. This allows them to portray complex meaning and achieve certain artistic effects. Most prior work on painterly rendering of videos, however, uses only a single painting style, with fixed global parameters, irrespective of objects and their layout in the images. This often leads to inadequate artistic control. Moreover, brush stroke orientation is typically assumed to follow an everywhere continuous directional field. In this paper, we propose a video painting system that accounts for the spatial support of objects in the images or videos, and uses this information to specify style parameters and stroke orientation for painterly rendering. Since objects occupy distinct image locations and move relatively smoothly from one video frame to another, our object-based painterly rendering approach is characterized by style parameters that coherently vary in space and time. Space-time-varying style parameters enable more artistic freedom, such as emphasis/de-emphasis, increase or decrease of contrast, exaggeration or abstraction of different objects in the scene in a temporally coherent fashion.},
keywords={art;rendering (computer graphics);video signal processing;artistic freedom;brush stroke orientation;object-based painterly rendering approach;space-time-varying style parameters;video painterly rendering;video painting system;Brushes;Computer Society;Constraint optimization;Focusing;Layout;Painting;Rendering (computer graphics);Stress control;Tensile stress;Nonphotorealistic rendering;multistyle painting;tensor field design.;video painting;Algorithms;Computer Graphics;Computer-Aided Design;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Paintings;Pattern Recognition, Automated;Space Perception;User-Computer Interface;Video Recording},
doi={10.1109/TVCG.2010.25},
ISSN={1077-2626},}
@ARTICLE{5406520,
author={Stapleton, G. and Rodgers, P. and Howse, John and Leishi Zhang},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Inductively Generating Euler Diagrams},
year={2011},
month={Jan},
volume={17},
number={1},
pages={88-100},
abstract={Euler diagrams have a wide variety of uses, from information visualization to logical reasoning. In all of their application areas, the ability to automatically layout Euler diagrams brings considerable benefits. In this paper, we present a novel approach to Euler diagram generation. We develop certain graphs associated with Euler diagrams in order to allow curves to be added by finding cycles in these graphs. This permits us to build Euler diagrams inductively, adding one curve at a time. Our technique is adaptable, allowing the easy specification, and enforcement, of sets of well-formedness conditions; we present a series of results that identify properties of cycles that correspond to the well-formedness conditions. This improves upon other contributions toward the automated generation of Euler diagrams which implicitly assume some fixed set of well-formedness conditions must hold. In addition, unlike most of these other generation methods, our technique allows any abstract description to be drawn as an Euler diagram. To establish the utility of the approach, a prototype implementation has been developed.},
keywords={diagrams;formal logic;graph theory;set theory;graphs;inductively Euler diagram generation;information visualization;logical reasoning;well-formedness condition;Prototypes;Visualization;Euler diagrams;Information visualization;Venn diagrams.;diagram generation;diagram layout;Algorithms;Computational Biology;Computer Graphics;Data Interpretation, Statistical;Humans;Software},
doi={10.1109/TVCG.2010.28},
ISSN={1077-2626},}
@ARTICLE{5406516,
author={Stott, J. and Rodgers, P. and Martínez-Ovando, J.C. and Walker, S.G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Automatic Metro Map Layout Using Multicriteria Optimization},
year={2011},
month={Jan},
volume={17},
number={1},
pages={101-114},
abstract={This paper describes an automatic mechanism for drawing metro maps. We apply multicriteria optimization to find effective placement of stations with a good line layout and to label the map unambiguously. A number of metrics are defined, which are used in a weighted sum to find a fitness value for a layout of the map. A hill climbing optimizer is used to reduce the fitness value, and find improved map layouts. To avoid local minima, we apply clustering techniques to the map-the hill climber moves both stations and clusters when finding improved layouts. We show the method applied to a number of metro maps, and describe an empirical study that provides some quantitative evidence that automatically-drawn metro maps can help users to find routes more efficiently than either published maps or undistorted maps. Moreover, we have found that, in these cases, study subjects indicate a preference for automatically-drawn maps over the alternatives.},
keywords={geographic information systems;optimisation;pattern clustering;automatic mechanism;automatic metro map layout;clustering techniques;hill climbing optimizer;metro map drawings;multicriteria optimization;published maps;undistorted maps;Application software;Cancer;Computer networks;Geometry;Humans;Navigation;Network topology;Optimization methods;System testing;Visualization;Information visualization;diagram layout;graph drawing.;Algorithms;Computer Graphics;Computer Simulation;Computer-Aided Design;Humans;Information Storage and Retrieval;Maps as Topic;Pattern Recognition, Automated;Software;User-Computer Interface},
doi={10.1109/TVCG.2010.24},
ISSN={1077-2626},}
@ARTICLE{5453358,
author={Jiantao Pu and Paik, D.S. and Xin Meng and Roos, J. and Rubin, G.D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Shape #x0201C;Break-and-Repair #x0201D; Strategy and Its Application to Automated Medical Image Segmentation},
year={2011},
month={Jan},
volume={17},
number={1},
pages={115-124},
abstract={In three-dimensional medical imaging, segmentation of specific anatomy structure is often a preprocessing step for computer-aided detection/diagnosis (CAD) purposes, and its performance has a significant impact on diagnosis of diseases as well as objective quantitative assessment of therapeutic efficacy. However, the existence of various diseases, image noise or artifacts, and individual anatomical variety generally impose a challenge for accurate segmentation of specific structures. To address these problems, a shape analysis strategy termed “break-and-repair” is presented in this study to facilitate automated medical image segmentation. Similar to surface approximation using a limited number of control points, the basic idea is to remove problematic regions and then estimate a smooth and complete surface shape by representing the remaining regions with high fidelity as an implicit function. The innovation of this shape analysis strategy is the capability of solving challenging medical image segmentation problems in a unified framework, regardless of the variability of anatomical structures in question. In our implementation, principal curvature analysis is used to identify and remove the problematic regions and radial basis function (RBF) based implicit surface fitting is used to achieve a closed (or complete) surface boundary. The feasibility and performance of this strategy are demonstrated by applying it to automated segmentation of two completely different anatomical structures depicted on CT examinations, namely human lungs and pulmonary nodules. Our quantitative experiments on a large number of clinical CT examinations collected from different sources demonstrate the accuracy, robustness, and generality of the shape “break-and-repair” strategy in medical image segmentation.},
keywords={computational geometry;computerised tomography;image segmentation;medical image processing;patient treatment;radial basis function networks;CT examinations;automated medical image segmentation;computer aided detection purposes;principal curvature analysis;radial basis function;shape break-and-repair strategy;therapeutic efficacy;three-dimensional medical imaging;Anatomical structure;Automatic control;Biomedical imaging;Computed tomography;Diseases;Image analysis;Image segmentation;Noise shaping;Shape control;Technological innovation;Shape analysis;computer-aided detection/diagnosis.;medical image segmentation;surface interpolation;Algorithms;Computer Simulation;Diagnosis, Computer-Assisted;Diagnostic Imaging;Humans;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Lung;Lung Neoplasms;Models, Biological;Pattern Recognition, Automated;Principal Component Analysis;Sensitivity and Specificity;Solitary Pulmonary Nodule;Subtraction Technique},
doi={10.1109/TVCG.2010.56},
ISSN={1077-2626},}
@ARTICLE{5453357,
author={Chiosa, I. and Kolb, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-Based Multilevel Clustering},
year={2011},
month={Feb},
volume={17},
number={2},
pages={132-145},
abstract={The processing power of parallel coprocessors like the Graphics Processing Unit (GPU) is dramatically increasing. However, until now only a few approaches have been presented to utilize this kind of hardware for mesh clustering purposes. In this paper, we introduce a Multilevel clustering technique designed as a parallel algorithm and solely implemented on the GPU. Our formulation uses the spatial coherence present in the cluster optimization and hierarchical cluster merging to significantly reduce the number of comparisons in both parts. Our approach provides a fast, high-quality, and complete clustering analysis. Furthermore, based on the original concept, we present a generalization of the method to data clustering. All advantages of the mesh-based techniques smoothly carry over to the generalized clustering approach. Additionally, this approach solves the problem of the missing topological information inherent to general data clustering and leads to a Local Neighbors k-means algorithm. We evaluate both techniques by applying them to Centroidal Voronoi Diagram (CVD)-based clustering. Compared to classical approaches, our techniques generate results with at least the same clustering quality. Our technique proves to scale very well, currently being limited only by the available amount of graphics memory.},
keywords={computational geometry;computer graphic equipment;coprocessors;optimisation;parallel algorithms;pattern clustering;statistical analysis;Centroidal Voronoi Diagram;GPU-based multilevel clustering;cluster optimization;clustering analysis;generalization;graphics memory;graphics processing unit;hierarchical cluster;local neighbors k-means algorithm;mesh clustering;parallel algorithm;parallel coprocessors;spatial coherence;Computer graphics;clustering methods;hierarchical methods;parallel processing;programmable graphics hardware.},
doi={10.1109/TVCG.2010.55},
ISSN={1077-2626},}
@ARTICLE{5492686,
author={Szirmay-Kalos, L. and Liktor, G. and Umenhoffer, T. and Tóth, B. and Kumar, S. and Lupton, G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Parallel Iteration to the Radiative Transport in Inhomogeneous Media with Bootstrapping},
year={2011},
month={Feb},
volume={17},
number={2},
pages={146-158},
abstract={This paper presents a fast parallel method to solve the radiative transport equation in inhomogeneous participating media. We apply a novel approximation scheme to find a good initial guess for both the direct and scattered components. Then, the initial approximation is used to bootstrap an iterative multiple scattering solver, i.e., we let the iteration concentrate just on the residual problem. This kind of bootstrapping makes the volumetric source approximation more uniform, thus it helps to reduce the discretization artifacts and improves the efficiency of the parallel implementation. The iterative refinement is executed on a face-centered cubic grid. The implementation is based on CUDA and runs on the GPU. For large volumes that do not fit into the GPU memory, we also consider the implementation on a GPU cluster, where the volume is decomposed to blocks according to the available GPU nodes. We show how the communication bottleneck can be avoided in the cluster implementation by not exchanging the boundary conditions in every iteration step. In addition to light photons, we also discuss the generalization of the method to γ-photons that are relevant in medical simulation.},
keywords={Monte Carlo methods;computer graphic equipment;computer graphics;coprocessors;inhomogeneous media;iterative methods;parallel processing;radiative transfer;scattering;statistical analysis;CUDA;GPU cluster;GPU memory;artifact discretization;bootstrapping;face centered cubic grid;inhomogeneous media;iterative multiple scattering solver;light photons;medical simulation;parallel iteration;radiative transport;residual problem;scattered component;volumetric source approximation;CUDA.;FCC grid;GPU;Monte Carlo method;Radiative transport equation;diffusion approximation;iteration;multiple scattering;parallel computation},
doi={10.1109/TVCG.2010.97},
ISSN={1077-2626},}
@ARTICLE{5492685,
author={Schmitz, A. and Rick, T. and Karolski, T. and Kuhlen, T. and Kobbelt, L.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Efficient Rasterization for Outdoor Radio Wave Propagation},
year={2011},
month={Feb},
volume={17},
number={2},
pages={159-170},
abstract={Conventional beam tracing can be used for solving global illumination problems. It is an efficient algorithm and performs very well when implemented on the GPU. This allows us to apply the algorithm in a novel way to the problem of radio wave propagation. The simulation of radio waves is conceptually analogous to the problem of light transport. We use a custom, parallel rasterization pipeline for creation and evaluation of the beams. We implement a subset of a standard 3D rasterization pipeline entirely on the GPU, supporting 2D and 3D frame buffers for output. Our algorithm can provide a detailed description of complex radio channel characteristics like propagation losses and the spread of arriving signals over time (delay spread). Those are essential for the planning of communication systems required by mobile network operators. For validation, we compare our simulation results with measurements from a real-world network. Furthermore, we account for characteristics of different propagation environments and estimate the influence of unknown components like traffic or vegetation by adapting model parameters to measurements.},
keywords={mobile radio;radiowave propagation;ray tracing;telecommunication network planning;2D frame buffers;3D frame buffers;3D rasterization pipeline;GPU;beam evaluation;beam tracing;communication system planning;global illumination problems;light transport;mobile network operators;outdoor radiowave propagation;parallel rasterization pipeline;propagation losses;radio channel characteristics;radiowave simulation;Ray tracing;electromagnetic propagation.;rendering},
doi={10.1109/TVCG.2010.96},
ISSN={1077-2626},}
@ARTICLE{5416703,
author={Yu-Shuen Wang and Chaoli Wang and Tong-Yee Lee and Kwan-Liu Ma},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Feature-Preserving Volume Data Reduction and Focus+Context Visualization},
year={2011},
month={Feb},
volume={17},
number={2},
pages={171-181},
abstract={The growing sizes of volumetric data sets pose a great challenge for interactive visualization. In this paper, we present a feature-preserving data reduction and focus+context visualization method based on transfer function driven, continuous voxel repositioning and resampling techniques. Rendering reduced data can enhance interactivity. Focus+context visualization can show details of selected features in context on display devices with limited resolution. Our method utilizes the input transfer function to assign importance values to regularly partitioned regions of the volume data. According to user interaction, it can then magnify regions corresponding to the features of interest while compressing the rest by deforming the 3D mesh. The level of data reduction achieved is significant enough to improve overall efficiency. By using continuous deformation, our method avoids the need to smooth the transition between low and high-resolution regions as often required by multiresolution methods. Furthermore, it is particularly attractive for focus+context visualization of multiple features. We demonstrate the effectiveness and efficiency of our method with several volume data sets from medical applications and scientific simulations.},
keywords={data reduction;data visualisation;display devices;transfer functions;very large databases;3D mesh;continuous deformation;continuous voxel repositioning;data rendering;display devices;feature-preserving volume data reduction;focus+context visualization;interactive visualization;multiresolution methods;resampling techniques;transfer function;user interaction;volumetric data sets;Biomedical equipment;Chaos;Costs;Data visualization;Displays;Energy resolution;Medical services;Medical simulation;Runtime;Transfer functions;Data reduction;focus+context visualization;interactive visualization;mesh deformation;transfer functions;volume rendering.},
doi={10.1109/TVCG.2010.34},
ISSN={1077-2626},}
@ARTICLE{5453366,
author={Nagaraj, Suthambhara and Natarajan, V.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Relation-Aware Isosurface Extraction in Multifield Data},
year={2011},
month={Feb},
volume={17},
number={2},
pages={182-191},
abstract={We introduce a variation density function that profiles the relationship between multiple scalar fields over isosurfaces of a given scalar field. This profile serves as a valuable tool for multifield data exploration because it provides the user with cues to identify interesting isovalues of scalar fields. Existing isosurface-based techniques for scalar data exploration like Reeb graphs, contour spectra, isosurface statistics, etc., study a scalar field in isolation. We argue that the identification of interesting isovalues in a multifield data set should necessarily be based on the interaction between the different fields. We demonstrate the effectiveness of our approach by applying it to explore data from a wide variety of applications.},
keywords={computational geometry;data handling;multifield data;multifield data exploration;relation aware isosurface extraction;scalar field;variation density function;Isosurface statistics;isocontours;multifield data.;persistence;variation density profile},
doi={10.1109/TVCG.2010.64},
ISSN={1077-2626},}
@ARTICLE{5416704,
author={Correa, C. and Kwan-Liu Ma},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visibility Histograms and Visibility-Driven Transfer Functions},
year={2011},
month={Feb},
volume={17},
number={2},
pages={192-204},
abstract={Direct volume rendering is an important tool for visualizing complex data sets. However, in the process of generating 2D images from 3D data, information is lost in the form of attenuation and occlusion. The lack of a feedback mechanism to quantify the loss of information in the rendering process makes the design of good transfer functions a difficult and time consuming task. In this paper, we present the general notion of visibility histograms, which are multidimensional graphical representations of the distribution of visibility in a volume-rendered image. In this paper, we explore the 1D and 2D transfer functions that result from intensity values and gradient magnitude. With the help of these histograms, users can manage a complex set of transfer function parameters that maximize the visibility of the intervals of interest and provide high quality images of volume data. We present a semiautomated method for generating transfer functions, which progressively explores the transfer function space toward the goal of maximizing visibility of important structures. Our methodology can be easily deployed in most visualization systems and can be used together with traditional 1D and 2D opacity transfer functions based on scalar values, as well as with other more sophisticated rendering algorithms.},
keywords={rendering (computer graphics);complex data set visualisation;direct volume rendering;feedback mechanism;multidimensional graphical representations;visibility driven transfer functions;visibility histograms;volume rendered image;Attenuation;Data visualization;Feedback;Histograms;Image generation;Multidimensional systems;Process design;Quality management;Rendering (computer graphics);Transfer functions;Transfer functions;histograms.;view-point dependent rendering;visibility;volume rendering},
doi={10.1109/TVCG.2010.35},
ISSN={1077-2626},}
@ARTICLE{5432167,
author={Adrienko, N. and Adrienko, G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Spatial Generalization and Aggregation of Massive Movement Data},
year={2011},
month={Feb},
volume={17},
number={2},
pages={205-219},
abstract={Movement data (trajectories of moving agents) are hard to visualize: numerous intersections and overlapping between trajectories make the display heavily cluttered and illegible. It is necessary to use appropriate data abstraction methods. We suggest a method for spatial generalization and aggregation of movement data, which transforms trajectories into aggregate flows between areas. It is assumed that no predefined areas are given. We have devised a special method for partitioning the underlying territory into appropriate areas. The method is based on extracting significant points from the trajectories. The resulting abstraction conveys essential characteristics of the movement. The degree of abstraction can be controlled through the parameters of the method. We introduce local and global numeric measures of the quality of the generalization, and suggest an approach to improve the quality in selected parts of the territory where this is deemed necessary. The suggested method can be used in interactive visual exploration of movement data and for creating legible flow maps for presentation purposes.},
keywords={aggregation;data structures;data visualisation;data abstraction method;generalization quality;interactive visual exploration;legible flow map;massive movement data aggregation;numeric measure;spatial generalization;trajectory transformation;Aggregates;Animals;Data mining;Data visualization;Displays;Space technology;Tracking;Trajectory;Vehicles;Visual analytics;Movement;aggregation;generalization;geovisualization;information visualization;visual analytics.;Computer Simulation;Humans;Maps as Topic;Movement},
doi={10.1109/TVCG.2010.44},
ISSN={1077-2626},}
@ARTICLE{5416707,
author={Vasa, L. and Skala, V.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Perception Correlated Comparison Method for Dynamic Meshes},
year={2011},
month={Feb},
volume={17},
number={2},
pages={220-230},
abstract={There are multiple areas of computer graphics where triangular meshes are being altered in order to reduce their size or complexity, while attempting to preserve the original shape of the mesh as closely as possible. Recently, this area of research has been extended to cover even a dynamic case, i.e., surface animations which are compressed and simplified. However, to date very little effort has been made to develop methods for evaluating the results, namely the amount of distortion introduced by the processing. Even the most sophisticated compression methods use distortion evaluation by some kind of mean squared error while the actual relevance of such measure has not been verified so far. In this paper, we point out some serious drawbacks of the existing error measures. We present results of the subjective testing that we have performed, and we derive a new measure called Spatiotemporal edge difference (STED) which is shown to provide much better correlation with subjective opinions on mesh distortion.},
keywords={computer animation;mean square error methods;mesh generation;computer graphics;distortion evaluation;dynamic mesh;mean squared error;perception correlated comparison method;spatiotemporal edge difference;subjective testing;surface animation;triangular mesh;Animation;discrepancy;distortion;dynamic mesh.;error;evaluation;measure},
doi={10.1109/TVCG.2010.38},
ISSN={1077-2626},}
@ARTICLE{5416705,
author={Yuanyuan Li and Fan Bao and Zhang, E. and Kobayashi, Y. and Wonka, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Geometry Synthesis on Surfaces Using Field-Guided Shape Grammars},
year={2011},
month={Feb},
volume={17},
number={2},
pages={231-243},
abstract={We show how to model geometric patterns on surfaces. We build on the concept of shape grammars to allow the grammars to be guided by a vector or tensor field. Our approach affords greater artistic freedom in design and enables the use of grammars to create patterns on manifold surfaces. We show several application examples in visualization, anisotropic tiling of mosaics, and geometry synthesis on surfaces. In contrast to previous work, we can create patterns that adapt to the underlying surface rather than distorting the geometry with a texture parameterization. Additionally, we are the first to model patterns with a global structure thanks to the ability to derive field-guided shape grammars on surfaces.},
keywords={computational geometry;data visualisation;anisotropic mosaics tiling;field guided shape grammars;manifold surfaces;surfaces geometry synthesis;texture parameterization;visualization;Shape grammars;geometry synthesis.;surfaces;tensor fields;vector fields},
doi={10.1109/TVCG.2010.36},
ISSN={1077-2626},}
@ARTICLE{5416702,
author={Patil, S. and van den Berg, J. and Curtis, S. and Lin, M.C. and Manocha, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Directing Crowd Simulations Using Navigation Fields},
year={2011},
month={Feb},
volume={17},
number={2},
pages={244-254},
abstract={We present a novel approach to direct and control virtual crowds using navigation fields. Our method guides one or more agents toward desired goals based on guidance fields. The system allows the user to specify these fields by either sketching paths directly in the scene via an intuitive authoring interface or by importing motion flow fields extracted from crowd video footage. We propose a novel formulation to blend input guidance fields to create singularity-free, goal-directed navigation fields. Our method can be easily combined with the most current local collision avoidance methods and we use two such methods as examples to highlight the potential of our approach. We illustrate its performance on several simulation scenarios.},
keywords={collision avoidance;feature extraction;navigation;virtual reality;collision avoidance method;crowd video footage;goal directed navigation field;guidance field;motion flow field extraction;path sketching;Animation;Artificial intelligence;Collision avoidance;Computational modeling;Computer science;Computer simulation;Decision making;Layout;Navigation;Virtual reality;Multiagent systems;animation;virtual reality.;Algorithms;Computer Graphics;Computer Simulation;Crowding;Humans;Imaging, Three-Dimensional;Movement},
doi={10.1109/TVCG.2010.33},
ISSN={1077-2626},}
@ARTICLE{5406518,
author={Antley, A. and Slater, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={The Effect on Lower Spine Muscle Activation of Walking on a Narrow Beam in Virtual Reality},
year={2011},
month={Feb},
volume={17},
number={2},
pages={255-259},
abstract={To what extent do people behave in immersive virtual environments as they would in similar situations in a physical environment? There are many ways to address this question, ranging from questionnaires, behavioral studies, and the use of physiological measures. Here, we compare the onsets of muscle activity using surface electromyography (EMG) while participants were walking under three different conditions: on a normal floor surface, on a narrow ribbon along the floor, and on a narrow platform raised off the floor. The same situation was rendered in an immersive virtual environment (IVE) Cave-like system, and 12 participants did the three types of walking in a counter-balanced within-groups design. The mean number of EMG activity onsets per unit time followed the same pattern in the virtual environment as in the physical environment-significantly higher for walking on the platform compared to walking on the floor. Even though participants knew that they were in fact really walking at floor level in the virtual environment condition, the visual illusion of walking on a raised platform was sufficient to influence their behavior in a measurable way. This opens up the door for this technique to be used in gait and posture related scenarios including rehabilitation.},
keywords={electromyography;medical signal processing;virtual reality;cave like system;immersive virtual environment;lower spine muscle activation;narrow beam walking;surface electromyography;virtual reality;Displays;Electromyography;Haptic interfaces;Information systems;Legged locomotion;Multimedia systems;Muscles;Particle measurements;Virtual environment;Virtual reality;Information technology and systems;and virtual realities;artificial;augmented;evaluation/methodology.;multimedia information systems;Adult;Electromyography;Gait;Humans;Muscles;Posture;Spine;Walking},
doi={10.1109/TVCG.2010.26},
ISSN={1077-2626},}
@ARTICLE{5665272,
author={Grammel, Lars and Tory, M. and Storey, Margaret-Anne},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Erratum to #x0201C;How Information Visualization Novices Construct Visualizations #x0201D;},
year={2011},
month={Feb},
volume={17},
number={2},
pages={260-260},
abstract={},
doi={10.1109/TVCG.2011.13},
ISSN={1077-2626},}
@ARTICLE{5473228,
author={Gosink, L.J. and Garth, C. and Anderson, J.C. and Bethel, E.W. and Joy, K.I.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={An Application of Multivariate Statistical Analysis for Query-Driven Visualization},
year={2011},
month={March},
volume={17},
number={3},
pages={264-275},
abstract={Driven by the ability to generate ever-larger, increasingly complex data, there is an urgent need in the scientific community for scalable analysis methods that can rapidly identify salient trends in scientific data. Query-Driven Visualization (QDV) strategies are among the small subset of techniques that can address both large and highly complex data sets. This paper extends the utility of QDV strategies with a statistics-based framework that integrates nonparametric distribution estimation techniques with a new segmentation strategy to visually identify statistically significant trends and features within the solution space of a query. In this framework, query distribution estimates help users to interactively explore their query's solution and visually identify the regions where the combined behavior of constrained variables is most important, statistically, to their inquiry. Our new segmentation strategy extends the distribution estimation analysis by visually conveying the individual importance of each variable to these regions of high statistical significance. We demonstrate the analysis benefits these two strategies provide and show how they maybe used to facilitate the refinement of constraints over variables expressed in a user's query. We apply our method to data sets from two different scientific domains to demonstrate its broad applicability.},
keywords={data visualisation;query processing;statistical analysis;QDV strategies;multivariate statistical analysis;new segmentation strategy;nonparametric distribution estimation techniques;query distribution;query-driven visualization;scientific data;Acceleration;Bandwidth;Data analysis;Data visualization;Information analysis;Kernel;Large-scale systems;Multidimensional systems;Statistical analysis;Visual databases;Query-driven visualization;kernel density estimation.;multivariate analysis;Computer Graphics;Data Interpretation, Statistical;Databases, Factual;Information Storage and Retrieval;Multivariate Analysis;User-Computer Interface},
doi={10.1109/TVCG.2010.80},
ISSN={1077-2626},}
@ARTICLE{5453362,
author={Archambault, D. and Munzner, T. and Auber, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Tugging Graphs Faster: Efficiently Modifying Path-Preserving Hierarchies for Browsing Paths},
year={2011},
month={March},
volume={17},
number={3},
pages={276-289},
abstract={Many graph visualization systems use graph hierarchies to organize a large input graph into logical components. These approaches detect features globally in the data and place these features inside levels of a hierarchy. However, this feature detection is a global process and does not consider nodes of the graph near a feature of interest. TugGraph is a system for exploring paths and proximity around nodes and subgraphs in a graph. The approach modifies a pre-existing hierarchy in order to see how a node or subgraph of interest extends out into the larger graph. It is guaranteed to create path-preserving hierarchies, so that the abstraction shown is meaningful with respect to the underlying structure of the graph. The system works well on graphs of hundreds of thousands of nodes and millions of edges. TugGraph is able to present views of this proximal information in the context of the entire graph in seconds, and does not require a layout of the full graph as input.},
keywords={data visualisation;edge detection;feature extraction;graph theory;online front-ends;TugGraph;browsing paths;feature detection;graph visualization systems;path preserving hierarchy;subgraphs;Books;Computer Society;Computer networks;Computer vision;Data visualization;IP networks;Internet;Network servers;Systems engineering and theory;Web server;Graph visualization;graph hierarchies.;proximity;Algorithms;Computer Graphics;Information Storage and Retrieval;Software;User-Computer Interface},
doi={10.1109/TVCG.2010.60},
ISSN={1077-2626},}
@ARTICLE{5432168,
author={Marriott, K. and Sbarski, P. and van Gelder, T. and Prager, D. and Bulka, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Hi-Trees and Their Layout},
year={2011},
month={March},
volume={17},
number={3},
pages={290-304},
abstract={We introduce hi-trees, a new visual representation for hierarchical data in which, depending on the kind of parent node, the child relationship is represented using either containment or links. We give a drawing convention for hi-trees based on the standard layered drawing convention for rooted trees, then show how to extend standard bottom-up tree layout algorithms to draw hi-trees in this convention. We also explore a number of other more compact layout styles for layout of larger hi-trees and give algorithms for computing these. Finally, we describe two applications of hi-trees: argument mapping and business decision support.},
keywords={tree data structures;trees (mathematics);argument mapping;business decision support;hi-trees;hierarchical data visual representation;rooted trees;standard bottom-up tree layout algorithms;standard layered drawing convention;Compaction;Data visualization;Decision making;Economic indicators;Electronic mail;Standards development;Tree layout;argument mapping;decision support;hi-tree;information visualization.;Algorithms;Computational Biology;Decision Trees},
doi={10.1109/TVCG.2010.45},
ISSN={1077-2626},}
@ARTICLE{5262940,
author={Correa, C. and Hero, R. and Kwan-Liu Ma},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Comparison of Gradient Estimation Methods for Volume Rendering on Unstructured Meshes},
year={2011},
month={March},
volume={17},
number={3},
pages={305-319},
abstract={This paper presents a study of gradient estimation methods for rendering unstructured-mesh volume data. Gradient estimation is necessary for rendering shaded isosurfaces and specular highlights, which provide important cues for shape and depth. Gradient estimation has been widely studied and deployed for regular-grid volume data to achieve local illumination effects, but has been, otherwise, for unstructured-mesh data. As a result, most of the unstructured-mesh volume visualizations made so far were unlit. In this paper, we present a comprehensive study of gradient estimation methods for unstructured meshes with respect to their cost and performance. Through a number of benchmarks, we discuss the effects of mesh quality and scalar function complexity in the accuracy of the reconstruction, and their impact in lighting-enabled volume rendering. Based on our study, we also propose two heuristic improvements to the gradient reconstruction process. The first heuristic improves the rendering quality with a hybrid algorithm that combines the results of the multiple reconstruction methods, based on the properties of a given mesh. The second heuristic improves the efficiency of its GPU implementation, by restricting the computation of the gradient on a fixed-size local neighborhood.},
keywords={computational complexity;data visualisation;flow visualisation;gradient methods;image reconstruction;lighting;net structures (mechanical);rendering (computer graphics);GPU implementation;fixed size local neighborhood;gradient estimation method;gradient reconstruction process;hybrid algorithm;illumination effect;mesh quality;regular grid volume data;rendering quality;scalar function complexity;shaded isosurface rendering;unstructured mesh;volume rendering;Costs;Data visualization;Image reconstruction;Isosurfaces;Lighting;Optical reflection;Reconstruction algorithms;Rendering (computer graphics);Shape;Spatial resolution;Volume rendering;flow visualization.;gradient estimation;local illumination;unstructured meshes;Algorithms;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Reproducibility of Results},
doi={10.1109/TVCG.2009.105},
ISSN={1077-2626},}
@ARTICLE{5453361,
author={Doerr, K.-U. and Kuester, F.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={CGLX: A Scalable, High-Performance Visualization Framework for Networked Display Environments},
year={2011},
month={March},
volume={17},
number={3},
pages={320-332},
abstract={The Cross Platform Cluster Graphics Library (CGLX) is a flexible and transparent OpenGL-based graphics framework for distributed, high-performance visualization systems. CGLX allows OpenGL based applications to utilize massively scalable visualization clusters such as multiprojector or high-resolution tiled display environments and to maximize the achievable performance and resolution. The framework features a programming interface for hardware-accelerated rendering of OpenGL applications on visualization clusters, mimicking a GLUT-like (OpenGL-Utility-Toolkit) interface to enable smooth translation of single-node applications to distributed parallel rendering applications. CGLX provides a unified, scalable, distributed OpenGL context to the user by intercepting and manipulating certain OpenGL directives. CGLX's interception mechanism, in combination with the core functionality for users to register callbacks, enables this framework to manage a visualization grid without additional implementation requirements to the user. Although CGLX grants access to its core engine, allowing users to change its default behavior, general development can occur in the context of a standalone desktop. The framework provides an easy-to-use graphical user interface (GUI) and tools to test, setup, and configure a visualization cluster. This paper describes CGLX's architecture, tools, and systems components. We present performance and scalability tests with different types of applications, and we compare the results with a Chromium-based approach.},
keywords={data visualisation;graphical user interfaces;pattern clustering;rendering (computer graphics);GLUT like interface;OpenGL based graphics framework;chromium based approach;cross platform cluster graphics library;graphical user interface;hardware accelerated rendering;networked display environments;visualization systems;Displays;Engines;Graphical user interfaces;Graphics;Libraries;Parallel programming;Rendering (computer graphics);Scalability;Testing;Visualization;Distributed/network graphics;distributed applications;distributed systems.;information interfaces and representation (HCI);information technology and systems;Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Software;User-Computer Interface},
doi={10.1109/TVCG.2010.59},
ISSN={1077-2626},}
@ARTICLE{5453365,
author={Di Xu and Doutre, C. and Nasiopoulos, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Correction of Clipped Pixels in Color Images},
year={2011},
month={March},
volume={17},
number={3},
pages={333-344},
abstract={Conventional images store a very limited dynamic range of brightness. The true luma in the bright area of such images is often lost due to clipping. When clipping changes the R, G, B color ratios of a pixel, color distortion also occurs. In this paper, we propose an algorithm to enhance both the luma and chroma of the clipped pixels. Our method is based on the strong chroma spatial correlation between clipped pixels and their surrounding unclipped area. After identifying the clipped areas in the image, we partition the clipped areas into regions with similar chroma, and estimate the chroma of each clipped region based on the chroma of its surrounding unclipped region. We correct the clipped R, G, or B color channels based on the estimated chroma and the unclipped color channel(s) of the current pixel. The last step involves smoothing of the boundaries between regions of different clipping scenarios. Both objective and subjective experimental results show that our algorithm is very effective in restoring the color of clipped pixels.},
keywords={image colour analysis;image enhancement;image restoration;image segmentation;RGB color channels;RGB color ratio;chroma spatial correlation;clipped area partitioning;clipped pixel correction;color distortion;color images;color restoration;image enhancement;Brightness;Color;Dynamic range;Image restoration;Partitioning algorithms;Pixel;Smoothing methods;Clipping;color restoration;desaturation;high dynamic range (HDR);inverse tone mapping.;Algorithms;Image Enhancement;Image Interpretation, Computer-Assisted;Reproducibility of Results},
doi={10.1109/TVCG.2010.63},
ISSN={1077-2626},}
@ARTICLE{5438988,
author={Guodong Rong and Yang Liu and Wenping Wang and Xiaotian Yin and Gu, X.D. and Guo, Xiaohu},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-Assisted Computation of Centroidal Voronoi Tessellation},
year={2011},
month={March},
volume={17},
number={3},
pages={345-356},
abstract={Centroidal Voronoi tessellations (CVT) are widely used in computational science and engineering. The most commonly used method is Lloyd's method, and recently the L-BFGS method is shown to be faster than Lloyd's method for computing the CVT. However, these methods run on the CPU and are still too slow for many practical applications. We present techniques to implement these methods on the GPU for computing the CVT on 2D planes and on surfaces, and demonstrate significant speedup of these GPU-based methods over their CPU counterparts. For CVT computation on a surface, we use a geometry image stored in the GPU to represent the surface for computing the Voronoi diagram on it. In our implementation a new technique is proposed for parallel regional reduction on the GPU for evaluating integrals over Voronoi cells.},
keywords={computational geometry;computer graphic equipment;coprocessors;Lloyd method;Voronoi diagram;centroidal Voronoi tessellations;graphics processing unit;parallel regional reduction;Application software;Art;Computational geometry;Computational modeling;Computer graphics;Computer science;Hardware;Mesh generation;Pattern recognition;Visualization;Centroidal Voronoi tessellation;L-BFGS algorithm;Lloyd's algorithm;graphics hardware;remeshing.;Algorithms;Computational Biology;Computer Graphics;Image Processing, Computer-Assisted},
doi={10.1109/TVCG.2010.53},
ISSN={1077-2626},}
@ARTICLE{5453359,
author={Juyong Zhang and Jianmin Zheng and Jianfei Cai},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Mesh Cutting Using Constrained Random Walks},
year={2011},
month={March},
volume={17},
number={3},
pages={357-367},
abstract={This paper considers the problem of interactively finding the cutting contour to extract components from an existing mesh. First, we propose a constrained random walks algorithm that can add constraints to the random walks procedure and thus allows for a variety of intuitive user inputs. Second, we design an optimization process that uses the shortest graph path to derive a nice cut contour. Then a new mesh cutting algorithm is developed based on the constrained random walks plus the optimization process. Within the same computational framework, the new algorithm provides a novel user interface for interactive mesh cutting that supports three typical user inputs and also their combinations: 1) foreground/background seed inputs: the user draws strokes specifying seeds for “foreground” (i.e., the part to be cut out) and “background” (i.e., the rest); 2) soft constraint inputs: the user draws strokes on the mesh indicating the region which the cuts should be made nearby; and 3) hard constraint inputs: the marks which the cutting contour must pass. The algorithm uses feature sensitive metrics that are based on surface geometric properties and cognitive theory. The integration of the constrained random walks algorithm, the optimization process, the feature sensitive metrics, and the varieties of user inputs makes the algorithm intuitive, flexible, and effective as well. The experimental examples show that the proposed cutting method is fast, reliable, and capable of producing good results reflecting user intention and geometric attributes.},
keywords={computational geometry;constraint handling;graph theory;mesh generation;optimisation;cognitive theory;constrained random walks;graph path;interactive mesh cutting;optimization process;surface geometric properties;user interface;Computer interfaces;Constraint optimization;Design optimization;Geometry;Humans;Partitioning algorithms;Process design;Shape;Solid modeling;User interfaces;Computational geometry and object modeling;geometric algorithms.;interaction techniques;Algorithms;Computer Graphics;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;User-Computer Interface},
doi={10.1109/TVCG.2010.57},
ISSN={1077-2626},}
@ARTICLE{5416708,
author={Taehyun Rhee and Lewis, J.P. and Neumann, U. and Nayak, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Scan-Based Volume Animation Driven by Locally Adaptive Articulated Registrations},
year={2011},
month={March},
volume={17},
number={3},
pages={368-379},
abstract={This paper describes a complete system to create anatomically accurate example-based volume deformation and animation of articulated body regions, starting from multiple in vivo volume scans of a specific individual. In order to solve the correspondence problem across volume scans, a template volume is registered to each sample. The wide range of pose variations is first approximated by volume blend deformation (VBD), providing proper initialization of the articulated subject in different poses. A novel registration method is presented to efficiently reduce the computation cost while avoiding strong local minima inherent in complex articulated body volume registration. The algorithm highly constrains the degrees of freedom and search space involved in the nonlinear optimization, using hierarchical volume structures and locally constrained deformation based on the biharmonic clamped spline. Our registration step establishes a correspondence across scans, allowing a data-driven deformation approach in the volume domain. The results provide an occlusion-free person-specific 3D human body model, asymptotically accurate inner tissue deformations, and realistic volume animation of articulated movements driven by standard joint control estimated from the actual skeleton. Our approach also addresses the practical issues arising in using scans from living subjects. The robustness of our algorithms is tested by their applications on the hand, probably the most complex articulated region in the body, and the knee, a frequent subject area for medical imaging due to injuries.},
keywords={biology computing;biomedical imaging;computer animation;image registration;nonlinear programming;solid modelling;3D human body model;articulated body region;biharmonic clamped spline;hierarchical volume structure;medical imaging;nonlinear optimization;search space;standard joint control;vivo volume scan;volume animation;volume blend deformation;Animation;Biological system modeling;Body regions;Computational efficiency;Constraint optimization;Deformable models;Humans;In vivo;Joints;Spline;Registration;deformation;volume animation.;Algorithms;Humans;Imaging, Three-Dimensional;Pattern Recognition, Automated;Whole Body Imaging},
doi={10.1109/TVCG.2010.39},
ISSN={1077-2626},}
@ARTICLE{5432170,
author={Lang, J. and Andrews, S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Measurement-Based Modeling of Contact Forces and Textures for Haptic Rendering},
year={2011},
month={March},
volume={17},
number={3},
pages={380-391},
abstract={Haptic texture represents the fine-grained attributes of an object's surface and is related to physical characteristics such as roughness and stiffness. We introduce an interactive and mobile scanning system for the acquisition and synthesis of haptic textures that consists of a visually tracked handheld touch probe. The most novel aspect of our work is an estimation method for the contact stiffness of an object based solely on the acceleration and forces measured during stroking of its surface with the handheld probe. We establish an experimental relationship between the estimated stiffness and the contact stiffness observed during compression. We also measure the height-displacement profile of an object's surface enabling us to generate haptic textures. We show an example of mapping the textures on to a coarse surface mesh obtained with an image-based technique, but the textures may also be combined with coarse surface meshes obtained by manual modeling.},
keywords={elasticity;force measurement;haptic interfaces;image scanners;image texture;mechanical contact;rendering (computer graphics);tactile sensors;acceleration measurement;coarse surface mesh;compression;contact forces;contact stiffness;estimation method;fine-grained attributes;forces measurement;haptic rendering;haptic textures;height-displacement profile;image-based technique;interactive system;mapping;measurement-based modeling;mobile scanning system;object surface;surface stroking;visually tracked handheld touch probe;Acceleration;Accelerometers;Force measurement;Haptic interfaces;Image coding;Manuals;Probes;Rough surfaces;Surface roughness;Surface texture;Haptics;contact stiffness;measurement-based modeling.;texture;Computer Graphics;Computers, Handheld;Image Interpretation, Computer-Assisted;Logistic Models;User-Computer Interface},
doi={10.1109/TVCG.2010.52},
ISSN={1077-2626},}
@ARTICLE{5473227,
author={Schulz, H. and Hadlak, S. and Schumann, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={The Design Space of Implicit Hierarchy Visualization: A Survey},
year={2011},
month={April},
volume={17},
number={4},
pages={393-411},
abstract={Apart from explicit node-link representations, implicit visualizations and especially the Treemap as their frontrunner have acquired a solid position among the available techniques to visualize hierarchies. Their advantage is a highly space-efficient graphical representation that does not require explicit drawing of edges. In this paper, we survey the design space for this class of visualization techniques. We establish the design space along the four axes of dimensionality, edge representation, node representation, and layout by examining existing implicit hierarchy visualization techniques. The survey is completed by casting some light into regions of the design space that have not yet been explored. Our design space is not a mere theoretical construct, but a practically usable tool for rapid visualization development. To that end, we discuss a software implementation of the introduced design space.},
keywords={data visualisation;software prototyping;design space;dimensionality aspect;edge representation aspect;explicit node-link representations;implicit hierarchy visualization;layout aspect;node representation aspect;rapid visualization development;space-efficient graphical representation;treemap;Casting;Computer graphics;Data visualization;Encoding;Layout;Prototypes;Software prototyping;Solids;Space exploration;Tree graphs;Information visualization;Treemaps;hierarchy visualization;rapid visualization prototyping.;visualization design space},
doi={10.1109/TVCG.2010.79},
ISSN={1077-2626},}
@ARTICLE{5467066,
author={Schafhitzel, T. and Baysal, K. and Vaaraniemi, M. and Rist, U. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualizing the Evolution and Interaction of Vortices and Shear Layers in Time-Dependent 3D Flow},
year={2011},
month={April},
volume={17},
number={4},
pages={412-425},
abstract={In this paper, we present a visualization and tracking system for coherent structures. For this purpose, we propose to consider shear stress-the stretching and shear of particles inside a flow-in vortex dynamics. Based on a discussion and comparison of recent methods for computing shear stress, we introduce visualization techniques in order to provide a representation of shear layers according to their physical interpretation. This paper contributes a combination of theory in fluid mechanics and the corresponding visualization: 1) shear layer criteria are assessed according to how well they can be combined with common vortex identification criteria; 2) sheets of maximal shear are introduced as an appropriate visual representation of shear layers; 3) a visualization method is described for simultaneous tracking of vortices and shear layers as well as their interaction; and 4) the relevance of shear layers in vortex dynamics is demonstrated by means of several examples. We have implemented these new techniques in an interactive visualization system for time-dependent 3D flow. The system is used by fluid mechanics experts in their research of shear-vortex interaction.},
keywords={data visualisation;flow visualisation;internal stresses;structural engineering computing;vortices;coherent structure tracking system;coherent structure visualization;fluid mechanics theory;maximal shear sheets;shear layer criteria;shear stress;shear-vortex interaction;time-dependent 3D flow;visualization techniques;vortex dynamics;Aerodynamics;Atmosphere;Computer Society;Energy dissipation;Fluid dynamics;Friction;Physics computing;Power engineering and energy;Stress;Visualization;Flow visualization;coherent structures;shear layers.;tracking;vortex dynamics},
doi={10.1109/TVCG.2010.65},
ISSN={1077-2626},}
@ARTICLE{5416706,
author={Hossain, Z. and Alim, U. and Möller, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Toward High-Quality Gradient Estimation on Regular Lattices},
year={2011},
month={April},
volume={17},
number={4},
pages={426-439},
abstract={In this paper, we present two methods for accurate gradient estimation from scalar field data sampled on regular lattices. The first method is based on the multidimensional Taylor series expansion of the convolution sum and allows us to specify design criteria such as compactness and approximation power. The second method is based on a Hilbert space framework and provides a minimum error solution in the form of an orthogonal projection operating between two approximation spaces. Both methods lead to discrete filters, which can be combined with continuous reconstruction kernels to yield highly accurate estimators as compared to the current state of the art. We demonstrate the advantages of our methods in the context of volume rendering of data sampled on Cartesian and Body-Centered Cubic lattices. Our results show significant qualitative and quantitative improvements for both synthetic and real data, while incurring a moderate preprocessing and storage overhead.},
keywords={approximation theory;gradient methods;rendering (computer graphics);series (mathematics);Cartesian lattices;Hilbert space framework;approximation power criteria;body-centered cubic lattices;compactness criteria;continuous reconstruction kernels;convolution sum;gradient estimation;multidimensional Taylor series expansion;orthogonal projection;regular lattices;volume rendering;Convolution;Filters;Hilbert space;Image reconstruction;Interpolation;Kernel;Lattices;Multidimensional systems;State estimation;Taylor series;Approximation theory;Taylor series expansion;body-centered cubic lattice;box splines.;normal reconstruction;orthogonal projection},
doi={10.1109/TVCG.2010.37},
ISSN={1077-2626},}
@ARTICLE{5473230,
author={Maciejewski, R. and Hafen, R. and Rudolph, S. and Larew, S.G. and Mitchell, M.A. and Cleveland, W.S. and Ebert, D.S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Forecasting Hotspots #x02014;A Predictive Analytics Approach},
year={2011},
month={April},
volume={17},
number={4},
pages={440-453},
abstract={Current visual analytics systems provide users with the means to explore trends in their data. Linked views and interactive displays provide insight into correlations among people, events, and places in space and time. Analysts search for events of interest through statistical tools linked to visual displays, drill down into the data, and form hypotheses based upon the available information. However, current systems stop short of predicting events. In spatiotemporal data, analysts are searching for regions of space and time with unusually high incidences of events (hotspots). In the cases where hotspots are found, analysts would like to predict how these regions may grow in order to plan resource allocation and preventative measures. Furthermore, analysts would also like to predict where future hotspots may occur. To facilitate such forecasting, we have created a predictive visual analytics toolkit that provides analysts with linked spatiotemporal and statistical analytic views. Our system models spatiotemporal events through the combination of kernel density estimation for event distribution and seasonal trend decomposition by loess smoothing for temporal predictions. We provide analysts with estimates of error in our modeling, along with spatial and temporal alerts to indicate the occurrence of statistically significant hotspots. Spatial data are distributed based on a modeling of previous event locations, thereby maintaining a temporal coherence with past events. Such tools allow analysts to perform real-time hypothesis testing, plan intervention strategies, and allocate resources to correspond to perceived threats.},
keywords={data analysis;data visualisation;statistical distributions;event distribution;hotspots forecasting;hypothesis testing;intervention strategy;kernel density estimation;predictive analytics approach;resource allocation;seasonal trend decomposition;spatiotemporal analytic view;statistical analytic view;visual analytics;Coherence;Data analysis;Kernel;Performance analysis;Performance evaluation;Predictive models;Resource management;Smoothing methods;Spatiotemporal phenomena;Visual analytics;Predictive analytics;syndromic surveillance.;visual analytics},
doi={10.1109/TVCG.2010.82},
ISSN={1077-2626},}
@ARTICLE{5453364,
author={Steffen, W. and Koning, N. and Wenger, S. and Morisset, C. and Magnor, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Shape: A 3D Modeling Tool for Astrophysics},
year={2011},
month={April},
volume={17},
number={4},
pages={454-465},
abstract={We present a flexible interactive 3D morpho-kinematical modeling application for astrophysics. Compared to other systems, our application reduces the restrictions on the physical assumptions, data type, and amount that is required for a reconstruction of an object's morphology. It is one of the first publicly available tools to apply interactive graphics to astrophysical modeling. The tool allows astrophysicists to provide a priori knowledge about the object by interactively defining 3D structural elements. By direct comparison of model prediction with observational data, model parameters can then be automatically optimized to fit the observation. The tool has already been successfully used in a number of astrophysical research projects.},
keywords={astronomy computing;interactive systems;solid modelling;3D modeling tool;3D structural elements;Shape;a priori knowledge;astrophysics;data type;flexible interactive 3D morpho-kinematical modeling;interactive graphics;Application software;Astronomy;Astrophysics;Computational modeling;Graphics;Image reconstruction;Morphology;Packaging;Predictive models;Shape;Modeling packages;astronomy;physics.;scene analysis},
doi={10.1109/TVCG.2010.62},
ISSN={1077-2626},}
@ARTICLE{5648735,
author={Qiming Hou and Xin Sun and Kun Zhou and Lauterbach, C. and Manocha, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Memory-Scalable GPU Spatial Hierarchy Construction},
year={2011},
month={April},
volume={17},
number={4},
pages={466-474},
abstract={Recent GPU algorithms for constructing spatial hierarchies have achieved promising performance for moderately complex models by using the breadth-first search (BFS) construction order. While being able to exploit the massive parallelism on the GPU, the BFS order also consumes excessive GPU memory, which becomes a serious issue for interactive applications involving very complex models with more than a few million triangles. In this paper, we propose to use the partial breadth-first search (PBFS) construction order to control memory consumption while maximizing performance. We apply the PBFS order to two hierarchy construction algorithms. The first algorithm is for kd-trees that automatically balances between the level of parallelism and intermediate memory usage. With PBFS, peak memory consumption during construction can be efficiently controlled without costly CPU-GPU data transfer. We also develop memory allocation strategies to effectively limit memory fragmentation. The resulting algorithm scales well with GPU memory and constructs kd-trees of models with millions of triangles at interactive rates on GPUs with 1 GB memory. Compared with existing algorithms, our algorithm is an order of magnitude more scalable for a given GPU memory bound. The second algorithm is for out-of-core bounding volume hierarchy (BVH) construction for very large scenes based on the PBFS construction order. At each iteration, all constructed nodes are dumped to the CPU memory, and the GPU memory is freed for the next iteration's use. In this way, the algorithm is able to build trees that are too large to be stored in the GPU memory. Experiments show that our algorithm can construct BVHs for scenes with up to 20 M triangles, several times larger than previous GPU algorithms.},
keywords={computer graphic equipment;coprocessors;storage management;tree searching;GPU spatial hierarchy construction;bounding volume hierarchy construction;breadth-first search construction order;graphics processing unit;kd-trees algorithm;memory allocation strategy;memory consumption;memory-scalable GPU;Algorithm design and analysis;Graphics processing unit;Layout;Memory management;Parallel processing;Ray tracing;Shape;Memory bound;bounding volume hierarchy.;kd-tree},
doi={10.1109/TVCG.2010.88},
ISSN={1077-2626},}
@ARTICLE{5473225,
author={Dachsbacher, C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Analyzing Visibility Configurations},
year={2011},
month={April},
volume={17},
number={4},
pages={475-486},
abstract={Many algorithms, such as level of detail rendering and occlusion culling methods, make decisions based on the degree of visibility of an object, but do not analyze the distribution, or structure, of the visible and occluded regions across surfaces. We present an efficient method to classify different visibility configurations and show how this can be used on top of existing methods based on visibility determination. We adapt co-occurrence matrices for visibility analysis and generalize them to operate on clusters of triangular surfaces instead of pixels. We employ machine learning techniques to reliably classify the thus extracted feature vectors. Our method allows perceptually motivated level of detail methods for real-time rendering applications by detecting configurations with expected visual masking. We exemplify the versatility of our method with an analysis of area light visibility configurations in ray tracing and an area-to-area visibility analysis suitable for hierarchical radiosity refinement. Initial results demonstrate the robustness, simplicity, and performance of our method in synthetic scenes, as well as real applications.},
keywords={data analysis;learning (artificial intelligence);matrix algebra;pattern classification;rendering (computer graphics);co-occurrence matrices;detail rendering method;hierarchical radiosity refinement;machine learning techniques;occlusion culling method;ray tracing;visibility analysis;visibility configuration classification;visibility degree;visibility determination;visual masking;Algorithm design and analysis;Artificial intelligence;Clustering algorithms;Computational modeling;Feature extraction;Layout;Machine learning;Ray tracing;Robustness;Solids;GPUs;Real-time rendering;artificial intelligence.;visibility},
doi={10.1109/TVCG.2010.77},
ISSN={1077-2626},}
@ARTICLE{5432169,
author={Sen, P. and Darabi, S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Compressive Rendering: A Rendering Application of Compressed Sensing},
year={2011},
month={April},
volume={17},
number={4},
pages={487-499},
abstract={Recently, there has been growing interest in compressed sensing (CS), the new theory that shows how a small set of linear measurements can be used to reconstruct a signal if it is sparse in a transform domain. Although CS has been applied to many problems in other fields, in computer graphics, it has only been used so far to accelerate the acquisition of light transport. In this paper, we propose a novel application of compressed sensing by using it to accelerate ray-traced rendering in a manner that exploits the sparsity of the final image in the wavelet basis. To do this, we raytrace only a subset of the pixel samples in the spatial domain and use a simple, greedy CS-based algorithm to estimate the wavelet transform of the image during rendering. Since the energy of the image is concentrated more compactly in the wavelet domain, less samples are required for a result of given quality than with conventional spatial-domain rendering. By taking the inverse wavelet transform of the result, we compute an accurate reconstruction of the desired final image. Our results show that our framework can achieve high-quality images with approximately 75 percent of the pixel samples using a nonadaptive sampling scheme. In addition, we also perform better than other algorithms that might be used to fill in the missing pixel data, such as interpolation or inpainting. Furthermore, since the algorithm works in image space, it is completely independent of scene complexity.},
keywords={data compression;greedy algorithms;rendering (computer graphics);sampling methods;wavelet transforms;compressed sensing;compressive rendering;greedy CS-based algorithm;inverse wavelet transform;nonadaptive sampling scheme;ray-traced rendering;Acceleration;Application software;Compressed sensing;Computer graphics;Image reconstruction;Image sampling;Pixel;Rendering (computer graphics);Wavelet domain;Wavelet transforms;Rendering;compressed sensing.;ray tracing;sampling and reconstruction},
doi={10.1109/TVCG.2010.46},
ISSN={1077-2626},}
@ARTICLE{5477421,
author={Guiqing Li and Canjiang Ren and Jiahua Zhang and Weiyin Ma},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Approximation of Loop Subdivision Surfaces for Fast Rendering},
year={2011},
month={April},
volume={17},
number={4},
pages={500-514},
abstract={This paper describes an approach to the approximation of Loop subdivision surfaces for real-time rendering. The approach consists of two phases, which separately construct the approximation geometry and the normal field of a subdivision surface. It first exploits quartic triangular Bézier patches to approximate the geometry of the subdivision surface by interpolating a grid of sampled points. To remedy the artifact of discontinuity of normal fields between adjacent patches, a continuous normal field is then reconstructed by approximating the tangent vector fields of the subdivision surfaces with quartic triangular Bézier patches. For regular triangles, the approach reproduces the associated subdivision patches, quartic three-directional box splines.},
keywords={approximation theory;computational geometry;interpolation;rendering (computer graphics);splines (mathematics);surface fitting;approximation geometry;continuous normal field;loop subdivision surface approximation;quartic three-directional box splines;quartic triangular Bezier patches;real-time rendering;sampled points interpolation;Acceleration;Buffer storage;Computer architecture;Geometry;Graphics;Hardware;Mesh generation;Rendering (computer graphics);Surface reconstruction;Table lookup;Bézier patches;Subdivision surfaces;graphics processors (GPU);surface approximation.;tessellation},
doi={10.1109/TVCG.2010.83},
ISSN={1077-2626},}
@ARTICLE{5438989,
author={Woojin Ahn and Doo Yong Lee},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Real-Time Resolution of Self-Intersection in Dynamic Cylindrical Free-Form Deformation},
year={2011},
month={April},
volume={17},
number={4},
pages={515-526},
abstract={This paper presents a method of self-intersection detection and resolution for dynamic cylindrical-lattice-based free-form deformation (FFD). The lattice-based approach allows efficient computation of deformation of complex geometries. But excessive deformation can cause visual anomalies such as surface infiltration and distortion. This paper derives a geometrically intuitive sufficient condition to guarantee that the FFD function is a homeomorphism and there is no self-intersection. The FFD function is defined by linear and quadratic B-Spline functions with the control points of the cylindrical lattice cell. The sufficient condition is satisfied if each trilinear function of the nine prism-shaped pentahedrons derived from the cell has a positive Jacobian determinant. The positivity is satisfied if the 12 tetrahedrons derived from the pentahedron have positive volumes. Based on the sufficient condition, the proposed method converts the self-intersection problem into a point-face collision detection and response problem suitable for dynamic simulation. The efficiency and accuracy of the self-intersection detection algorithm is analyzed and compared with a previous method. The results show that the proposed technique allows simulation of excessive deformation of tubular objects in an efficient and realistic manner.},
keywords={computational geometry;solid modelling;splines (mathematics);FFD function;Jacobian determinant;complex geometry deformation;cylindrical lattice cell;dynamic cylindrical free-form deformation;linear B-spline function;prism-shaped pentahedrons;quadratic B-spline function;self-intersection detection method;self-intersection resolution method;Algorithm design and analysis;Computational geometry;Deformable models;Detection algorithms;Jacobian matrices;Lattices;Spline;Sufficient conditions;Free-form deformation;collision;self-intersection;simulation.;Algorithms;Colonoscopy;Humans;Image Processing, Computer-Assisted;Models, Theoretical},
doi={10.1109/TVCG.2010.54},
ISSN={1077-2626},}
@ARTICLE{5660069,
author={I-Chen Lin and Jen-Yu Peng and Chao-Chih Lin and Ming-Han Tsai},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Adaptive Motion Data Representation with Repeated Motion Analysis},
year={2011},
month={April},
volume={17},
number={4},
pages={527-538},
abstract={In this paper, we present a representation method for motion capture data by exploiting the nearly repeated characteristics and spatiotemporal coherence in human motion. We extract similar motion clips of variable lengths or speeds across the database. Since the coding costs between these matched clips are small, we propose the repeated motion analysis to extract the referred and repeated clip pairs with maximum compression gains. For further utilization of motion coherence, we approximate the subspace-projected clip motions or residuals by interpolated functions with range-aware adaptive quantization. Our experiments demonstrate that the proposed feature-aware method is of high computational efficiency. Furthermore, it also provides substantial compression gains with comparable reconstruction and perceptual errors.},
keywords={data structures;motion estimation;adaptive motion data representation;feature aware method;motion analysis;motion coherence;range aware adaptive quantization;spatiotemporal coherence;Approximation methods;Encoding;Joints;Motion segmentation;Pixel;Principal component analysis;Trajectory;Compression (coding)-approximate methods.;Three-dimensional graphics and realism-animation},
doi={10.1109/TVCG.2010.87},
ISSN={1077-2626},}
@ARTICLE{5473226,
author={Archambault, D. and Purchase, H.C. and Pinaud, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Animation, Small Multiples, and the Effect of Mental Map Preservation in Dynamic Graphs},
year={2011},
month={April},
volume={17},
number={4},
pages={539-552},
abstract={In this paper, we present the results of a human-computer interaction experiment that compared the performance of the animation of dynamic graphs to the presentation of small multiples and the effect that mental map preservation had on the two conditions. Questions used in the experiment were selected to test both local and global properties of graph evolution over time. The data sets used in this experiment were derived from standard benchmark data sets of the information visualization community. We found that small multiples gave significantly faster performance than animation overall and for each of our five graph comprehension tasks. In addition, small multiples had significantly more errors than animation for the tasks of determining sets of nodes or edges added to the graph during the same timeslice, although a positive time-error correlation coefficient suggests that, in this case, faster responses did not lead to more errors. This result suggests that, for these two tasks, animation is preferable if accuracy is more important than speed. Preserving the mental map under either the animation or the small multiples condition had little influence in terms of error rate and response time.},
keywords={computer animation;data visualisation;human computer interaction;dynamic graphs animation;human-computer interaction;information visualization community;mental map preservation effect;small multiples presentation;time-error correlation coefficient;Algorithm design and analysis;Animation;Benchmark testing;Data visualization;Delay;Displays;Error analysis;Heuristic algorithms;Human computer interaction;Shape;Dynamic graph drawing;animation;evaluation.;mental map preservation;small multiples},
doi={10.1109/TVCG.2010.78},
ISSN={1077-2626},}
@ARTICLE{5482578,
author={Koch, S. and Bosch, H. and Giereth, M. and Ertl, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Iterative Integration of Visual Insights during Scalable Patent Search and Analysis},
year={2011},
month={May},
volume={17},
number={5},
pages={557-569},
abstract={Patents are of growing importance in current economic markets. Analyzing patent information has, therefore, become a common task for many interest groups. As a prerequisite for patent analysis, extensive search for relevant patent information is essential. Unfortunately, the complexity of patent material inhibits a straightforward retrieval of all relevant patent documents and leads to iterative, time-consuming approaches in practice. Already the amount of patent data to be analyzed poses challenges with respect to scalability. Further scalability issues arise concerning the diversity of users and the large variety of analysis tasks. With "PatViz”, a system for interactive analysis of patent information has been developed addressing scalability at various levels. PatViz provides a visual environment allowing for interactive reintegration of insights into subsequent search iterations, thereby bridging the gap between search and analytic processes. Because of its extensibility, we expect that the approach we have taken can be employed in different problem domains that require high quality of search results regarding their completeness.},
keywords={data visualisation;information retrieval;interactive systems;iterative methods;patents;visual databases;PatViz;interactive analysis;iterative integration;scalable patent search;visual insights;Data analysis;Environmental economics;Graphical user interfaces;Information analysis;Information retrieval;Intellectual property;Iterative methods;Scalability;Statistics;Visualization;Visual analytics;graphical user interfaces;information search and retrieval.},
doi={10.1109/TVCG.2010.85},
ISSN={1077-2626},}
@ARTICLE{5482577,
author={Youn-ah Kang and Gorg, C. and Stasko, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={How Can Visual Analytics Assist Investigative Analysis? Design Implications from an Evaluation},
year={2011},
month={May},
volume={17},
number={5},
pages={570-583},
abstract={Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations on metrics and techniques for evaluating visual analytics systems for investigative analysis.},
keywords={data analysis;data visualisation;Jigsaw;information visuaization;investigative analysis tools;simulated intelligence analysis task;visual analytic support;visual analytics system;Analytical models;Availability;Computational intelligence;Computational modeling;Control systems;Data analysis;Data visualization;Information analysis;Performance analysis;Visual analytics;Visual analytics;evaluation;information visualization;investigative analysis;user study.},
doi={10.1109/TVCG.2010.84},
ISSN={1077-2626},}
@ARTICLE{5620902,
author={Tatu, A. and Albuquerque, G. and Eisemann, M. and Bak, P. and Theisel, H. and Magnor, M. and Keim, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Automated Analytical Methods to Support Visual Exploration of High-Dimensional Data},
year={2011},
month={May},
volume={17},
number={5},
pages={584-597},
abstract={Visual exploration of multivariate data typically requires projection onto lower dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non-class-based scatterplots and parallel coordinates visualizations. The proposed analysis methods are evaluated on different data sets.},
keywords={data analysis;data visualisation;interactive systems;visual databases;automated analytical methods;high-dimensional data;interactive data analysis;multivariate data;useful candidate visualizations;visual exploration;Coordinate measuring machines;Correlation;Data visualization;Density measurement;Pixel;Rotation measurement;Visualization;Dimensionality reduction;parallel coordinates.;quality measures;scatterplots},
doi={10.1109/TVCG.2010.242},
ISSN={1077-2626},}
@ARTICLE{5644519,
author={Schulz, H. and Hadlak, S. and Schumann, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Point-Based Visualization for Large Hierarchies},
year={2011},
month={May},
volume={17},
number={5},
pages={598-611},
abstract={Space-filling layout techniques for tree representations are frequently used when the available screen space is small or the data set is large. In this paper, we propose an efficient approach to space-filling tree representations that uses mechanisms from the point-based rendering paradigm. We present helpful interaction techniques and visual cues that tie in with our layout. Additionally, we relate this new layout approach to common layout mechanisms and evaluate the new layout along the lines of a numerical evaluation using the measures of the Ink-Paper Ratio and overplotted%, and in a preliminary user study. The flexibility of the general approach is illustrated by several enhancements of the basic layout, as well as its usage within the context of two software frameworks from different application fields.},
keywords={data visualisation;rendering (computer graphics);ink-paper ratio;numerical evaluation;point-based rendering paradigm;point-based visualization;software framework;space-filling layout technique;space-filling tree representation;visual cues;Data visualization;Image color analysis;Layout;Pixel;Rendering (computer graphics);Three dimensional displays;Web sites;Tree visualization;point-based rendering.;space-filling layout},
doi={10.1109/TVCG.2010.89},
ISSN={1077-2626},}
@ARTICLE{5453363,
author={Van Almsick, M. and Peeters, T. H J M and Prckovska, V. and Vilanova, A. and ter Haar Romeny, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-Based Ray-Casting of Spherical Functions Applied to High Angular Resolution Diffusion Imaging},
year={2011},
month={May},
volume={17},
number={5},
pages={612-625},
abstract={Abstract-Any sufficiently smooth, positive, real-valued function ψ : S2 → K+ on a sphere S2 can be expanded by a Laplace expansion into a sum of spherical harmonics. Given the Laplace expansion coefficients, we provide a CPU and GPU-based algorithm that renders the radial graph of ψ in a fast and efficient way by ray-casting the glyph of ψ in the fragment shader of a GPU. The proposed rendering algorithm has proven highly useful in the visualization of high angular resolution diffusion imaging (HARDI) data. Our implementation of the rendering algorithm can display simultaneously thousands of glyphs depicting the local diffusivity of water. The rendering is fast enough to allow for interactive manipulation of large HARDI data sets.},
keywords={computational geometry;computer graphic equipment;coprocessors;rendering (computer graphics);CPU based algorithm;GPU based algorithm;GPU based ray casting;HARDI data sets;Laplace expansion;fragment shader;glyph ray casting;high angular resolution diffusion imaging;rendering algorithm;spherical functions;Computer applications;Computer displays;Computer graphics;Data visualization;Diffusion tensor imaging;High-resolution imaging;Image resolution;Magnetic resonance imaging;Probability density function;Rendering (computer graphics);Computer graphics;computer applications;life and medical sciences.;three-dimensional graphics and realism;viewing algorithms},
doi={10.1109/TVCG.2010.61},
ISSN={1077-2626},}
@ARTICLE{5473229,
author={Nollenburg, M. and Wolff, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Drawing and Labeling High-Quality Metro Maps by Mixed-Integer Programming},
year={2011},
month={May},
volume={17},
number={5},
pages={626-641},
abstract={Metro maps are schematic diagrams of public transport networks that serve as visual aids for route planning and navigation tasks. It is a challenging problem in network visualization to automatically draw appealing metro maps. There are two aspects to this problem that depend on each other: the layout problem of finding station and link coordinates and the labeling problem of placing nonoverlapping station labels. In this paper, we present a new integral approach that solves the combined layout and labeling problem (each of which, independently, is known to be NP-hard) using mixed-integer programming (MIP). We identify seven design rules used in most real-world metro maps. We split these rules into hard and soft constraints and translate them into an MIP model. Our MIP formulation finds a metro map that satisfies all hard constraints (if such a drawing exists) and minimizes a weighted sum of costs that correspond to the soft constraints. We have implemented the MIP model and present a case study and the results of an expert assessment to evaluate the performance of our approach in comparison to both manually designed official maps and results of previous layout methods.},
keywords={cartography;computational complexity;data visualisation;integer programming;NP hard;high quality metro maps drawing;high quality metro maps labeling;mixed integer programming;navigation tasks;network visualization;public transport networks;route planning;visual aids;Costs;Geography;Information geometry;Labeling;Navigation;Network topology;Space stations;Urban areas;Visualization;Network visualization;graph drawing;graph labeling;metro map;mixed-integer programming.;octilinear layout},
doi={10.1109/TVCG.2010.81},
ISSN={1077-2626},}
@ARTICLE{5482579,
author={Ramachandra, V. and Hirakawa, K. and Zwicker, M. and Truong Nguyen},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Spatioangular Prefiltering for Multiview 3D Displays},
year={2011},
month={May},
volume={17},
number={5},
pages={642-654},
abstract={In this paper, we analyze the reproduction of light fields on multiview 3D displays. A three-way interaction between the input light field signal (which is often aliased), the joint spatioangular sampling grids of multiview 3D displays, and the interview light leakage in modern multiview 3D displays is characterized in the joint spatioangular frequency domain. Reconstruction of light fields by all physical 3D displays is prone to light leakage, which means that the reconstruction low-pass filter implemented by the display is too broad in the angular domain. As a result, 3D displays excessively attenuate angular frequencies. Our analysis shows that this reduces sharpness of the images shown in the 3D displays. In this paper, stereoscopic image recovery is recast as a problem of joint spatioangular signal reconstruction. The combination of the 3D display point spread function and human visual system provides the narrow-band low-pass filter which removes spectral replicas in the reconstructed light field on the multiview display. The nonideality of this filter is corrected with the proposed prefiltering. The proposed light field reconstruction method performs light field antialiasing as well as angular sharpening to compensate for the nonideal response of the 3D display. The union of cosets approach which has been used earlier by others is employed here to model the nonrectangular spatioangular sampling grids on a multiview display in a generic fashion. We confirm the effectiveness of our approach in simulation and in physical hardware, and demonstrate improvement over existing techniques.},
keywords={image reconstruction;image sampling;low-pass filters;stereo image processing;three-dimensional displays;human visual system;image sharpness;input light field signal;interview light leakage;joint spatioangular frequency domain;light fields;multiview 3D displays;narrow-band low-pass filter;signal reconstruction;spatioangular prefiltering;spatioangular sampling grids;spectral replicas;stereoscopic image recovery;Frequency domain analysis;Humans;Image analysis;Image reconstruction;Low pass filters;Narrowband;Sampling methods;Signal reconstruction;Three dimensional displays;Visual system;3D;Light field;aliasing;autostereoscopic display;crosstalk;lenticular;parallax barrier;sampling;sharpening.},
doi={10.1109/TVCG.2010.86},
ISSN={1077-2626},}
@ARTICLE{5467067,
author={Prendinger, H. and Ullrich, S. and Nakasone, A. and Ishizuka, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={MPML3D: Scripting Agents for the 3D Internet},
year={2011},
month={May},
volume={17},
number={5},
pages={655-668},
abstract={The aim of this paper is two-fold. First, it describes a scripting language for specifying communicative behavior and interaction of computer-controlled agents ("bots”) in the popular three-dimensional (3D) multiuser online world of "Second Life” and the emerging "OpenSimulator” project. While tools for designing avatars and in-world objects in Second Life exist, technology for nonprogrammer content creators of scenarios involving scripted agents is currently missing. Therefore, we have implemented new client software that controls bots based on the Multimodal Presentation Markup Language 3D (MPML3D), a highly expressive XML-based scripting language for controlling the verbal and nonverbal behavior of interacting animated agents. Second, the paper compares Second Life and OpenSimulator platforms and discusses the merits and limitations of each from the perspective of agent control. Here, we also conducted a small study that compares the network performance of both platforms.},
keywords={Internet;authoring languages;avatars;computer animation;data visualisation;graphical user interfaces;software agents;3D Internet;MPML3D;OpenSimulator;Second Life;avatar design;bots;computer-controlled agents;graphical user interfaces;multimodal presentation markup language 3D;scripting agents;scripting language;Animation;Avatars;Computer crashes;Graphical user interfaces;Informatics;Internet;Markup languages;Second Life;Virtual reality;Visualization;Artificial;and virtual realities;augmented;graphical user interfaces;markup languages;scripting languages.;synchronous interaction;visualization},
doi={10.1109/TVCG.2010.66},
ISSN={1077-2626},}
@ARTICLE{5473223,
author={Kun Zhou and Gong, Minmin and Xin Huang and Baining Guo},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Data-Parallel Octrees for Surface Reconstruction},
year={2011},
month={May},
volume={17},
number={5},
pages={669-681},
abstract={We present the first parallel surface reconstruction algorithm that runs entirely on the GPU. Like existing implicit surface reconstruction methods, our algorithm first builds an octree for the given set of oriented points, then computes an implicit function over the space of the octree, and finally extracts an isosurface as a watertight triangle mesh. A key component of our algorithm is a novel technique for octree construction on the GPU. This technique builds octrees in real time and uses level-order traversals to exploit the fine-grained parallelism of the GPU. Moreover, the technique produces octrees that provide fast access to the neighborhood information of each octree node, which is critical for fast GPU surface reconstruction. With an octree so constructed, our GPU algorithm performs Poisson surface reconstruction, which produces high-quality surfaces through a global optimization. Given a set of 500 K points, our algorithm runs at the rate of about five frames per second, which is over two orders of magnitude faster than previous CPU algorithms. To demonstrate the potential of our algorithm, we propose a user-guided surface reconstruction technique which reduces the topological ambiguity and improves reconstruction results for imperfect scan data. We also show how to use our algorithm to perform on-the-fly conversion from dynamic point clouds to surfaces as well as to reconstruct fluid surfaces for real-time fluid simulation.},
keywords={computer graphic equipment;computer graphics;coprocessors;octrees;optimisation;surface reconstruction;GPU;Poisson surface reconstruction;data-parallel octrees;fine-grained parallelism;global optimization;high-quality surfaces;oriented points;parallel surface reconstruction;user-guided surface reconstruction;watertight triangle mesh;Fluid dynamics;Graphics processing unit;Heuristic algorithms;Isosurfaces;Octrees;Parallel processing;Real time systems;Reconstruction algorithms;Surface fitting;Surface reconstruction;Surface reconstruction;marching cubes.;octree;programable graphics unit},
doi={10.1109/TVCG.2010.75},
ISSN={1077-2626},}
@ARTICLE{5557867,
author={Lentine, M. and Gretarsson, J.T. and Schroeder, C. and Robinson-Mosher, A. and Fedkiw, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Creature Control in a Fluid Environment},
year={2011},
month={May},
volume={17},
number={5},
pages={682-693},
abstract={In this paper, we propose a method designed to allow creatures to actively respond to a fluid environment. We explore various objective functions in order to determine ways to direct the behavior of our creatures. Our proposed method works in conjunction with generalized body forces as well as both one-way and two-way coupled fluid forces. As one might imagine, interesting behaviors can be derived from minimizing and maximizing both drag and lift as well as minimizing the effort that a creature's internal actuators exert. A major application for our work is the automatic specification of secondary motions, for example, certain joints can be animated, while others are automatically solved for in order to satisfy the objective function.},
keywords={computer animation;drag reduction;creature control;fluid environment;one-way coupled fluid force;two-way coupled fluid force;Mathematical model;Navier-Stokes equations;Steady-state;Computer graphics;animation;creatures;fluids.;motion control},
doi={10.1109/TVCG.2010.108},
ISSN={1077-2626},}
@ARTICLE{5710858,
author={Orbay, G. and Kara, L.B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Beautification of Design Sketches Using Trainable Stroke Clustering and Curve Fitting},
year={2011},
month={May},
volume={17},
number={5},
pages={694-708},
abstract={We propose a new sketch parsing and beautification method that converts digitally created design sketches into beautified line drawings. Our system uses a trainable, sequential bottom-up and top-down stroke clustering method that learns how to parse input pen strokes into groups of strokes each representing a single curve, followed by point-cloud ordering that facilitates curve fitting and smoothing. This approach enables greater conceptual freedom during visual ideation activities by allowing designers to develop their sketches using multiple, casually drawn strokes without requiring them to indicate the separation between different stroke groups. With the proposed method, raw sketches are seamlessly converted into vectorized geometric models, thus, facilitating downstream assessment and editing activities.},
keywords={computer graphics;curve fitting;pattern clustering;beautification;curve fitting;design sketches;line drawings;point-cloud ordering;sketch parsing;smoothing;trainable stroke clustering;vectorized geometric models;visual ideation activities;Artificial neural networks;Bifurcation;Curve fitting;Feature extraction;Shape;Smoothing methods;Training;Laplacian Eigenmaps;Sketch-based design;conceptual design;curve fitting.;sketch beautification;sketch parsing;supervised stroke clustering},
doi={10.1109/TVCG.2010.105},
ISSN={1077-2626},}
@ARTICLE{5730198,
author={Nagaraj, Suthambhara and Natarajan, V.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Errata to "Relation-Aware Isosurface Extraction in Multifield Data"},
year={2011},
month={May},
volume={17},
number={5},
pages={709-710},
abstract={},
doi={10.1109/TVCG.2011.63},
ISSN={1077-2626},}
@ARTICLE{5557871,
author={Merrell, P. and Manocha, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Model Synthesis: A General Procedural Modeling Algorithm},
year={2011},
month={June},
volume={17},
number={6},
pages={715-728},
abstract={We present a method for procedurally modeling general complex 3D shapes. Our approach can automatically generate complex models of buildings, man-made structures, or urban data sets in a few minutes based on user-defined inputs. The algorithm attempts to generate complex 3D models that resemble a user-defined input model and satisfy various dimensional, geometric, and algebraic constraints to control the shape. These constraints are used to capture the intent of the user and generate shapes that look more natural. We also describe efficient techniques to handle complex shapes and highlight its performance on many different types of models. We compare model synthesis algorithms with other procedural modeling techniques, discuss the advantages of different approaches, and describe as close connection between model synthesis and context-sensitive grammars.},
keywords={solid modelling;user interfaces;3D shape modeling;algebraic constraint;context-sensitive grammars;dimensional constraint;geometric constraint;model synthesis;procedural modeling algorithm;user-defined input model;Buildings;Computational modeling;Grammar;Roads;Shape;Solid modeling;Three dimensional displays;Model synthesis;procedural modeling.},
doi={10.1109/TVCG.2010.112},
ISSN={1077-2626},}
@ARTICLE{5721975,
author={Krishnamurthy, A. and McMains, S. and Haller, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-Accelerated Minimum Distance and Clearance Queries},
year={2011},
month={June},
volume={17},
number={6},
pages={729-742},
abstract={We present practical algorithms for accelerating distance queries on models made of trimmed NURBS surfaces using programmable Graphics Processing Units (GPUs). We provide a generalized framework for using GPUs as coprocessors in accelerating CAD operations. By supplementing surface data with a surface bounding-box hierarchy on the GPU, we answer distance queries such as finding the closest point on a curved NURBS surface given any point in space and evaluating the clearance between two solid models constructed using multiple NURBS surfaces. We simultaneously output the parameter values corresponding to the solution of these queries along with the model space values. Though our algorithms make use of the programmable fragment processor, the accuracy is based on the model space precision, unlike earlier graphics algorithms that were based only on image space precision. In addition, we provide theoretical bounds for both the computed minimum distance values as well as the location of the closest point. Our algorithms are at least an order of magnitude faster and about two orders of magnitude more accurate than the commercial solid modeling kernel ACIS.},
keywords={CAD;computational geometry;computer graphic equipment;coprocessors;mechanical engineering computing;query processing;solid modelling;splines (mathematics);ACIS solid modeling kernel;CAD operations;GPU-accelerated minimum clearance queries;GPU-accelerated minimum distance queries;coprocessors;graphics algorithms;image space precision;model space precision;nonuniform rational B-spline;programmable fragment processor;programmable graphics processing units;solid models;surface bounding-box hierarchy;trimmed NURBS surfaces;Acceleration;Computational modeling;Graphics processing unit;Solid modeling;Spline;Surface reconstruction;Surface topography;GPU;Minimum distance;NURBS;clearance analysis;closest point;hybrid CPU/GPU algorithms.},
doi={10.1109/TVCG.2010.114},
ISSN={1077-2626},}
@ARTICLE{5669298,
author={Mérigot, Q. and Ovsjanikov, M. and Guibas, L.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Voronoi-Based Curvature and Feature Estimation from Point Clouds},
year={2011},
month={June},
volume={17},
number={6},
pages={743-756},
abstract={We present an efficient and robust method for extracting curvature information, sharp features, and normal directions of a piecewise smooth surface from its point cloud sampling in a unified framework. Our method is integral in nature and uses convolved covariance matrices of Voronoi cells of the point cloud which makes it provably robust in the presence of noise. We show that these matrices contain information related to curvature in the smooth parts of the surface, and information about the directions and angles of sharp edges around the features of a piecewise-smooth surface. Our method is applicable in both two and three dimensions, and can be easily parallelized, making it possible to process arbitrarily large point clouds, which was a challenge for Voronoi-based methods. In addition, we describe a Monte-Carlo version of our method, which is applicable in any dimension. We illustrate the correctness of both principal curvature information and feature extraction in the presence of varying levels of noise and sampling density on a variety of models. As a sample application, we use our feature detection method to segment point cloud samplings of piecewise-smooth surfaces.},
keywords={Monte Carlo methods;computational geometry;covariance matrices;curve fitting;feature extraction;Monte Carlo method;Voronoi cells;Voronoi-based curvature estimation;Voronoi-based feature estimation;convolved covariance matrices;feature detection method;feature extraction;piecewise smooth surface;point cloud sampling;point cloud sampling segmentation;Approximation methods;Clouds;Covariance matrix;Estimation;Feature extraction;Noise;Shape;Computational geometry;object modeling.},
doi={10.1109/TVCG.2010.261},
ISSN={1077-2626},}
@ARTICLE{5557873,
author={Whited, B. and Rossignac, Jarek},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Ball-Morph: Definition, Implementation, and Comparative Evaluation},
year={2011},
month={June},
volume={17},
number={6},
pages={757-769},
abstract={We define b-compatibility for planar curves and propose three ball morphing techniques between pairs of b-compatible curves. Ball-morphs use the automatic ball-map correspondence, proposed by Chazal et al. [1], from which we derive different vertex trajectories (linear, circular, and parabolic). All three morphs are symmetric, meeting both curves with the same angle, which is a right angle for the circular and parabolic. We provide simple constructions for these ball-morphs and compare them to each other and other simple morphs (linear-interpolation, closest-projection, curvature-interpolation, Laplace-blending, and heat-propagation) using six cost measures (travel-distance, distortion, stretch, local acceleration, average squared mean curvature, and maximum squared mean curvature). The results depend heavily on the input curves. Nevertheless, we found that the linear ball-morph has consistently the shortest travel-distance and the circular ball-morph has the least amount of distortion.},
keywords={computational geometry;computer animation;mean square error methods;Ball-Morph;Laplace-blending;average squared mean curvature;b-compatible planar curves;ball morphing techniques;closest-projection;curvature-interpolation;maximum squared mean curvature;travel-distance;Animation;Benchmark testing;Construction industry;Heating;Interpolation;Shape;Trajectory;Morphing;ball-map.;curve averaging;curve interpolation;medial axis;surface reconstruction from slices},
doi={10.1109/TVCG.2010.115},
ISSN={1077-2626},}
@ARTICLE{5487517,
author={Weinkauf, T. and Theisel, H. and Van Gelder, A. and Pang, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Stable Feature Flow Fields},
year={2011},
month={June},
volume={17},
number={6},
pages={770-780},
abstract={Feature Flow Fields are a well-accepted approach for extracting and tracking features. In particular, they are often used to track critical points in time-dependent vector fields and to extract and track vortex core lines. The general idea is to extract the feature or its temporal evolution using a stream line integration in a derived vector field-the so-called Feature Flow Field (FFF). Hence, the desired feature line is a stream line of the FFF. As we will carefully analyze in this paper, the stream lines around this feature line may diverge from it. This creates an unstable situation: if the integration moves slightly off the feature line due to numerical errors, then it will be captured by the diverging neighborhood and carried away from the real feature line. The goal of this paper is to define a new FFF with the guarantee that the neighborhood of a feature line has always converging behavior. This way, we have an automatic correction of numerical errors: if the integration moves slightly off the feature line, it automatically moves back to it during the ongoing integration. This yields results which are an order of magnitude more accurate than the results from previous schemes. We present new stable FFF formulations for the main applications of tracking critical points and solving the Parallel Vectors operator. We apply our method to a number of data sets.},
keywords={computer graphics;feature extraction;flow visualisation;mechanical engineering computing;vortices;feature extraction;feature flow fields;feature tracking;flow field stability;parallel vectors operator;stream line integration;temporal evolution;time-dependent vector fields;vortex core lines;Bifurcation;Computer errors;Concrete;Data mining;Error correction;Feature extraction;Field-flow fractionation;Tensile stress;Flow visualization;feature extraction.},
doi={10.1109/TVCG.2010.93},
ISSN={1077-2626},}
@ARTICLE{5557866,
author={Hlawatsch, M. and Vollrath, J.E. and Sadlo, F. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Coherent Structures of Characteristic Curves in Symmetric Second Order Tensor Fields},
year={2011},
month={June},
volume={17},
number={6},
pages={781-794},
abstract={This paper generalizes the concept of Lagrangian coherent structures, which is known for its potential to visualize coherent regions in vector fields and to distinguish them from each other. In particular, we extend the concept of the flow map to generic mappings of coordinates. As the major application of this generalization, we present a semiglobal method for visualizing coherent structures in symmetric second order tensor fields. We demonstrate the usefulness by examples from DT-MRI, uncovering anatomical structures in linearly anisotropic regions not amenable to local feature criteria. To further exemplify the suitability of our concept, we also present its application to stress tensor fields. Last, an accelerated implementation utilizing GPUs is presented.},
keywords={biomedical MRI;computational geometry;data visualisation;tensors;DT-MRI;GPU;Lagrangian coherent structures;anatomical structures;characteristic curves;coherent structure visualization;diffusion tensor magnetic resonance imaging;flow map;linearly anisotropic regions;stress tensor fields;symmetric second order tensor fields;tensor field visualization;Anisotropic magnetoresistance;Diffusion tensor imaging;Eigenvalues and eigenfunctions;Feature extraction;Tensile stress;Visualization;Lagrangian coherent structures;feature extraction;general-purpose computation using graphics hardware.;tensor field topology;tensor field visualization},
doi={10.1109/TVCG.2010.107},
ISSN={1077-2626},}
@ARTICLE{5487518,
author={Elmqvist, N. and Dragicevic, P. and Fekete, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Color Lens: Adaptive Color Scale Optimization for Visual Exploration},
year={2011},
month={June},
volume={17},
number={6},
pages={795-807},
abstract={Visualization applications routinely map quantitative attributes to color using color scales. Although color is an effective visualization channel, it is limited by both display hardware and the human visual system. We propose a new interaction technique that overcomes these limitations by dynamically optimizing color scales based on a set of sampling lenses. The technique inspects the lens contents in data space, optimizes the initial color scale, and then renders the contents of the lens to the screen using the modified color scale. We present two prototype implementations of this pipeline and describe several case studies involving both information visualization and image inspection applications. We validate our approach with two mutually linked and complementary user studies comparing the Color Lens with explicit contrast control for visual search.},
keywords={data visualisation;image colour analysis;optimisation;rendering (computer graphics);adaptive color scale optimization;color lens;data space;image inspection applications;information visualization;lens content rendering;visual exploration;Data visualization;Displays;Hardware;Humans;Image sampling;Lenses;Pipelines;Prototypes;Rendering (computer graphics);Visual system;Color scales;Magic Lens.;interaction technique;visualization},
doi={10.1109/TVCG.2010.94},
ISSN={1077-2626},}
@ARTICLE{5473224,
author={Clarke, L. and Chen, M. and Mora, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Automatic Generation of 3D Caricatures Based on Artistic Deformation Styles},
year={2011},
month={June},
volume={17},
number={6},
pages={808-821},
abstract={Caricatures are a form of humorous visual art, usually created by skilled artists for the intention of amusement and entertainment. In this paper, we present a novel approach for automatic generation of digital caricatures from facial photographs, which capture artistic deformation styles from hand-drawn caricatures. We introduced a pseudo stress-strain model to encode the parameters of an artistic deformation style using “virtual” physical and material properties. We have also developed a software system for performing the caricaturistic deformation in 3D which eliminates the undesirable artifacts in 2D caricaturization. We employed a Multilevel Free-Form Deformation (MFFD) technique to optimize a 3D head model reconstructed from an input facial photograph, and for controlling the caricaturistic deformation. Our results demonstrated the effectiveness and usability of the proposed approach, which allows ordinary users to apply the captured and stored deformation styles to a variety of facial photographs.},
keywords={art;solid modelling;3D caricature generation;3D head model;artistic deformation style;digital caricature generation;facial photographs;humorous visual art;multilevel free-form deformation technique;pseudostress-strain model;Art;Computer graphics;Deformable models;Head;Image reconstruction;Internet;Material properties;Rendering (computer graphics);Software systems;Usability;Computer-generated imagery;caricature art;caricaturization;example-based deformation;nonphotorealistic rendering;pseudo stress-strain model;sketch-based modeling.},
doi={10.1109/TVCG.2010.76},
ISSN={1077-2626},}
@ARTICLE{5487516,
author={Zhang, N. and Huamin Qu and Sweet, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Orientation-Preserving Rod Elements for Real-Time Thin-Shell Simulation},
year={2011},
month={June},
volume={17},
number={6},
pages={822-835},
abstract={We propose a new computation model for simulating elastic thin shells at interactive rates. Existing graphical simulation methods are mostly based on dihedral angle energy functions, which need to compute the first order and second order partial derivatives with respect to current vertex positions as bending forces and stiffness matrices. The symbolic derivatives are complicated in nonisometric element deformations. To simplify computing the derivatives, instead of directly constructing the dihedral angle energy, we use the orientation change energy of mesh edges. A continuum-mechanics-based orientation-preserving rod element model is developed to provide the bending forces. The advantage of our method is simple bending force and stiffness matrix computation, since in the rod model, we apply a novel incremental construction of the deformation gradient tensor to linearize both tensile and orientation deformations. Consequently, our model is efficient, easy to implement, and supports both quadrilateral and triangle meshes. It also treats shells and plates uniformly.},
keywords={bending;computer graphics;elastic constants;plates (structures);rods (structures);shells (structures);structural engineering computing;bending force;continuum mechanics;deformation gradient tensor;dihedral angle energy functions;graphical simulation methods;mesh edge energy;nonisometric element deformation;orientation-preserving rod element;plates;quadrilateral mesh;stiffness matrix;thin-shell simulation;triangle mesh;Animation;Application software;Computational geometry;Computational modeling;Computer graphics;Computer simulation;Deformable models;Solid modeling;Springs;Tensile stress;Physically based modeling;bending energy;orientation preserving.;rod element;thin-shell simulation},
doi={10.1109/TVCG.2010.92},
ISSN={1077-2626},}
@ARTICLE{5539758,
author={Wang, Charlie C L},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Approximate Boolean Operations on Large Polyhedral Solids with Partial Mesh Reconstruction},
year={2011},
month={June},
volume={17},
number={6},
pages={836-849},
abstract={We present a new approach to compute the approximate Boolean operations of two freeform polygonal mesh solids efficiently with the help of Layered Depth Images (LDIs). After applying the LDI sampling-based membership classification, the most challenging part, a trimmed adaptive contouring algorithm, is developed to reconstruct the mesh surface from the LDI samples near the intersected regions and stitch it to the boundary of the retained surfaces. Our method of approximate Boolean operations holds the advantage of numerical robustness as the approach uses volumetric representation. However, unlike other methods based on volumetric representation, we do not damage the facets in nonintersected regions, thus preserving geometric details much better and speeding up the computation as well. We show that the proposed method can successfully compute the Boolean operations of free-form solids with a massive number of polygons in a few seconds.},
keywords={Boolean algebra;approximation theory;mesh generation;pattern classification;Boolean operation approximation;LDI sampling-based membership classification;freeform polygonal mesh solids;large polyhedral solids;layered depth images;partial mesh reconstruction;trimmed adaptive contouring algorithm;volumetric representation;Arithmetic;Geometry;Image reconstruction;Image sampling;Robustness;Shape;Solid modeling;Surface reconstruction;Topology;Boolean operations;Layered Depth Images.;approximation;free-form solids;robust},
doi={10.1109/TVCG.2010.106},
ISSN={1077-2626},}
@ARTICLE{5487519,
author={Southern, R. and Zhang, J.J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Motion-Sensitive Anchor Identification of Least-Squares Meshes from Examples},
year={2011},
month={June},
volume={17},
number={6},
pages={850-856},
abstract={A least-squares mesh is a surface representation consisting of a small set of anchor points and the differential and topological properties of the surface. In this paper, we present a novel method to identify motion-sensitive anchor points for least-squares meshes from a set of examples. We present a new method, called clustered teleconnection analysis, to identify the maximally excited points in a subset of basis vectors deduced using principal component analysis. We demonstrate by means of examples that our approach has a smaller reconstruction error and equivalent performance to the current best approaches.},
keywords={computational geometry;computer graphics;image representation;least squares approximations;mesh generation;pattern clustering;principal component analysis;reverse engineering;basis vectors;clustered teleconnection analysis;clustering methods;computer graphics research;deformable model reverse engineering;geometric modeling;least-squares meshes;motion-sensitive anchor points identification;principal component analysis;scene analysis;statistical models;surface representation;Animation;Clustering methods;Computer errors;Computer graphics;Deformable models;Image analysis;Joints;Laplace equations;Laser modes;Reverse engineering;Geometric modeling;clustering methods.;scene analysis;statistical models},
doi={10.1109/TVCG.2010.95},
ISSN={1077-2626},}
@ARTICLE{5539757,
author={Bimber, O. and Kloeck, D. and Amano, T. and Grundhoefer, A. and Kurz, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Closed-Loop Feedback Illumination for Optical Inverse Tone-Mapping in Light Microscopy},
year={2011},
month={June},
volume={17},
number={6},
pages={857-870},
abstract={In this paper, we show that optical inverse tone-mapping (OITM) in light microscopy can improve the visibility of specimens, both when observed directly through the oculars and when imaged with a camera. In contrast to previous microscopy techniques, we premodulate the illumination based on the local modulation properties of the specimen itself. We explain how the modulation of uniform white light by a specimen can be estimated in real time, even though the specimen is continuously but not uniformly illuminated. This information is processed and back-projected constantly, allowing the illumination to be adjusted on the fly if the specimen is moved or the focus or magnification of the microscope is changed. The contrast of the specimen's optical image can be enhanced, and high-intensity highlights can be suppressed. A formal pilot study with users indicates that this optimizes the visibility of spatial structures when observed through the oculars. We also demonstrate that the signal-to-noise (S/N) ratio in digital images of the specimen is higher if captured under an optimized rather than a uniform illumination. In contrast to advanced scanning techniques that maximize the S/N ratio using multiple measurements, our approach is fast because it requires only two images. This can improve image analysis in digital microscopy applications with real-time capturing requirements.},
keywords={image enhancement;image processing;lighting;optical computing;optical images;optical microscopy;closed-loop feedback illumination;digital images;digital microscopy application;image analysis;light microscopy;local modulation property;optical image enhancement;optical inverse tone-mapping;signal-to-noise ratio;uniform white light modulation;Biomedical optical imaging;Cameras;Fluorescence;Interference;Lighting;Optical feedback;Optical microscopy;Optical modulation;Optical recording;Optical refraction;Computer graphics;display algorithms;enhancement.;image processing;picture/image generation},
doi={10.1109/TVCG.2010.104},
ISSN={1077-2626},}
@ARTICLE{5620903,
author={Kim, S. and Coffin, Christopher and Hollerer, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Robust Relocalization and Its Evaluation for Online Environment Map Construction},
year={2011},
month={July},
volume={17},
number={7},
pages={875-887},
abstract={The acquisition of surround-view panoramas using a single hand-held or head-worn camera relies on robust real-time camera orientation tracking and relocalization. This paper presents robust methodology and evaluation for camera orientation relocalization, using virtual keyframes for online environment map construction. In the case of tracking loss, incoming camera frames are matched against known-orientation keyframes to re-estimate camera orientation. Instead of solely using real keyframes from incoming video, the proposed approach employs virtual keyframes which are distributed strategically within completed portions of an environment map. To improve tracking speed, we introduce a new variant of our system which carries out relocalization only when tracking fails and uses inexpensive image-patch descriptors. We compare different system variants using three evaluation methods to show that the proposed system is useful in a practical sense. To improve relocalization robustness against lighting changes in indoor and outdoor environments, we propose a new approach based on illumination normalization and saturated area removal. We examine the performance of our solution over several indoor and outdoor video sequences, evaluating relocalization rates based on ground truth from a pan-tilt unit.},
keywords={augmented reality;cartography;image sensors;camera orientation relocalization;camera orientation tracking;hand held camera;head worn camera;image patch descriptors;online environment map construction;pan tilt unit;surround view panoramas;video sequences;virtual keyframes;Cameras;Lighting;Real time systems;Robustness;Three dimensional displays;Tracking;Visualization;Environment map;camera pose relocalization;illumination changes.;virtual keyframe;vision-based tracking},
doi={10.1109/TVCG.2010.243},
ISSN={1077-2626},}
@ARTICLE{5620907,
author={Steinicke, F. and Bruder, G. and Kuhl, S. and Willemsen, P. and Lappe, M. and Hinrichs, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Natural Perspective Projections for Head-Mounted Displays},
year={2011},
month={July},
volume={17},
number={7},
pages={888-899},
abstract={The display units integrated in today's head-mounted displays (HMDs) provide only a limited field of view (FOV) to the virtual world. In order to present an undistorted view to the virtual environment (VE), the perspective projection used to render the VE has to be adjusted to the limitations caused by the HMD characteristics. In particular, the geometric field of view (GFOV), which defines the virtual aperture angle used for rendering of the 3D scene, is set up according to the display field of view (DFOV). A discrepancy between these two fields of view distorts the geometry of the VE in a way that either minifies or magnifies the imagery displayed to the user. It has been shown that this distortion has the potential to affect a user's perception of the virtual space, sense of presence, and performance on visual search tasks. In this paper, we analyze the user's perception of a VE displayed in a HMD, which is rendered with different GFOVs. We introduce a psychophysical calibration method to determine the HMD's actual field of view, which may vary from the nominal values specified by the manufacturer. Furthermore, we conducted two experiments to identify perspective projections for HMDs, which are identified as natural by subjects-even if these perspectives deviate from the perspectives that are inherently defined by the DFOV. In the first experiment, subjects had to adjust the GFOV for a rendered virtual laboratory such that their perception of the virtual replica matched the perception of the real laboratory, which they saw before the virtual one. In the second experiment, we displayed the same virtual laboratory, but restricted the viewing condition in the real world to simulate the limited viewing condition in a HMD environment. We found that subjects evaluate a GFOV as natural when it is larger than the actual DFOV of the HMD-in some cases up to 50 percent-even when subjects viewed the real space with a limited field of view.},
keywords={helmet mounted displays;rendering (computer graphics);virtual reality;3D scene rendering;display field-of-view;geometric field-of-view;head-mounted displays;natural perspective projection;psychophysical calibration method;virtual environment;virtual world;Calibration;Cameras;Electronic mail;Laboratories;Rendering (computer graphics);Three dimensional displays;Visualization;Virtual reality;field of view.;head-mounted displays;Adult;Calibration;Female;Head;Humans;Image Processing, Computer-Assisted;Male;Man-Machine Systems;Middle Aged;Psychophysics;User-Computer Interface;Visual Fields;Visual Perception},
doi={10.1109/TVCG.2010.248},
ISSN={1077-2626},}
@ARTICLE{5557872,
author={Mori, H. and Sumiya, E. and Mashita, T. and Kiyokawa, K. and Takemura, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Wide-View Parallax-Free Eye-Mark Recorder with a Hyperboloidal Half-Silvered Mirror and Appearance-Based Gaze Estimation},
year={2011},
month={July},
volume={17},
number={7},
pages={900-912},
abstract={In this paper, we propose a wide-view parallax-free eye-mark recorder with a hyperboloidal half-silvered mirror and a gaze estimation method suitable for the device. Our eye-mark recorder provides a wide field-of-view video recording of the user's exact view by positioning the focal point of the mirror at the user's viewpoint. The vertical angle of view of the prototype is 122 degree (elevation and depression angles are 38 and 84 degree, respectively) and its horizontal view angle is 116 degree (nasal and temporal view angles are 38 and 78 degree, respectively). We implemented and evaluated a gaze estimation method for our eye-mark recorder. We use an appearance-based approach for our eye-mark recorder to support a wide field-of-view. We apply principal component analysis (PCA) and multiple regression analysis (MRA) to determine the relationship between the captured images and their corresponding gaze points. Experimental results verify that our eye-mark recorder successfully captures a wide field-of-view of a user and estimates gaze direction with an angular accuracy of around 2 to 4 degree.},
keywords={image processing;mirrors;principal component analysis;recorders;regression analysis;appearance-based gaze estimation;hyperboloidal half-silvered mirror;multiple regression analysis;parallax-free eye-mark recorder;principal component analysis;video recording;Cameras;Erbium;Estimation;Lenses;Mirrors;Optical imaging;Strontium;Eye-mark recorder;gaze estimation;half-silvered hyperboloidal mirror;head-mounted camera.;parallax free;wide field-of-view},
doi={10.1109/TVCG.2010.113},
ISSN={1077-2626},}
@ARTICLE{5557869,
author={Caserta, P. and Zendra, O.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization of the Static Aspects of Software: A Survey},
year={2011},
month={July},
volume={17},
number={7},
pages={913-933},
abstract={Software is usually complex and always intangible. In practice, the development and maintenance processes are time-consuming activities mainly because software complexity is difficult to manage. Graphical visualization of software has the potential to result in a better and faster understanding of its design and functionality, thus saving time and providing valuable information to improve its quality. However, visualizing software is not an easy task because of the huge amount of information comprised in the software. Furthermore, the information content increases significantly once the time dimension to visualize the evolution of the software is taken into account. Human perception of information and cognitive factors must thus be taken into account to improve the understandability of the visualization. In this paper, we survey visualization techniques, both 2D- and 3D-based, representing the static aspects of the software and its evolution. We categorize these techniques according to the issues they focus on, in order to help compare them and identify the most relevant techniques and tools for a given problem.},
keywords={data visualisation;software maintenance;development processes;graphical visualization;maintenance processes;software complexity;static software aspects;Cities and towns;Color;Measurement;Organizations;Software;Three dimensional displays;Visualization;Visualization of software;human perception.;software comprehension;software maintenance},
doi={10.1109/TVCG.2010.110},
ISSN={1077-2626},}
@ARTICLE{5557870,
author={Kehrer, J. and Muigg, P. and Doleisch, H. and Hauser, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Visual Analysis of Heterogeneous Scientific Data across an Interface},
year={2011},
month={July},
volume={17},
number={7},
pages={934-946},
abstract={We present a systematic approach to the interactive visual analysis of heterogeneous scientific data. The data consist of two interrelated parts given on spatial grids over time (e.g., atmosphere and ocean part from a coupled climate model). By integrating both data parts in a framework of coordinated multiple views (with linking and brushing), the joint investigation of features across the data parts is enabled. An interface is constructed between the data parts that specifies 1) which grid cells in one part are related to grid cells in the other part, and vice versa, 2) how selections (in terms of feature extraction via brushing) are transferred between the two parts, and 3) how an update mechanism keeps the feature specification in both data parts consistent during the analysis. We also propose strategies for visual analysis that result in an iterative refinement of features specified across both data parts. Our approach is demonstrated in the context of a complex simulation of fluid-structure interaction and a multirun climate simulation.},
keywords={data visualisation;grid computing;iterative methods;natural sciences computing;user interfaces;feature specification;fluid structure interaction;grid cells;heterogeneous scientific data;interactive visual analysis;iterative features refinement;multirun climate simulation;spatial grids;Analytical models;Atmospheric modeling;Computational modeling;Data models;Data visualization;Solids;Visualization;Interactive visual analysis;coordinated multiple views.;heterogeneous scientific data},
doi={10.1109/TVCG.2010.111},
ISSN={1077-2626},}
@ARTICLE{5582087,
author={Palacios, J. and Zhang, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Visualization of Rotational Symmetry Fields on Surfaces},
year={2011},
month={July},
volume={17},
number={7},
pages={947-955},
abstract={Rotational symmetries (RoSys) have found uses in several computer graphics applications, such as global surface parameterization, geometry remeshing, texture and geometry synthesis, and nonphotorealistic visualization of surfaces. The visualization of N-way rotational symmetry (N-RoSy) fields is a challenging problem due to the ambiguities in the N directions represented by an N-way symmetry. We provide an algorithm that allows faithful and interactive representation of N-RoSy fields in the plane and on surfaces, by adapting the well-known line integral convolution (LIC) technique from vector and second-order tensor fields. Our algorithm captures N directions associated with each point in a given field by decomposing the field into multiple different vector fields, generating LIC images of these fields, and then blending the results. To address the loss of contrast caused by the blending of images, we observe that the pixel values in LIC images closely approximate normally distributed random variables. This allows us to use concepts from probability theory to correct the loss of contrast without the need to perform any image analysis at each frame.},
keywords={computational geometry;data visualisation;image texture;probability;tensors;N-way rotational symmetry fields;computer graphics applications;geometry remeshing;geometry synthesis;global surface parameterization;image analysis;interactive representation;interactive visualization;line integral convolution technique;nonphotorealistic surface visualization;probability theory;rotational symmetry fields;second order tensor fields;texture synthesis;vector tensor fields;Image color analysis;Noise;Pipelines;Pixel;Tensile stress;Trajectory;Visualization;RoSy;Rotational symmetry;contrast adjustment.;image blending;tensor field visualization;visualization},
doi={10.1109/TVCG.2010.121},
ISSN={1077-2626},}
@ARTICLE{5582083,
author={Arbree, A. and Walter, B. and Bala, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Heterogeneous Subsurface Scattering Using the Finite Element Method},
year={2011},
month={July},
volume={17},
number={7},
pages={956-969},
abstract={Materials with visually important heterogeneous subsurface scattering, including marble, skin, leaves, and minerals are common in the real world. However, general, accurate, and efficient rendering of these materials is an open problem. In this paper, we describe a finite element (FE) solution of the heterogeneous diffusion equation (DE) that solves this problem. Our algorithm is the first to use the FE method to solve the difficult problem of heterogeneous subsurface rendering. To create our algorithm, we make two contributions. First, we correct previous work and derive an accurate and complete heterogeneous diffusion formulation with two key elements: the diffusive source boundary condition (DSBC)-an accurate model of the reduced intensity (RI) source-and its associated render query function. Second, we solve this formulation accurately and efficiently using the FE method. With these contributions, we can render subsurface scattering with a simple four step algorithm. To demonstrate that our algorithm is simultaneously general, accurate, and efficient, we test its performance on a series of difficult scenes. For a wide range of materials and geometry, it produces, in minutes, images that match path traced references, that required hours.},
keywords={finite element analysis;rendering (computer graphics);diffusive source boundary condition;finite element method;heterogeneous diffusion equation;heterogeneous subsurface rendering;heterogeneous subsurface scattering;reduced intensity source;render query function;Approximation algorithms;Approximation methods;Equations;Materials;Mathematical model;Rendering (computer graphics);Scattering;Three-dimensional graphics and realism;color;finite element methods.;miscellaneous;partial differential equations;shading;shadowing;subsurface scattering;texture},
doi={10.1109/TVCG.2010.117},
ISSN={1077-2626},}
@ARTICLE{5601814,
author={Servin, M. and Lacoursière, C. and Nordfelth, F. and Bodin, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Hybrid, Multiresolution Wires with Massless Frictional Contacts},
year={2011},
month={July},
volume={17},
number={7},
pages={970-982},
abstract={We describe a method for the visual interactive simulation of wires contacting with rigid multibodies. The physical model used is a hybrid combining lumped elements and massless quasistatic representations. The latter is based on a kinematic constraint preserving the total length of the wire along a segmented path which can involve multiple bodies simultaneously and dry frictional contact nodes used for roping, lassoing, and fastening. These nodes provide stick and slide friction along the edges of the contacting geometries. The lumped element resolution is adapted dynamically based on local stability criteria, becoming coarser as the tension increases, and up to the purely kinematic representation. Kinematic segments and contact nodes are added, deleted, and propagated based on contact geometries and dry friction configurations. The method gives a dramatic increase in both performance and robustness because it quickly decimates superfluous nodes without loosing stability, yet adapts to complex configurations with many contacts and high curvature, keeping a fixed, large integration time step. Numerical results demonstrating the performance and stability of the adaptive multiresolution scheme are presented along with an array of representative simulation examples illustrating the versatility of the frictional contact model.},
keywords={computer animation;friction;mechanical contact;mechanical engineering computing;wires;dry frictional contact nodes;frictional contact model;hybrid multiresolution wires;kinematic constraint representation;lumped element resolution;massless frictional contacts;massless quasistatic representations;stick friction;wires visual interactive simulation;Adaptation model;Computational modeling;Geometry;Numerical models;Visualization;Wires;Computer graphics;adaptive resolution;animation;dry frictional contacts.;graphics and realism;physics simulation;strands;three-dimensional;virtual reality;wires},
doi={10.1109/TVCG.2010.122},
ISSN={1077-2626},}
@ARTICLE{5557868,
author={Jin Huang and Yiying Tong and Kun Zhou and Hujun Bao and Desbrun, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Shape Interpolation through Controllable Dynamic Deformation},
year={2011},
month={July},
volume={17},
number={7},
pages={983-992},
abstract={In this paper, we introduce an interactive approach to generate physically based shape interpolation between poses. We extend linear modal analysis to offer an efficient and robust numerical technique to generate physically-plausible dynamics even for very large deformation. Our method also provides a rich set of intuitive editing tools with real-time feedback, including control over vibration frequencies, amplitudes, and damping of the resulting interpolation sequence. We demonstrate the versatility of our approach through a series of complex dynamic shape interpolations.},
keywords={computer animation;interpolation;controllable dynamic deformation;interactive shape interpolation;linear modal analysis;physically-plausible dynamics;Damping;Interpolation;Matrix decomposition;Modal analysis;Shape;Strain;Vibrations;Deformation gradient;modal analysis.;shape interpolation;space-time constraints},
doi={10.1109/TVCG.2010.109},
ISSN={1077-2626},}
@ARTICLE{5582084,
author={Long Zhang and Ying He and Jiazhi Xia and Xuexiang Xie and Wei Chen},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Real-Time Shape Illustration Using Laplacian Lines},
year={2011},
month={July},
volume={17},
number={7},
pages={993-1006},
abstract={This paper presents a novel object-space line drawing algorithm that can depict shapes with view-dependent feature lines in real time. Strongly inspired by the Laplacian-of-Gaussian (LoG) edge detector in image processing, we define Laplacian lines as the zero-crossing points of the Laplacian of the surface illumination. Compared to other view-dependent feature lines, Laplacian lines are computationally efficient because most expensive computations can be preprocessed. We further extend Laplacian lines to volumetric data and develop the algorithm to compute volumetric Laplacian lines without isosurface extraction. We apply the proposed Laplacian lines to a wide range of real-world models and demonstrate that Laplacian lines are more efficient than the existing computer generated feature lines, and can be used in interactive graphics applications.},
keywords={Laplace equations;edge detection;lighting;solid modelling;Laplacian lines;Laplacian-of-Gaussian edge detector;image processing;interactive graphics applications;object space line drawing algorithm;real time shape illustration;surface illumination;view dependent feature lines;zero crossing points;Detectors;Feature extraction;Image edge detection;Laplace equations;Lighting;Shape;Three dimensional displays;Laplacian lines;Nonphotorealistic rendering;object-space line extraction;real-time line drawing;view-dependent feature line;volume illustration.},
doi={10.1109/TVCG.2010.118},
ISSN={1077-2626},}
@ARTICLE{5487514,
author={Thomas, D.M. and Natarajan, V. and Bonneau, G.-P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Link Conditions for Simplifying Meshes with Embedded Structures},
year={2011},
month={July},
volume={17},
number={7},
pages={1007-1019},
abstract={Interactive visualization applications benefit from simplification techniques that generate good-quality coarse meshes from high-resolution meshes that represent the domain. These meshes often contain interesting substructures, called embedded structures, and it is desirable to preserve the topology of the embedded structures during simplification, in addition to preserving the topology of the domain. This paper describes a proof that link conditions, proposed earlier, are sufficient to ensure that edge contractions preserve the topology of the embedded structures and the domain. Excluding two specific configurations, the link conditions are also shown to be necessary for topology preservation. Repeated application of edge contraction on an extended complex produces a coarser representation of the domain and the embedded structures. An extension of the quadric error metric is used to schedule edge contractions, resulting in a good-quality coarse mesh that closely approximates the input domain and the embedded structures.},
keywords={data visualisation;mesh generation;coarse mesh;edge contractions;embedded structures;interactive visualization applications;mesh simplification;quadric error metric;Automation;Computer science;Computer science education;Geophysics;Iterative methods;Joining processes;Mesh generation;Supercomputers;Topology;Visualization;Embedded structures;extended complex;link conditions;mesh simplification;quadric error metric.;topology preservation},
doi={10.1109/TVCG.2010.90},
ISSN={1077-2626},}
@ARTICLE{5582085,
author={Stapleton, G. and Leishi Zhang and Howse, John and Rodgers, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Drawing Euler Diagrams with Circles: The Theory of Piercings},
year={2011},
month={July},
volume={17},
number={7},
pages={1020-1032},
abstract={Euler diagrams are effective tools for visualizing set intersections. They have a large number of application areas ranging from statistical data analysis to software engineering. However, the automated generation of Euler diagrams has never been easy: given an abstract description of a required Euler diagram, it is computationally expensive to generate the diagram. Moreover, the generated diagrams represent sets by polygons, sometimes with quite irregular shapes that make the diagrams less comprehensible. In this paper, we address these two issues by developing the theory of piercings, where we define single piercing curves and double piercing curves. We prove that if a diagram can be built inductively by successively adding piercing curves under certain constraints, then it can be drawn with circles, which are more esthetically pleasing than arbitrary polygons. The theory of piercings is developed at the abstract level. In addition, we present a Java implementation that, given an inductively pierced abstract description, generates an Euler diagram consisting only of circles within polynomial time.},
keywords={Java;computational geometry;data visualisation;polynomials;Euler diagrams;Java implementation;arbitrary polygons;circles;double piercing curves;piercings theory;polynomial time;set intersection visualization;single piercing curves;software engineering;statistical data analysis;Layout;Measurement;Ontologies;Polynomials;Shape;Software;Visualization;Automated diagram drawing;Euler diagrams;diagrammatic reasoning;information visualization.},
doi={10.1109/TVCG.2010.119},
ISSN={1077-2626},}
@ARTICLE{5601714,
author={Enderton, E. and Sintorn, E. and Shirley, P. and Luebke, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Stochastic Transparency},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1036-1047},
abstract={Stochastic transparency provides a unified approach to order-independent transparency, antialiasing, and deep shadow maps. It augments screen-door transparency using a random sub-pixel stipple pattern, where each fragment of transparent geometry covers a random subset of pixel samples of size proportional to alpha. This results in correct alpha-blended colors on average, in a single render pass with fixed memory size and no sorting, but introduces noise. We reduce this noise by an alpha correction pass, and by an accumulation pass that uses a stochastic shadow map from the camera. At the pixel level, the algorithm does not branch and contains no read-modify-write loops, other than traditional z-buffer blend operations. This makes it an excellent match for modern massively parallel GPU hardware. Stochastic transparency is very simple to implement and supports all types of transparent geometry, able without coding for special cases to mix hair, smoke, foliage, windows, and transparent cloth in a single scene.},
keywords={computer graphic equipment;coprocessors;rendering (computer graphics);alpha-blended colors;parallel GPU hardware;screen door transparency;stochastic transparency;subpixel stipple pattern;transparent geometry;Color;Equations;Geometry;Hardware;Noise;Pixel;Rendering (computer graphics);Rendering;deep shadow maps;shadow maps;stochastic sampling.;transparency},
doi={10.1109/TVCG.2010.123},
ISSN={1077-2626},}
@ARTICLE{5620900,
author={Laine, S. and Karras, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Efficient Sparse Voxel Octrees},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1048-1059},
abstract={In this paper, we examine the possibilities of using voxel representations as a generic way for expressing complex and feature-rich geometry on current and future GPUs. We present in detail a compact data structure for storing voxels and an efficient algorithm for performing ray casts using this structure. We augment the voxel data with novel contour information that increases geometric resolution, allows more compact encoding of smooth surfaces, and accelerates ray casts. We also employ a novel normal compression format for storing high-precision object-space normals. Finally, we present a variable-radius postprocess filtering technique for smoothing out blockiness caused by discrete sampling of shading attributes. Based on benchmark results, we show that our voxel representation is competitive with triangle-based representations in terms of ray casting performance, while allowing tremendously greater geometric detail and unique shading information for every voxel. Our voxel codebase is open sourced and available at http://code.google.com/p/efficient-sparse-voxel-octrees/.},
keywords={computational geometry;computer graphic equipment;coprocessors;filtering theory;image representation;octrees;ray tracing;GPU;compact data structure;feature-rich geometry;ray cast acceleration;ray tracing;shading attribute discrete sampling;smooth surface compact encoding;sparse voxel octrees;triangle-based representations;variable-radius postprocess filtering technique;voxel representations;Approximation methods;Arrays;Geometry;Graphics processing unit;Image color analysis;Octrees;Rendering (computer graphics);CUDA.;GPU;Voxel;octree;ray tracing;volumetric image representation},
doi={10.1109/TVCG.2010.240},
ISSN={1077-2626},}
@ARTICLE{5710909,
author={Miller, C. and Arikan, O. and Fussell, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Frankenrigs: Building Character Rigs from Multiple Sources},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1060-1070},
abstract={We present a new rigging and skinning method which uses a database of partial rigs extracted from a set of source characters. Given a target mesh and a set of joint locations, our system can automatically scan through the database to find the best-fitting body parts, tailor them to match the target mesh, and transfer their skinning information onto the new character. For the cases where our automatic procedure fails, we provide an intuitive set of tools to fix the problems. When used fully automatically, the system can generate results of much higher quality than a standard smooth bind, and with some user interaction, it can create rigs approaching the quality of artist-created manual rigs in a small fraction of the time.},
keywords={computer animation;database management systems;character rigs;frankenrigs;multiple sources;partial rigs database;rigging method;skinning method;Animation;Bones;Databases;Joints;Painting;Skin;Rigging;character animation.;rig reuse;skinning},
doi={10.1109/TVCG.2011.39},
ISSN={1077-2626},}
@ARTICLE{5669300,
author={Vergne, R. and Pacanowski, R. and Barla, P. and Granier, X. and Shlick, C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Improving Shape Depiction under Arbitrary Rendering},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1071-1081},
abstract={Based on the observation that shading conveys shape information through intensity gradients, we present a new technique called Radiance Scaling that modifies the classical shading equations to offer versatile shape depiction functionalities. It works by scaling reflected light intensities depending on both surface curvature and material characteristics. As a result, diffuse shading or highlight variations become correlated with surface feature variations, enhancing concavities and convexities. The first advantage of such an approach is that it produces satisfying results with any kind of material for direct and global illumination: we demonstrate results obtained with Phong and Ashikmin-Shirley BRDFs, Cartoon shading, sub-Lambertian materials, perfectly reflective or refractive objects. Another advantage is that there is no restriction to the choice of lighting environment: it works with a single light, area lights, and interreflections. Third, it may be adapted to enhance surface shape through the use of precomputed radiance data such as Ambient Occlusion, Prefiltered Environment Maps or Lit Spheres. Finally, our approach works in real time on modern graphics hardware making it suitable for any interactive 3D visualization.},
keywords={rendering (computer graphics);shape recognition;Lit Spheres;arbitrary rendering;intensity gradients;interactive 3D visualization;prefiltered environment maps;radiance scaling;shading equations;shape depiction improvement;surface curvature;Anisotropic magnetoresistance;Light sources;Lighting;Materials;Rendering (computer graphics);Shape;Three dimensional displays;Expressive rendering;NPR;global illumination.;shading;shape depiction},
doi={10.1109/TVCG.2010.252},
ISSN={1077-2626},}
@ARTICLE{5611506,
author={Chenglei Wu and Yebin Liu and Qionghai Dai and Wilburn, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Fusing Multiview and Photometric Stereo for 3D Reconstruction under Uncalibrated Illumination},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1082-1095},
abstract={We propose a method to obtain a complete and accurate 3D model from multiview images captured under a variety of unknown illuminations. Based on recent results showing that for Lambertian objects, general illumination can be approximated well using low-order spherical harmonics, we develop a robust alternating approach to recover surface normals. Surface normals are initialized using a multi-illumination multiview stereo algorithm, then refined using a robust alternating optimization method based on the ℓ1 metric. Erroneous normal estimates are detected using a shape prior. Finally, the computed normals are used to improve the preliminary 3D model. The reconstruction system achieves watertight and robust 3D reconstruction while neither requiring manual interactions nor imposing any constraints on the illumination. Experimental results on both real world and synthetic data show that the technique can acquire accurate 3D models for Lambertian surfaces, and even tolerates small violations of the Lambertian assumption.},
keywords={image reconstruction;stereo image processing;3D reconstruction;Lambertian assumption;Lambertian objects;Lambertian surfaces;photometric stereo;spherical harmonics;uncalibrated illumination;Computational modeling;Harmonic analysis;Image reconstruction;Lighting;Measurement;Surface reconstruction;Three dimensional displays;Lambertian reflectance;Multiview stereo;ell_{1} minimization.;photometric stereo},
doi={10.1109/TVCG.2010.224},
ISSN={1077-2626},}
@ARTICLE{5620898,
author={Lagae, A. and Lefebvre, S. and Dutre, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Improving Gabor Noise},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1096-1107},
abstract={We have recently proposed a new procedural noise function, Gabor noise, which offers a combination of properties not found in the existing noise functions. In this paper, we present three significant improvements to Gabor noise: 1) an isotropic kernel for Gabor noise, which speeds up isotropic Gabor noise with a factor of roughly two, 2) an error analysis of Gabor noise, which relates the kernel truncation radius to the relative error of the noise, and 3) spatially varying Gabor noise, which enables spatial variation of all noise parameters. These improvements make Gabor noise an even more attractive alternative for the existing noise functions.},
keywords={Gabor filters;computer graphics;Gabor noise;isotropic kernel;kernel truncation radius;noise functions;noise parameters;spatial variation;Convolution;Frequency domain analysis;Harmonic analysis;Kernel;Noise;Visualization;Gabor noise;Gabor noise error analysis;Hankel transform;Procedural noise;circular Gabor filter;circularly symmetric functions;isotropic Gabor kernel;sparse convolution noise;spatially varying Gabor noise.},
doi={10.1109/TVCG.2010.238},
ISSN={1077-2626},}
@ARTICLE{5611512,
author={Pajot, A. and Barthe, L. and Paulin, M. and Poulin, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Representativity for Robust and Adaptive Multiple Importance Sampling},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1108-1121},
abstract={We present a general method enhancing the robustness of estimators based on multiple importance sampling (MIS) in a numerical integration context. MIS minimizes variance of estimators for a given sampling configuration, but when this configuration is less adapted to the integrand, the resulting estimator suffers from extra variance. We address this issue by introducing the notion of "representativity” of a sampling strategy, and demonstrate how it can be used to increase robustness of estimators, by adapting them to the integrand. We first show how to compute representativities using common rendering informations such as BSDF, photon maps, or caches in order to choose the best sampling strategy for MIS. We then give hints to generalize our method to any integration problem and demonstrate that it can be used successfully to enhance robustness in different common rendering algorithms.},
keywords={numerical analysis;rendering (computer graphics);MIS;adaptive multiple importance sampling;integration problem;numerical integration context;rendering informations;Estimation;Light sources;Lighting;Monte Carlo methods;Photonics;Rendering (computer graphics);Robustness;Monte-Carlo;three-dimensional graphics and realism.},
doi={10.1109/TVCG.2010.230},
ISSN={1077-2626},}
@ARTICLE{5611508,
author={Chunxia Xiao and Meng Liu and Nie Yongwei and Zhao Dong},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Fast Exact Nearest Patch Matching for Patch-Based Image Editing and Processing},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1122-1134},
abstract={This paper presents an efficient exact nearest patch matching algorithm which can accurately find the most similar patch-pairs between source and target image. Traditional match matching algorithms treat each pixel/patch as an independent sample and build a hierarchical data structure, such as kd-tree, to accelerate nearest patch finding. However, most of these approaches can only find approximate nearest patch and do not explore the sequential overlap between patches. Hence, they are neither accurate in quality nor optimal in speed. By eliminating redundant similarity computation of sequential overlap between patches, our method finds the exact nearest patch in brute-force style but reduces its running time complexity to be linear on the patch size. Furthermore, relying on recent multicore graphics hardware, our method can be further accelerated by at least an order of magnitude (≥ 10 ×). This greatly improves performance and ensures that our method can be efficiently applied in an interactive editing framework for moderate-sized image even video. To our knowledge, this approach is the fastest exact nearest patch matching method for high-dimensional patch and also its extra memory requirement is minimal. Comparisons with the popular nearest patch matching methods in the experimental results demonstrate the merits of our algorithm.},
keywords={data structures;image matching;data structure;fast exact nearest patch matching;match matching algorithms;multicore graphics hardware;patch based image editing;patch based processing;Acceleration;Complexity theory;Force;Graphics processing unit;Memory management;Pixel;Principal component analysis;Nearest patch search;image completion;image denoising;image summarization.;texture synthesis},
doi={10.1109/TVCG.2010.226},
ISSN={1077-2626},}
@ARTICLE{5601716,
author={Chunxia Xiao and Yongwei Nie and Feng Tang},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Efficient Edit Propagation Using Hierarchical Data Structure},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1135-1147},
abstract={This paper presents a novel unified hierarchical structure for scalable edit propagation. Our method is based on the key observation that in edit propagation, appearance varies very smoothly in those regions where the appearance is different from the user-specified pixels. Uniformly sampling in these regions leads to redundant computation. We propose to use a quadtree-based adaptive subdivision method such that more samples are selected in similar regions and less in those that are different from the user-specified regions. As a result, both the computation and the memory requirement are significantly reduced. In edit propagation, an edge-preserving propagation function is first built, and the full solution for all the pixels can be computed by interpolating from the solution obtained from the adaptively subdivided domain. Furthermore, our approach can be easily extended to accelerate video edit propagation using an adaptive octree structure. In order to improve user interaction, we introduce several new Gaussian Mixture Model (GMM) brushes to find pixels that are similar to the user-specified regions. Compared with previous methods, our approach requires significantly less time and memory, while achieving visually same results. Experimental results demonstrate the efficiency and effectiveness of our approach on high-resolution photographs and videos.},
keywords={Gaussian processes;image resolution;tree data structures;trees (mathematics);Gaussian Mixture Model;edge-preserving propagation function;efficient edit propagation;hierarchical data structure;quadtree-based adaptive subdivision method;video edit propagation;Brushes;Data structures;Image edge detection;Image resolution;Linear systems;Memory management;Pixel;Gaussian mixture model;Tone adjustment;hierarchical data structure;high dynamic range imaging;tone mapping.},
doi={10.1109/TVCG.2010.125},
ISSN={1077-2626},}
@ARTICLE{5611509,
author={Hlawatsch, M. and Sadlo, F. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Hierarchical Line Integration},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1148-1163},
abstract={This paper presents an acceleration scheme for the numerical computation of sets of trajectories in vector fields or iterated solutions in maps, possibly with simultaneous evaluation of quantities along the curves such as integrals or extrema. It addresses cases with a dense evaluation on the domain, where straightforward approaches are subject to redundant calculations. These are avoided by first calculating short solutions for the whole domain. From these, longer solutions are then constructed in a hierarchical manner until the designated length is achieved. While the computational complexity of the straightforward approach depends linearly on the length of the solutions, the computational cost with the proposed scheme grows only logarithmically with increasing length. Due to independence of subtasks and memory locality, our algorithm is suitable for parallel execution on many-core architectures like GPUs. The trade-offs of the method - lower accuracy and increased memory consumption - are analyzed, including error order as well as numerical error for discrete computation grids. The usefulness and flexibility of the scheme are demonstrated with two example applications: line integral convolution and the computation of the finite-time Lyapunov exponent. Finally, results and performance measurements of our GPU implementation are presented for both synthetic and simulated vector fields from computational fluid dynamics.},
keywords={computational complexity;computational geometry;iterative methods;GPU;Lyapunov exponent;computational complexity;computational fluid dynamics;hierarchical line integration;iterated solutions;memory consumption;numerical computation;parallel execution;vector fields;Acceleration;Accuracy;Convolution;Interpolation;Kernel;Trajectory;Visualization;FTLE;Flow visualization;GPU.;LIC;hierarchical computation;integral curves},
doi={10.1109/TVCG.2010.227},
ISSN={1077-2626},}
@ARTICLE{5582082,
author={Moloney, B. and Ament, M. and Weiskopf, D. and Moller, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Sort-First Parallel Volume Rendering},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1164-1177},
abstract={Sort-first distributions have been studied and used far less than sort-last distributions for parallel volume rendering, especially when the data are too large to be replicated fully. We demonstrate that sort-first distributions are not only a viable method of performing data-scalable parallel volume rendering, but more importantly they allow for a range of rendering algorithms and techniques that are not efficient with sort-last distributions. Several of these algorithms are discussed and two of them are implemented in a parallel environment: a new improved variant of early ray termination to speed up rendering when volumetric occlusion occurs and a volumetric shadowing technique that produces more realistic and informative images based on half angle slicing. Improved methods of distributing the computation of the load balancing and loading portions of a subdivided data set are also presented. Our detailed test results for a typical GPU cluster with distributed memory show that our sort-first rendering algorithm outperforms sort-last rendering in many scenarios.},
keywords={computer graphic equipment;coprocessors;rendering (computer graphics);GPU cluster;parallel environment;sort first parallel volume rendering;volumetric shadowing technique;Casting;Graphics processing unit;Heuristic algorithms;Load management;Pipelines;Rendering (computer graphics);Shadow mapping;Volume rendering;dynamic load balancing;early ray termination;ray coherence.;shadow;sort-first parallelization;visualization},
doi={10.1109/TVCG.2010.116},
ISSN={1077-2626},}
@ARTICLE{5601715,
author={I-Cheng Yeh and Chao-Hung Lin and Sorkine, O. and Tong-Yee Lee},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Template-Based 3D Model Fitting Using Dual-Domain Relaxation},
year={2011},
month={Aug},
volume={17},
number={8},
pages={1178-1190},
abstract={We introduce a template fitting method for 3D surface meshes. A given template mesh is deformed to closely approximate the input 3D geometry. The connectivity of the deformed template model is automatically adjusted to facilitate the geometric fitting and to ascertain high quality of the mesh elements. The template fitting process utilizes a specially tailored Laplacian processing framework, where in the first, coarse fitting stage we approximate the input geometry with a linearized biharmonic surface (a variant of LS-mesh), and then the fine geometric detail is fitted further using iterative Laplacian editing with reliable correspondence constraints and a local surface flattening mechanism to avoid foldovers. The latter step is performed in the dual mesh domain, which is shown to encourage near-equilateral mesh elements and significantly reduces the occurrence of triangle foldovers, a well-known problem in mesh fitting. To experimentally evaluate our approach, we compare our method with relevant state-of-the-art techniques and confirm significant improvements of results. In addition, we demonstrate the usefulness of our approach to the application of consistent surface parameterization (also known as cross-parameterization).},
keywords={Laplace equations;computer graphics;mesh generation;3D geometry;3D surface meshes;Laplacian editing;Laplacian processing framework;dual-domain relaxation;template based 3D model fitting;Approximation methods;Computational modeling;Geometry;Laplace equations;Shape;Surface reconstruction;Surface treatment;Laplacian coordinates;Template-based fitting;consistent parameterization;cross-parameterization;dual mesh;intersurface mapping.;local surface flattening},
doi={10.1109/TVCG.2010.124},
ISSN={1077-2626},}
@ARTICLE{5710906,
author={Moehring, M. and Froehlich, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Natural Interaction Metaphors for Functional Validations of Virtual Car Models},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1195-1208},
abstract={Natural Interaction in virtual environments is a key requirement for the virtual validation of functional aspects in automotive product development processes. Natural Interaction is the metaphor people encounter in reality: the direct manipulation of objects by their hands. To enable this kind of Natural Interaction, we propose a pseudophysical metaphor that is both plausible enough to provide realistic interaction and robust enough to meet the needs of industrial applications. Our analysis of the most common types of objects in typical automotive scenarios guided the development of a set of refined grasping heuristics to support robust finger-based interaction of multiple hands and users. The objects' behavior in reaction to the users' finger motions is based on pseudophysical simulations, which also take various types of constrained objects into account. In dealing with real-world scenarios, we had to introduce the concept of Normal Proxies, which extend objects with appropriate normals for improved grasp detection and grasp stability. An expert review revealed that our interaction metaphors allow for an intuitive and reliable assessment of several functionalities of objects found in a car interior. Follow-up user studies showed that overall task performance and usability are similar for CAVE and HMD environments. For larger objects and more gross manipulation, using the CAVE without employing a virtual hand representation is preferred, but for more fine-grained manipulation and smaller objects, the HMD turns out to be beneficial.},
keywords={automotive components;automotive engineering;mechanical engineering computing;product development;virtual reality;CAVE;HMD;automotive product development processes;car interior;direct object manipulation;finger-based interaction;functional validations;multiple hands;natural interaction metaphors;normal proxies;object behavior;pseudophysical simulations;refined grasping heuristics;virtual car models;virtual hand representation;Computer graphics;Three dimensional displays;User interfaces;3D graphics and realism;User interfaces;input/output devices;systems and software.},
doi={10.1109/TVCG.2011.36},
ISSN={1077-2626},}
@ARTICLE{5710903,
author={Sajadi, B. and Majumder, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Autocalibrating Tiled Projectors on Piecewise Smooth Vertically Extruded Surfaces},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1209-1222},
abstract={In this paper, we present a novel technique to calibrate multiple casually aligned projectors on fiducial-free piecewise smooth vertically extruded surfaces using a single camera. Such surfaces include cylindrical displays and CAVEs, common in immersive virtual reality systems. We impose two priors to the display surface. We assume the surface is a piecewise smooth vertically extruded surface for which the aspect ratio of the rectangle formed by the four corners of the surface is known and the boundary is visible and segmentable. Using these priors, we can estimate the display's 3D geometry and camera extrinsic parameters using a nonlinear optimization technique from a single image without any explicit display to camera correspondences. Using the estimated camera and display properties, the intrinsic and extrinsic parameters of each projector are recovered using a single projected pattern seen by the camera. This in turn is used to register the images on the display from any arbitrary viewpoint making it appropriate for virtual reality systems. The fast convergence and robustness of this method is achieved via a novel dimension reduction technique for camera parameter estimation and a novel deterministic technique for projector property estimation. This simplicity, efficiency, and robustness of our method enable several coveted features for nonplanar projection-based displays. First, it allows fast recalibration in the face of projector, display or camera movements and even change in display shape. Second, this opens up, for the first time, the possibility of allowing multiple projectors to overlap on the corners of the CAVE-a popular immersive VR display system. Finally, this opens up the possibility of easily deploying multiprojector displays on aesthetic novel shapes for edutainment and digital signage applications},
keywords={cameras;geometry;image registration;image segmentation;optimisation;parameter estimation;solid modelling;three-dimensional displays;virtual reality;3D geometry;CAVE;VR display system;camera extrinsic parameters;camera parameter estimation;cylindrical displays;digital signage applications;dimension reduction technique;edutainment;fiducial-free piecewise smooth vertically extruded surface;image registration;immersive virtual reality systems;nonlinear optimization technique;nonplanar projection based display;projector property estimation;single camera;Calibration;Cameras;Optimization;Registers;Shape;Surface reconstruction;Three dimensional displays;CAVES.;Tiled displays;autocalibration;cylindrical displays;geometric registration},
doi={10.1109/TVCG.2011.33},
ISSN={1077-2626},}
@ARTICLE{5710911,
author={Steinicke, F. and Bruder, G. and Hinrichs, K. and Willemsen, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Change Blindness Phenomena for Virtual Reality Display Systems},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1223-1233},
abstract={In visual perception, change blindness describes the phenomenon that persons viewing a visual scene may apparently fail to detect significant changes in that scene. These phenomena have been observed in both computer-generated imagery and real-world scenes. Several studies have demonstrated that change blindness effects occur primarily during visual disruptions such as blinks or saccadic eye movements. However, until now the influence of stereoscopic vision on change blindness has not been studied thoroughly in the context of visual perception research. In this paper, we introduce change blindness techniques for stereoscopic virtual reality (VR) systems, providing the ability to substantially modify a virtual scene in a manner that is difficult for observers to perceive. We evaluate techniques for semiimmersive VR systems, i.e., a passive and active stereoscopic projection system as well as an immersive VR system, i.e., a head-mounted display, and compare the results to those of monoscopic viewing conditions. For stereoscopic viewing conditions, we found that change blindness phenomena occur with the same magnitude as in monoscopic viewing conditions. Furthermore, we have evaluated the potential of the presented techniques for allowing abrupt, and yet significant, changes of a stereoscopically displayed virtual reality environment.},
keywords={natural scenes;stereo image processing;three-dimensional displays;virtual reality;vision defects;visual perception;change blindness;computer-generated imagery;display systems;monoscopic viewing conditions;stereoscopic vision;virtual reality;visual disruptions;visual perception;visual scene;Blindness;Context;Humans;Observers;Virtual reality;Visual perception;Visualization;Change blindness;stereoscopic display;virtual reality.},
doi={10.1109/TVCG.2011.41},
ISSN={1077-2626},}
@ARTICLE{5708144,
author={Nordahl, R. and Turchet, L. and Serafin, S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Sound Synthesis and Evaluation of Interactive Footsteps and Environmental Sounds Rendering for Virtual Reality Applications},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1234-1244},
abstract={We propose a system that affords real-time sound synthesis of footsteps on different materials. The system is based on microphones, which detect real footstep sounds from subjects, from which the ground reaction force (GRF) is estimated. Such GRF is used to control a sound synthesis engine based on physical models. Two experiments were conducted. In the first experiment, the ability of subjects to recognize the surface they were exposed to was assessed. In the second experiment, the sound synthesis engine was enhanced with environmental sounds. Results show that, in some conditions, adding a soundscape significantly improves the recognition of the simulated environment.},
keywords={audio signal processing;microphones;surface acoustic wave signal processing;virtual reality;environmental sounds;ground reaction force;interactive footsteps;microphones;real-time sound synthesis engine;soundscape rendering;virtual reality applications;Engines;Footwear;Force;Legged locomotion;Materials;Microphones;Solid modeling;Sound and music computing;soundscape rendering.;surface simulation;walking;Foot;Humans;Sound;User-Computer Interface;Video Games},
doi={10.1109/TVCG.2011.30},
ISSN={1077-2626},}
@ARTICLE{5728802,
author={Sangyoon Lee and Hong Hua},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Effects of Viewing Conditions and Rotation Methods in a Collaborative Tabletop AR Environment},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1245-1258},
abstract={We investigate the effects of viewing conditions and rotation methods on different types of collaborative tasks in a two-user colocated tabletop augmented reality (AR) environment. The viewing condition means how the manipulation of a tabletop world by one user is shown in the other users' views and the rotation method means what type of input devices is used to rotate the tabletop world for alternative orientations. Our experiment considered two viewing conditions (consistent view and inconsistent view), two rotation methods (direct turn and indirect turn), and two task types (synchronous and referring-strong type, and asynchronous and orientation-strong type). A 3D display environment called "Stereoscopic Collaboration in Augmented and Projective Environments (SCAPE)” was utilized as a test environment. According to the results, the viewing conditions had significant effects on several objective and subjective measurements. On task completion time, their effect for the synchronous and referring-strong type of task was opposite to that for the asynchronous and orientation-strong type of task. On the other hand, the rotation methods had significant effects only on the accumulated turn angle (for both task types) and the number of negotiation phrases (only in the inconsistent viewing condition for the asynchronous and orientation-strong type of task).},
keywords={augmented reality;groupware;three-dimensional displays;3D display environment;SCAPE;augmented reality;collaborative tabletop AR environment;referring-strong type;rotation methods;stereoscopic collaboration in augmented and projective environments;Collaboration;Mice;Performance evaluation;Three dimensional displays;Turning;User interfaces;Visualization;Augmented reality;collaborative computing;evaluation;human factors;user interfaces.},
doi={10.1109/TVCG.2011.49},
ISSN={1077-2626},}
@ARTICLE{5710908,
author={Borst, C.W. and Tiesel, J.-P. and Habib, E. and Das, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Single-Pass Composable 3D Lens Rendering and Spatiotemporal 3D Lenses},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1259-1272},
abstract={We present a new 3D lens rendering technique and a new spatiotemporal lens. Interactive 3D lenses, often called volumetric lenses, provide users with alternative views of data sets within 3D lens boundaries while maintaining the surrounding overview (context). In contrast to previous multipass rendering work, we discuss the strengths, limitations, and performance costs of a single-pass technique especially suited to fragment-level lens effects, such as color mapping, lighting, and clipping. Some object-level effects, such as a data set selection lens, are also incorporated, with each object's geometry being processed once by the graphics pipeline. For a substantial range of effects, our approach supports several composable lenses at interactive frame rates without performance loss during increasing lens intersections or manipulation by a user. Other cases, for which this performance cannot be achieved, are also discussed. We illustrate possible applications of our lens system, including Time Warp lenses for exploring time-varying data sets.},
keywords={computational geometry;lenses;solid modelling;time warp simulation;data set selection lens;fragment-level lens effect;graphics pipeline;interactive 3D lens;interactive frame rate;object geometry;object-level effect;performance cost;single-pass composable 3D lens rendering technique;spatiotemporal 3D lens technique;time varying data set;time warp lens;volumetric lens;Geometry;Graphics processing unit;Lenses;Rendering (computer graphics);Shape;Three dimensional displays;Transforms;Interaction styles;virtual reality;volumetric lens.},
doi={10.1109/TVCG.2011.38},
ISSN={1077-2626},}
@ARTICLE{5620893,
author={Johnson, M.K. and Dale, K. and Avidan, S. and Pfister, H. and Freeman, W.T. and Matusik, W.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={CG2Real: Improving the Realism of Computer Generated Images Using a Large Collection of Photographs},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1273-1285},
abstract={Computer-generated (CG) images have achieved high levels of realism. This realism, however, comes at the cost of long and expensive manual modeling, and often humans can still distinguish between CG and real images. We introduce a new data-driven approach for rendering realistic imagery that uses a large collection of photographs gathered from online repositories. Given a CG image, we retrieve a small number of real images with similar global structure. We identify corresponding regions between the CG and real images using a mean-shift cosegmentation algorithm. The user can then automatically transfer color, tone, and texture from matching regions to the CG image. Our system only uses image processing operations and does not require a 3D model of the scene, making it fast and easy to integrate into digital content creation workflows. Results of a user study show that our hybrid images appear more realistic than the originals.},
keywords={image colour analysis;image matching;image segmentation;image texture;photography;realistic images;rendering (computer graphics);CG image;CG2Real;computer-generated image;hybrid image;image color;image matching;image texture;image tone;mean-shift cosegmentation algorithm;photograph;realism;realistic imagery;rendering;Computational modeling;Databases;Histograms;Image color analysis;Image segmentation;Pixel;Rendering (computer graphics);Image enhancement;image databases;image-based rendering.},
doi={10.1109/TVCG.2010.233},
ISSN={1077-2626},}
@ARTICLE{5611510,
author={Hong-Yun Kim and Chang-Hyo Yu and Lee-Sup Kim},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Memory-Efficient Unified Early Z-Test},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1286-1294},
abstract={The Unified Early Z-Test (U-EZT) is proposed to examine the visibility of pixels during tile-based rasterization in a mobile 3D graphics processor. U-EZT combines the advantages of the Z-max and Z-min EZT algorithms: the Z-max algorithm is improved by the independently updatable z-max tiles and the use of mask bits; and the Z-min algorithm is improved by reusing the mask bits from the z-max test to update the z-min tiles after tile rasterizing. As a result, storage requirements are reduced to 3 bits per pixel, and simulations suggest that U-EZT requires 20 percent to 57 percent less memory bandwidth than previous EZT algorithms.},
keywords={computer graphic equipment;solid modelling;storage management chips;U-EZT;Z-max EZT algorithm;Z-max test;Z-min EZT algorithm;Z-min tile;memory bandwidth;memory-efficient unified early Z-test;mobile 3D graphics processor;tile rasterizing;tile-based rasterization;Classification algorithms;Memory management;Pixel;Rendering (computer graphics);System-on-a-chip;Tiles;Computer graphics;graphics processors;visible line/surface algorithms;z-test.},
doi={10.1109/TVCG.2010.228},
ISSN={1077-2626},}
@ARTICLE{5620899,
author={Dehui Xiang and Tian, Jie and Fei Yang and Qi Yang and Xing Zhang and Qingde Li and Xin Liu},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Skeleton Cuts #x02014;An Efficient Segmentation Method for Volume Rendering},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1295-1306},
abstract={Volume rendering has long been used as a key technique for volume data visualization, which works by using a transfer function to map color and opacity to each voxel. Many volume rendering approaches proposed so far for voxels classification have been limited in a single global transfer function, which is in general unable to properly visualize interested structures. In this paper, we propose a localized volume data visualization approach which regards volume visualization as a combination of two mutually related processes: the segmentation of interested structures and the visualization using a locally designed transfer function for each individual structure of interest. As shown in our work, a new interactive segmentation algorithm is advanced via skeletons to properly categorize interested structures. In addition, a localized transfer function is subsequently presented to assign optical parameters via interested information such as intensity, thickness and distance. As can be seen from the experimental results, the proposed techniques allow to appropriately visualize interested structures in highly complex volume medical data sets.},
keywords={bone;data visualisation;image classification;image colour analysis;image segmentation;interactive systems;medical image processing;rendering (computer graphics);color mapping;complex medical sets;interactive segmentation algorithm;localized transfer function;opacity mapping;skeleton cuts;transfer function;visual parameters;volume data visualization;volume rendering;voxel classification;Data visualization;Euclidean distance;Rendering (computer graphics);Skeleton;Three dimensional displays;Transfer functions;Visualization;Volume rendering;classification;localized transfer function;segmentation;skeleton cuts},
doi={10.1109/TVCG.2010.239},
ISSN={1077-2626},}
@ARTICLE{5669296,
author={Bremer, P.-T. and Weber, G. and Tierny, J. and Pascucci, V. and Day, M. and Bell, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Exploration and Analysis of Large-Scale Simulations Using Topology-Based Data Segmentation},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1307-1324},
abstract={Large-scale simulations are increasingly being used to study complex scientific and engineering phenomena. As a result, advanced visualization and data analysis are also becoming an integral part of the scientific process. Often, a key step in extracting insight from these large simulations involves the definition, extraction, and evaluation of features in the space and time coordinates of the solution. However, in many applications, these features involve a range of parameters and decisions that will affect the quality and direction of the analysis. Examples include particular level sets of a specific scalar field, or local inequalities between derived quantities. A critical step in the analysis is to understand how these arbitrary parameters/decisions impact the statistical properties of the features, since such a characterization will help to evaluate the conclusions of the analysis as a whole. We present a new topological framework that in a single-pass extracts and encodes entire families of possible features definitions as well as their statistical properties. For each time step we construct a hierarchical merge tree a highly compact, yet flexible feature representation. While this data structure is more than two orders of magnitude smaller than the raw simulation data it allows us to extract a set of features for any given parameter selection in a postprocessing step. Furthermore, we augment the trees with additional attributes making it possible to gather a large number of useful global, local, as well as conditional statistic that would otherwise be extremely difficult to compile. We also use this representation to create tracking graphs that describe the temporal evolution of the features over time. Our system provides a linked-view interface to explore the time-evolution of the graph interactively alongside the segmentation, thus making it possible to perform extensive data analysis in a very efficient manner. We demonstrate our framework by extracting a- d analyzing burning cells from a large-scale turbulent combustion simulation. In particular, we show how the statistical analysis enabled by our techniques provides new insight into the combustion process.},
keywords={combustion;data analysis;digital simulation;natural sciences computing;statistical analysis;burning cells;data analysis;feature representation;hierarchical merge tree;large scale simulations;scientific process;single pass extracts;statistical analysis;topology based data segmentation;turbulent combustion simulation;Combustion;Computational modeling;Data models;Data structures;Data visualization;Feature extraction;Fuels;Morse theory;Topology;combustion.;merge trees;segmentation;streaming algorithms},
doi={10.1109/TVCG.2010.253},
ISSN={1077-2626},}
@ARTICLE{5620990,
author={Rueda, A.J. and Feito, F.R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={EL-REP: A New 2D Geometric Decomposition Scheme and Its Applications},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1325-1336},
abstract={This work describes the EL-REP, a new 2D decomposition scheme with interesting properties and applications. The EL-REP can be computed for one or more simple polygons of any kind: convex or nonconvex, with or without holes and even with several shells. A method for constructing this decomposition is described in detail, together with several of its main applications: fast point-in-polygon inclusion test, 2D location, triangulation of polygons, and collision detection.},
keywords={computational geometry;mesh generation;solid modelling;2D geometric decomposition scheme;EL-REP;polygons;solid modeling;Complexity theory;Fans;Generators;Indexes;Mesh generation;Solid modeling;Three dimensional displays;2D decompositions;geometric algorithms.;solid modeling},
doi={10.1109/TVCG.2010.246},
ISSN={1077-2626},}
@ARTICLE{5611514,
author={Rossignac, Jarek},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Ordered Boolean List (OBL): Reducing the Footprint for Evaluating Boolean Expressions},
year={2011},
month={Sept},
volume={17},
number={9},
pages={1337-1351},
abstract={An Expanded Boolean Expression (EBE) does not contain any XOR or EQUAL operators. The occurrence of each variable is a different literal. We provide a linear time algorithm that converts an EBE of n literals into a logically equivalent Ordered Boolean List (OBL) and show how to use the OBL to evaluate the EBE in n steps and O(log log n) space, if the values of the literals are each read once in the order prescribed by the OBL. (An evaluation workspace of 5 bits suffices for all EBEs of up to six billion literals.) The primary application is the SIMD architecture, where the same EBE is evaluated in parallel for different input vectors when rendering solid models on the GPU directly from their Constructive Solid Geometry (CSG) representation. We compare OBL to the Reduced Ordered Binary Decision Diagram (ROBDD) and suggest possible applications of OBL to logic verification and to circuit design.},
keywords={Boolean algebra;computational complexity;computer graphic equipment;coprocessors;parallel architectures;rendering (computer graphics);solid modelling;GPU;SIMD architecture;boolean expression evaluation;circuit design;constructive solid geometry representation;expanded Boolean expression;linear time algorithm;logic verification;logically equivalent ordered Boolean list;reduced ordered binary decision diagram;solid model rendering;Boolean functions;Data structures;Pixel;Solids;Switches;Weaving;Wiring;Boolean expression evaluation cost;CSG;OBDD.},
doi={10.1109/TVCG.2010.232},
ISSN={1077-2626},}
@ARTICLE{5620905,
author={Henderson, S. and Feiner, S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Exploring the Benefits of Augmented Reality Documentation for Maintenance and Repair},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1355-1368},
abstract={We explore the development of an experimental augmented reality application that provides benefits to professional mechanics performing maintenance and repair tasks in a field setting. We developed a prototype that supports military mechanics conducting routine maintenance tasks inside an armored vehicle turret, and evaluated it with a user study. Our prototype uses a tracked headworn display to augment a mechanic's natural view with text, labels, arrows, and animated sequences designed to facilitate task comprehension, localization, and execution. A within-subject controlled user study examined professional military mechanics using our system to complete 18 common tasks under field conditions. These tasks included installing and removing fasteners and indicator lights, and connecting cables, all within the cramped interior of an armored personnel carrier turret. An augmented reality condition was tested against two baseline conditions: the same headworn display providing untracked text and graphics and a fixed flat panel display representing an improved version of the laptop-based documentation currently employed in practice. The augmented reality condition allowed mechanics to locate tasks more quickly than when using either baseline, and in some instances, resulted in less overall head movement. A qualitative survey showed that mechanics found the augmented reality condition intuitive and satisfying for the tested sequence of tasks.},
keywords={augmented reality;helmet mounted displays;maintenance engineering;military computing;user interfaces;armored vehicle turret;augmented reality;flat panel display;headworn display;laptop-based documentation;maintenance;military mechanics;repair;routine maintenance task;task comprehension;task execution;task localization;within-subject controlled user study;Assembly;Augmented reality;Cameras;Maintenance engineering;Prototypes;Software;Three dimensional displays;Industrial;military;user interfaces;virtual and augmented reality.},
doi={10.1109/TVCG.2010.245},
ISSN={1077-2626},}
@ARTICLE{5620901,
author={Hagbi, N. and Bergig, O. and El-Sana, J. and Billinghurst, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Shape Recognition and Pose Estimation for Mobile Augmented Reality},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1369-1379},
abstract={Nestor is a real-time recognition and camera pose estimation system for planar shapes. The system allows shapes that carry contextual meanings for humans to be used as Augmented Reality (AR) tracking targets. The user can teach the system new shapes in real time. New shapes can be shown to the system frontally, or they can be automatically rectified according to previously learned shapes. Shapes can be automatically assigned virtual content by classification according to a shape class library. Nestor performs shape recognition by analyzing contour structures and generating projective-invariant signatures from their concavities. The concavities are further used to extract features for pose estimation and tracking. Pose refinement is carried out by minimizing the reprojection error between sample points on each image contour and its library counterpart. Sample points are matched by evolving an active contour in real time. Our experiments show that the system provides stable and accurate registration, and runs at interactive frame rates on a Nokia N95 mobile phone.},
keywords={augmented reality;error analysis;feature extraction;image classification;image registration;mobile computing;mobile handsets;pose estimation;shape recognition;target tracking;ubiquitous computing;Nokia N95 mobile phone;active contour;camera pose estimation system;contour structure;feature estimation;image contour;interactive frame rate;mobile augmented reality;planar shape;pose refinement;projective-invariant signature;real-time recognition;reprojection error;shape class library;shape recognition;target tracking;virtual content;Cameras;Estimation;Feature extraction;Libraries;Robustness;Shape;Transforms;Multimedia information systems;and virtual realities;artificial;augmented;image processing and computer vision;scene analysis;tracking.},
doi={10.1109/TVCG.2010.241},
ISSN={1077-2626},}
@ARTICLE{5620908,
author={Nilsson, S. and Johansson, B.J.E. and Jönsson, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Cross-Organizational Collaboration Supported by Augmented Reality},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1380-1392},
abstract={This paper presents a study where Augmented Reality (AR) technology has been used as a tool for supporting collaboration between the rescue services, the police and military personnel in a crisis management scenario. There are few studies on how AR systems should be designed to improve cooperation between actors from different organizations while at the same time supporting individual needs. In the present study, an AR system was utilized for supporting joint planning tasks by providing organization specific views of a shared map. The study involved a simulated emergency event conducted in close to real settings with representatives from the organizations for which the system is developed. As a baseline, a series of trials without the AR system was carried out. Results show that the users were positive toward the AR system and would like to use it in real work. They also experience some performance benefits of using the AR system compared to their traditional tools. Finally, the problem of designing for collaborative work as well as the benefits of using an iterative design processes is discussed.},
keywords={augmented reality;emergency services;groupware;military systems;organisational aspects;personnel;police;augmented reality;collaborative work;crisis management scenario;cross-organizational collaboration;military personnel;police;rescue services;Augmented reality;Collaboration;Collaborative work;Command and control systems;Helicopters;Joints;Personnel;Collaborative augmented reality;augmented reality;user evaluation.},
doi={10.1109/TVCG.2010.249},
ISSN={1077-2626},}
@ARTICLE{5620906,
author={Pothkow, K. and Hege, H.-C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Positional Uncertainty of Isocontours: Condition Analysis and Probabilistic Measures},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1393-1406},
abstract={Uncertainty is ubiquitous in science, engineering and medicine. Drawing conclusions from uncertain data is the normal case, not an exception. While the field of statistical graphics is well established, only a few 2D and 3D visualization and feature extraction methods have been devised that consider uncertainty. We present mathematical formulations for uncertain equivalents of isocontours based on standard probability theory and statistics and employ them in interactive visualization methods. As input data, we consider discretized uncertain scalar fields and model these as random fields. To create a continuous representation suitable for visualization we introduce interpolated probability density functions. Furthermore, we introduce numerical condition as a general means in feature-based visualization. The condition number-which potentially diverges in the isocontour problem-describes how errors in the input data are amplified in feature computation. We show how the average numerical condition of isocontours aids the selection of thresholds that correspond to robust isocontours. Additionally, we introduce the isocontour density and the level crossing probability field; these two measures for the spatial distribution of uncertain isocontours are directly based on the probabilistic model of the input data. Finally, we adapt interactive visualization methods to evaluate and display these measures and apply them to 2D and 3D data sets.},
keywords={data visualisation;probability;2D visualization method;3D visualization method;feature extraction method;feature-based visualization;interactive visualization method;isocontour density;isocontour positional uncertainty;level crossing probability;probability density function;probability theory;statistical graphics;Isosurfaces;Level set;Measurement uncertainty;Random variables;Systematics;Uncertainty;Uncertainty;error analysis;isolines;isosurfaces;numerical condition;probability;volume visualization.},
doi={10.1109/TVCG.2010.247},
ISSN={1077-2626},}
@ARTICLE{5620904,
author={Prckovska, V. and Peeters, T. H J M and Van Almsick, M. and ter Haar Romeny, B. and Vilanova i Bartroli, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Fused DTI/HARDI Visualization},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1407-1419},
abstract={High-angular resolution diffusion imaging (HARDI) is a diffusion weighted MRI technique that overcomes some of the decisive limitations of its predecessor, diffusion tensor imaging (DTI), in the areas of composite nerve fiber structure. Despite its advantages, HARDI raises several issues: complex modeling of the data, nonintuitive and computationally demanding visualization, inability to interactively explore and transform the data, etc. To overcome these drawbacks, we present a novel, multifield visualization framework that adopts the benefits of both DTI and HARDI. By applying a classification scheme based on HARDI anisotropy measures, the most suitable model per imaging voxel is automatically chosen. This classification allows simplification of the data in areas with single fiber bundle coherence. To accomplish fast and interactive visualization for both HARDI and DTI modalities, we exploit the capabilities of modern GPUs for glyph rendering and adopt DTI fiber tracking in suitable regions. The resulting framework, allows user-friendly data exploration of fused HARDI and DTI data. Many incorporated features such as sharpening, normalization, maxima enhancement and different types of color coding of the HARDI glyphs, simplify the data and enhance its features. We provide a qualitative user evaluation that shows the potentials of our visualization tools in several HARDI applications.},
keywords={biomedical MRI;data visualisation;medical image processing;rendering (computer graphics);DTI fiber tracking;DTI/HARDI visualization;diffusion tensor imaging;diffusion weighted MRI;glyph rendering;high-angular resolution diffusion imaging;modern GPU;multifield visualization framework;Anisotropic magnetoresistance;Data visualization;Diffusion tensor imaging;Ellipsoids;Harmonic analysis;Rendering (computer graphics);Tensile stress;DTI;GPU;HARDI;diffusion;glyphs;multifield.;Adult;Algorithms;Animals;Anisotropy;Brain;Diffusion Tensor Imaging;Female;Humans;Image Processing, Computer-Assisted;Nerve Fibers;Phantoms, Imaging;Rats;Reproducibility of Results},
doi={10.1109/TVCG.2010.244},
ISSN={1077-2626},}
@ARTICLE{5620894,
author={Tai Meng and Entezari, A. and Smith, B. and Moller, T. and Weiskopf, D. and Kirkpatrick, A.E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visual Comparability of 3D Regular Sampling and Reconstruction},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1420-1432},
abstract={The Body-Centered Cubic (BCC) and Face-Centered Cubic (FCC) lattices have been analytically shown to be more efficient sampling lattices than the traditional Cartesian Cubic (CC) lattice, but there has been no estimate of their visual comparability. Two perceptual studies (each with N = 12 participants) compared the visual quality of images rendered from BCC and FCC lattices to images rendered from the CC lattice. Images were generated from two signals: the commonly used Marschner-Lobb synthetic function and a computed tomography scan of a fish tail. Observers found that BCC and FCC could produce images of comparable visual quality to CC, using 30-35 percent fewer samples. For the images used in our studies, the L2 error metric shows high correlation with the judgement of human observers. Using the L2 metric as a proxy, the results of the experiments appear to extend across a wide range of images and parameter choices.},
keywords={image reconstruction;rendering (computer graphics);sampling methods;3D reconstruction;3D regular sampling;L2 error metric;Marschner-Lobb synthetic function;body-centered cubic lattice;face-centered cubic lattice;fish tail tomography scan;image rendering;image visual quality;sampling lattice;visual comparability;FCC;Image reconstruction;Image resolution;Lattices;Marine animals;Observers;Visualization;3D regular sampling and reconstruction;Visual comparability;body-centered cubic (BCC) lattice;cartesian cubic (CC) lattice;face-centered cubic (FCC) lattice.;perceptual quality;Algorithms;Animals;Fishes;Humans;Image Processing, Computer-Assisted;Models, Theoretical;Tail;Tomography, X-Ray Computed},
doi={10.1109/TVCG.2010.234},
ISSN={1077-2626},}
@ARTICLE{5620895,
author={Reininghaus, J. and Lowen, C. and Hotz, I.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Fast Combinatorial Vector Field Topology},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1433-1443},
abstract={This paper introduces a novel approximation algorithm for the fundamental graph problem of combinatorial vector field topology (CVT). CVT is a combinatorial approach based on a sound theoretical basis given by Forman's work on a discrete Morse theory for dynamical systems. A computational framework for this mathematical model of vector field topology has been developed recently. The applicability of this framework is however severely limited by the quadratic complexity of its main computational kernel. In this work, we present an approximation algorithm for CVT with a significantly lower complexity. This new algorithm reduces the runtime by several orders of magnitude and maintains the main advantages of CVT over the continuous approach. Due to the simplicity of our algorithm it can be easily parallelized to improve the runtime further.},
keywords={approximation theory;computational complexity;data analysis;data visualisation;graph theory;Morse dynamical systems theory;approximation algorithm;combinatorial vector field topology;graph problem;quadratic complexity;topological data analysis;vector field visualization;Approximation algorithms;Approximation methods;Orbits;Prediction algorithms;Runtime;Skeleton;Topology;Flow visualization;graph algorithms.},
doi={10.1109/TVCG.2010.235},
ISSN={1077-2626},}
@ARTICLE{5620897,
author={Bartram, L. and Stone, M.C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Whisper, Don't Scream: Grids and Transparency},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1444-1458},
abstract={Visual elements such as grids, labels, and contour lines act as reference structures that support the primary information being presented. Such structures need to be usefully visible, but not so obtrusive that they clutter the presentation. Visual designers know how to carefully manage transparency and layering in an image to balance these elements. We want the presentation of these structures in complex, dynamic, computer-generated visualizations to reflect the same subtlety and comfort of good design. Our goal is to determine the physical, perceptual, and cognitive characteristics of such structures in a way that enables automatic presentation. Our approach to this problem does not try to characterize "ideal” or "best,” but instead seeks boundary conditions that define a range of visible yet subtle legibility. All presentations that are clearly bad lie outside of this range, and can easily be avoided. In this paper, we report three experiments investigating the effects of grid color and spacing on these boundary conditions, defined by manipulating the transparency (alpha) of thin rectangular grids over scatter plots. Our results show that while there is some variation due to user preference and image properties, bounding alpha allows us to reliably predict a range of usable yet unobtrusive grids over a wide variety of conditions.},
keywords={data visualisation;image colour analysis;user interfaces;bounding alpha;computer-generated visualization;contour lines;grid color effect;grid element;image layering;image property;image transparency;line element;user preference;visual designers;Art;Complexity theory;Data visualization;Image color analysis;Measurement;Rendering (computer graphics);Visualization;Index Terms—Information visualization;applied perception;automated presentation;visual design.},
doi={10.1109/TVCG.2010.237},
ISSN={1077-2626},}
@ARTICLE{5620896,
author={Cabral, M. and Bonneel, N. and Lefebvre, S. and Drettakis, G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Relighting Photographs of Tree Canopies},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1459-1474},
abstract={We present an image-based approach to relighting photographs of tree canopies. Our goal is to minimize capture overhead; thus the only input required is a set of photographs of the tree taken at a single time of day, while allowing relighting at any other time. We first analyze lighting in a tree canopy both theoretically and using simulations. From this analysis, we observe that tree canopy lighting is similar to volumetric illumination. We assume a single-scattering volumetric lighting model for tree canopies, and diffuse leaf reflectance; we validate our assumptions with synthetic renderings. We create a volumetric representation of the tree from 10-12 images taken at a single time of day and use a single-scattering participating media lighting model. An analytical sun and sky illumination model provides consistent representation of lighting for the captured input and unknown target times. We relight the input image by applying a ratio of the target and input time lighting representations. We compute this representation efficiently by simultaneously coding transmittance from the sky and to the eye in spherical harmonics. We validate our method by relighting images of synthetic trees and comparing to path-traced solutions. We also present results for photographs, validating with time-lapse ground truth sequences.},
keywords={image representation;image sequences;lighting;rendering (computer graphics);vegetation;image-based approach;image-based rendering;input time lighting representations;leaf reflectance diffusion;photograph relighting;single-scattering volumetric lighting model;sky illumination model;sun illumination model;synthetic renderings;target time lighting representations;time-lapse ground truth sequences;tree canopy lighting;volumetric representation;Approximation methods;Computational modeling;Lighting;Media;Pixel;Rendering (computer graphics);Sun;Image-based rendering;relighting.},
doi={10.1109/TVCG.2010.236},
ISSN={1077-2626},}
@ARTICLE{5887298,
author={Guofeng Zhang and Hanqing Jiang and Jin Huang and Jiaya Jia and Tien-Tsin Wong and Kun Zhou and Hujun Bao},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Motion Imitation with a Handheld Camera},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1475-1486},
abstract={In this paper, we present a novel method to extract motion of a dynamic object from a video that is captured by a handheld camera, and apply it to a 3D character. Unlike the motion capture techniques, neither special sensors/trackers nor a controllable environment is required. Our system significantly automates motion imitation which is traditionally conducted by professional animators via manual keyframing. Given the input video sequence, we track the dynamic reference object to obtain trajectories of both 2D and 3D tracking points. With them as constraints, we then transfer the motion to the target 3D character by solving an optimization problem to maintain the motion gradients. We also provide a user-friendly editing environment for users to fine tune the motion details. As casual videos can be used, our system, therefore, greatly increases the supply source of motion data. Examples of imitating various types of animal motion are shown.},
keywords={cameras;image motion analysis;image sequences;optimisation;video signal processing;handheld camera;motion capture techniques;motion extraction;motion imitation;optimization problem;video sequence;Cameras;Deformable models;Shape;Solid modeling;Target tracking;Three dimensional displays;Motion imitation;depth recovery;mesh deformation;motion gradient;motion tracking.},
doi={10.1109/TVCG.2010.254},
ISSN={1077-2626},}
@ARTICLE{5611511,
author={Lawrence, J. and Arietta, S. and Kazhdan, M. and Lepage, D. and O'Hagan, C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A User-Assisted Approach to Visualizing Multidimensional Images},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1487-1498},
abstract={We present a new technique for fusing together an arbitrary number of aligned images into a single color or intensity image. We approach this fusion problem from the context of Multidimensional Scaling (MDS) and describe an algorithm that preserves the relative distances between pairs of pixel values in the input (vectors of measurements) as perceived differences in a color image. The two main advantages of our approach over existing techniques are that it can incorporate user constraints into the mapping process and allows adaptively compressing or exaggerating features in the input in order to make better use of the output's limited dynamic range. We demonstrate these benefits by showing applications in various scientific domains and comparing our algorithm to previously proposed techniques.},
keywords={data visualisation;image colour analysis;user interfaces;color image;intensity image;mapping process;multidimensional image visualization;multidimensional scaling context;user-assisted approach;Color;Equations;Image color analysis;Laplace equations;Linear systems;Pixel;Stress;Multidimensional images;dimensionality reduction;life and medical sciences.;multidimensional scaling;physical sciences and engineering;visualization techniques},
doi={10.1109/TVCG.2010.229},
ISSN={1077-2626},}
@ARTICLE{5708145,
author={Liang Wan and Shue-Kwan Mak and Tien-Tsin Wong and Chi-Sing Leung},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Spatiotemporal Sampling of Dynamic Environment Sequences},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1499-1509},
abstract={Environment sampling is a popular technique for rendering scenes with distant environment illumination. However, the temporal consistency of animations synthesized under dynamic environment sequences has not been fully studied. This paper addresses this problem and proposes a novel method, namely spatiotemporal sampling, to fully exploit both the temporal and spatial coherence of environment sequences. Our method treats an environment sequence as a spatiotemporal volume and samples the sequence by stratifying the volume adaptively. For this purpose, we first present a new metric to measure the importance of each stratified volume. A stratification algorithm is then proposed to adaptively suppress the abrupt temporal and spatial changes in the generated sampling patterns. The proposed method is able to automatically adjust the number of samples for each environment frame and produce temporally coherent sampling patterns. Comparative experiments demonstrate the capability of our method to produce smooth and consistent animations under dynamic environment sequences.},
keywords={computer animation;rendering (computer graphics);sampling methods;animation consistency;environment illumination;environment sampling;environment sequence;scene rendering;spatiotemporal sampling method;spatiotemporal volume;stratification algorithm;Animation;Binary trees;Lighting;Measurement;Monte Carlo methods;Rendering (computer graphics);Time domain analysis;Spatiotemporal sampling;adaptive volume stratification.;dynamic environment sequences;importance metric;temporal consistency},
doi={10.1109/TVCG.2011.31},
ISSN={1077-2626},}
@ARTICLE{5708143,
author={Panozzo, D. and PUppo, E. and Tarini, M. and Pietroni, N. and Cignoni, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Automatic Construction of Quad-Based Subdivision Surfaces Using Fitmaps},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1510-1520},
abstract={We present an automatic method to produce a Catmull-Clark subdivision surface that fits a given input mesh. Its control mesh is coarse and adaptive, and it is obtained by simplifying an initial mesh at high resolution. Simplification occurs progressively via local operators and addresses both quality of surface and faithfulness to the input shape throughout the whole process. The method is robust and performs well on rather complex shapes. Displacement mapping or normal mapping can be applied to approximate the input shape arbitrarily well.},
keywords={computational geometry;mesh generation;Catmull-Clark subdivision surface;Fitmaps;displacement mapping;mesh compression;normal mapping;quad-based subdivision surface automatic construction;quadrilateral meshes;Accuracy;Approximation methods;Polynomials;Rendering (computer graphics);Shape;Smoothing methods;Surface treatment;Quadrilateral meshes;displacement mapping;mesh compression.;subdivision surfaces},
doi={10.1109/TVCG.2011.28},
ISSN={1077-2626},}
@ARTICLE{5674028,
author={Youyi Zheng and Hongbo Fu and Au, O.K.-C. and Chiew-Lan Tai},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Bilateral Normal Filtering for Mesh Denoising},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1521-1530},
abstract={Decoupling local geometric features from the spatial location of a mesh is crucial for feature-preserving mesh denoising. This paper focuses on first order features, i.e., facet normals, and presents a simple yet effective anisotropic mesh denoising framework via normal field denoising. Unlike previous denoising methods based on normal filtering, which process normals defined on the Gauss sphere, our method considers normals as a surface signal defined over the original mesh. This allows the design of a novel bilateral normal filter that depends on both spatial distance and signal distance. Our bilateral filter is a more natural extension of the elegant bilateral filter for image denoising than those used in previous bilateral mesh denoising methods. Besides applying this bilateral normal filter in a local, iterative scheme, as common in most of previous works, we present for the first time a global, noniterative scheme for an isotropic denoising. We show that the former scheme is faster and more effective for denoising extremely noisy meshes while the latter scheme is more robust to irregular surface sampling. We demonstrate that both our feature-preserving schemes generally produce visually and numerically better denoising results than previous methods, especially at challenging regions with sharp features or irregular sampling.},
keywords={filtering theory;image denoising;iterative methods;Gauss sphere;bilateral normal filtering;feature-preserving mesh denoising;image denoising;irregular surface sampling;isotropic denoising;noniterative scheme;normal field denoising;signal distance;spatial distance;surface signal;Equations;Laplace equations;Mathematical model;Noise;Noise reduction;Optimization;Robustness;Mesh denoising;bilateral normal filtering;feature preserving;irregular surface sampling.},
doi={10.1109/TVCG.2010.264},
ISSN={1077-2626},}
@ARTICLE{5611513,
author={Huai-Yu Wu and Chunhong Pan and Hongbin Zha and Qing Yang and Songde Ma},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Partwise Cross-Parameterization via Nonregular Convex Hull Domains},
year={2011},
month={Oct},
volume={17},
number={10},
pages={1531-1544},
abstract={In this paper, we propose a novel partwise framework for cross-parameterization between 3D mesh models. Unlike most existing methods that use regular parameterization domains, our framework uses nonregular approximation domains to build the cross-parameterization. Once the nonregular approximation domains are constructed for 3D models, different (and complex) input shapes are transformed into similar (and simple) shapes, thus facilitating the cross-parameterization process. Specifically, a novel nonregular domain, the convex hull, is adopted to build shape correspondence. We first construct convex hulls for each part of the segmented model, and then adopt our convex-hull cross-parameterization method to generate compatible meshes. Our method exploits properties of the convex hull, e.g., good approximation ability and linear convex representation for interior vertices. After building an initial cross-parameterization via convex-hull domains, we use compatible remeshing algorithms to achieve an accurate approximation of the target geometry and to ensure a complete surface matching. Experimental results show that the compatible meshes constructed are well suited for shape blending and other geometric applications.},
keywords={approximation theory;solid modelling;3D mesh model;compatible remeshing algorithm;nonregular approximation domain;nonregular convex hull domain;partwise cross-parameterization;shape blending;surface matching;Approximation algorithms;Approximation methods;Geometry;Measurement;Shape;Solid modeling;Three dimensional displays;Cross-parameterization;compatible remeshing;convex hull;critical points;nonregular approximation domains;sketch-based segmentation.},
doi={10.1109/TVCG.2010.231},
ISSN={1077-2626},}
@ARTICLE{5708142,
author={Oesterling, P. and Heine, C. and Janicke, H. and Scheuermann, G. and Heyer, G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization of High-Dimensional Point Clouds Using Their Density Distribution's Topology},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1547-1559},
abstract={We present a novel method to visualize multidimensional point clouds. While conventional visualization techniques, like scatterplot matrices or parallel coordinates, have issues with either overplotting of entities or handling many dimensions, we abstract the data using topological methods before presenting it. We assume the input points to be samples of a random variable with a high-dimensional probability distribution which we approximate using kernel density estimates on a suitably reconstructed mesh. From the resulting scalar field we extract the join tree and present it as a topological landscape, a visualization metaphor that utilizes the human capability of understanding natural terrains. In this landscape, dense clusters of points show up as hills. The nesting of hills indicates the nesting of clusters. We augment the landscape with the data points to allow selection and inspection of single points and point sets. We also present optimizations to make our algorithm applicable to large data sets and to allow interactive adaption of our visualization to the kernel window width used in the density estimation.},
keywords={approximation theory;cloud computing;data visualisation;matrix algebra;optimisation;statistical distributions;trees (mathematics);data abstraction;density distribution topology;high dimensional probability distribution;high-dimensional point clouds visualization technique;interactive adaption;kernel density estimation;kernel window width;mesh reconstruction;multidimensional point clouds;natural terrain;optimization;parallel coordinates;scalar field;scatterplot matrices;topological landscape;topological method;visualization metaphor;Approximation methods;Data visualization;Density functional theory;Kernel;Piecewise linear approximation;Runtime;Topology;Clustering;graphs;pattern analysis;point clouds;topology.},
doi={10.1109/TVCG.2011.27},
ISSN={1077-2626},}
@ARTICLE{5887324,
author={Yunhai Wang and Wei Chen and Jian Zhang and Tingxing Dong and Guihua Shan and Xuebin Chi},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Efficient Volume Exploration Using the Gaussian Mixture Model},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1560-1573},
abstract={The multidimensional transfer function is a flexible and effective tool for exploring volume data. However, designing an appropriate transfer function is a trial-and-error process and remains a challenge. In this paper, we propose a novel volume exploration scheme that explores volumetric structures in the feature space by modeling the space using the Gaussian mixture model (GMM). Our new approach has three distinctive advantages. First, an initial feature separation can be automatically achieved through GMM estimation. Second, the calculated Gaussians can be directly mapped to a set of elliptical transfer functions (ETFs), facilitating a fast pre-integrated volume rendering process. Third, an inexperienced user can flexibly manipulate the ETFs with the assistance of a suite of simple widgets, and discover potential features with several interactions. We further extend the GMM-based exploration scheme to time-varying data sets using an incremental GMM estimation algorithm. The algorithm estimates the GMM for one time step by using itself and the GMM generated from its previous steps. Sequentially applying the incremental algorithm to all time steps in a selected time interval yields a preliminary classification for each time step. In addition, the computed ETFs can be freely adjusted. The adjustments are then automatically propagated to other time steps. In this way, coherent user-guided exploration of a given time interval is achieved. Our GPU implementation demonstrates interactive performance and good scalability. The effectiveness of our approach is verified on several data sets.},
keywords={Gaussian processes;computer graphic equipment;coprocessors;rendering (computer graphics);GMM-based exploration scheme;GPU implementation;Gaussian mixture model;elliptical transfer functions;incremental GMM estimation algorithm;multidimensional transfer function;volume exploration scheme;volume rendering process;Aerospace electronics;Estimation;Feature extraction;Histograms;Rendering (computer graphics);Solid modeling;Transfer functions;Gaussian mixture model;Volume classification;temporal coherence.;time-varying data;volume rendering},
doi={10.1109/TVCG.2011.97},
ISSN={1077-2626},}
@ARTICLE{5732716,
author={Brownlee, C. and Pegoraro, V. and Shankar, S. and McCormick, P.S. and Hansen, C.D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Physically-Based Interactive Flow Visualization Based on Schlieren and Interferometry Experimental Techniques},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1574-1586},
abstract={Understanding fluid flow is a difficult problem and of increasing importance as computational fluid dynamics (CFD) produces an abundance of simulation data. Experimental flow analysis has employed techniques such as shadowgraph, interferometry, and schlieren imaging for centuries, which allow empirical observation of inhomogeneous flows. Shadowgraphs provide an intuitive way of looking at small changes in flow dynamics through caustic effects while schlieren cutoffs introduce an intensity gradation for observing large scale directional changes in the flow. Interferometry tracks changes in phase-shift resulting in bands appearing. The combination of these shading effects provides an informative global analysis of overall fluid flow. Computational solutions for these methods have proven too complex until recently due to the fundamental physical interaction of light refracting through the flow field. In this paper, we introduce a novel method to simulate the refraction of light to generate synthetic shadowgraph, schlieren and interferometry images of time-varying scalar fields derived from computational fluid dynamics data. Our method computes physically accurate schlieren and shadowgraph images at interactive rates by utilizing a combination of GPGPU programming, acceleration methods, and data-dependent probabilistic schlieren cutoffs. Applications of our method to multifield data and custom application-dependent color filter creation are explored. Results comparing this method to previous schlieren approximations are finally presented.},
keywords={computational fluid dynamics;computer graphic equipment;coprocessors;data visualisation;interferometry;GPGPU programming;acceleration methods;application dependent color filter creation;computational fluid dynamics;data dependent probabilistic schlieren cutoffs;flow dynamics;fluid flow;interferometry experimental techniques;physically based interactive flow visualization;schlieren approximations;schlieren experimental techniques;shadowgraph;time varying scalar fields;Data visualization;Image color analysis;Laser beams;Light sources;Optical filters;Optical interferometry;Refractive index;GPUs and multicore architectures;Scalar field data;flow visualization.},
doi={10.1109/TVCG.2010.255},
ISSN={1077-2626},}
@ARTICLE{5674029,
author={Batagelj, V. and Brandenburg, F.J. and Didimo, W. and Liotta, G. and Palladino, P. and Patrignani, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visual Analysis of Large Graphs Using (X,Y)-Clustering and Hybrid Visualizations},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1587-1598},
abstract={Many different approaches have been proposed for the challenging problem of visually analyzing large networks. Clustering is one of the most promising. In this paper, we propose a new clustering technique whose goal is that of producing both intracluster graphs and intercluster graph with desired topological properties. We formalize this concept in the (X,Y) -clustering framework, where Y is the class that defines the desired topological properties of intracluster graphs and X is the class that defines the desired topological properties of the intercluster graph. By exploiting this approach, hybrid visualization tools can effectively combine different node-link and matrix-based representations, allowing users to interactively explore the graph by expansion/contraction of clusters without loosing their mental map. As a proof of concept, we describe the system Visual Hybrid (X,Y)-clustering (VHYXY) that implements our approach and we present the results of case studies to the visual analysis of social networks.},
keywords={data visualisation;graph theory;pattern clustering;social networking (online);clustering technique;hybrid visualization tools;intracluster graphs;matrix based representation;mental map;node link representation;social networks;topological properties;visual analysis;Algorithm design and analysis;Clustering algorithms;Computational modeling;Context;Layout;Social network services;Visualization;Large graphs;graph clustering;hybrid visualization;visual analytics.},
doi={10.1109/TVCG.2010.265},
ISSN={1077-2626},}
@ARTICLE{5674034,
author={Heine, C. and Schneider, D. and Carr, H. and Scheuermann, G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Drawing Contour Trees in the Plane},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1599-1611},
abstract={The contour tree compactly describes scalar field topology. From the viewpoint of graph drawing, it is a tree with attributes at vertices and optionally on edges. Standard tree drawing algorithms emphasize structural properties of the tree and neglect the attributes. Applying known techniques to convey this information proves hard and sometimes even impossible. We present several adaptions of popular graph drawing approaches to the problem of contour tree drawing and evaluate them. We identify five esthetic criteria for drawing contour trees and present a novel algorithm for drawing contour trees in the plane that satisfies four of these criteria. Our implementation is fast and effective for contour tree sizes usually used in interactive systems (around 100 branches) and also produces readable pictures for larger trees, as is shown for an 800 branch example.},
keywords={computational geometry;data visualisation;interactive systems;trees (mathematics);contour tree compactly;graph drawing;interactive systems;scalar field topology;Clustering algorithms;Image edge detection;Isosurfaces;Layout;Minimization;Stress;Visualization;Contour tree;graph layout.},
doi={10.1109/TVCG.2010.270},
ISSN={1077-2626},}
@ARTICLE{5669306,
author={Qizhi Yu and Neyret, F. and Bruneton, E. and Holzschuch, Nicolas},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Lagrangian Texture Advection: Preserving both Spectrum and Velocity Field},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1612-1623},
abstract={Texturing an animated fluid is a useful way to augment the visual complexity of pictures without increasing the simulation time. But texturing flowing fluids is a complex issue, as it creates conflicting requirements: we want to keep the key texture properties (features, spectrum) while advecting the texture with the underlying flow-which distorts it. In this paper, we present a new, Lagrangian, method for advecting textures: the advected texture is computed only locally and follows the velocity field at each pixel. The texture retains its local properties, including its Fourier spectrum, even though it is accurately advected. Due to its Lagrangian nature, our algorithm can perform on very large, potentially infinite scenes in real time. Our experiments show that it is well suited for a wide range of input textures, including, but not limited to, noise textures.},
keywords={flow simulation;image texture;Lagrangian texture advection;animated fluid;flowing fluid texturing;pictures;spectrum;velocity field;visual complexity;Animation;Heuristic algorithms;Noise;Pixel;Rendering (computer graphics);Surface texture;Visualization;Computer graphics;animation;lagrangian methods.;particles;texture},
doi={10.1109/TVCG.2010.263},
ISSN={1077-2626},}
@ARTICLE{5674030,
author={Eitz, M. and Hildebrand, K. and Boubekeur, T. and Alexa, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Sketch-Based Image Retrieval: Benchmark and Bag-of-Features Descriptors},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1624-1636},
abstract={We introduce a benchmark for evaluating the performance of large-scale sketch-based image retrieval systems. The necessary data are acquired in a controlled user study where subjects rate how well given sketch/image pairs match. We suggest how to use the data for evaluating the performance of sketch-based image retrieval systems. The benchmark data as well as the large image database are made publicly available for further studies of this type. Furthermore, we develop new descriptors based on the bag-of-features approach and use the benchmark to demonstrate that they significantly outperform other descriptors in the literature.},
keywords={image matching;image retrieval;visual databases;bag-of-feature descriptor;benchmark data;image database;image pair matching;large scale sketch-based image retrieval system;performance evaluation;sketch pair matching;Benchmark testing;Correlation;Humans;Image retrieval;Shape;Image/video retrieval;benchmarking.;image databases},
doi={10.1109/TVCG.2010.266},
ISSN={1077-2626},}
@ARTICLE{5582086,
author={Kniss, J. and Guanyu Wang},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Supervised Manifold Distance Segmentation},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1637-1649},
abstract={We present a simple and robust method for image and volume data segmentation based on manifold distance metrics. This is done by treating the image as a function that maps the 2D (image) or 3D (volume) to a 2D or 3D manifold in a higher dimensional feature space. We explore a range of possible feature spaces, including value, gradient, and probabilistic measures, and examine the consequences of including these measures in the feature space. The time and space computational complexity of our segmentation algorithm is O(N), which allows interactive, user-centric segmentation even for large data sets. We show that this method, given appropriate choice of feature vector, produces results both qualitatively and quantitatively similar to Level Sets, Random Walkers, and others. We validate the robustness of this segmentation scheme with comparisons to standard ground-truth models and sensitivity analysis of the algorithm.},
keywords={image segmentation;probability;gradient measures;ground truth models;image data segmentation;level sets;manifold distance metrics;probabilistic measures;random walkers;sensitivity analysis;supervised manifold distance segmentation;user centric segmentation;value measures;volume data segmentation;Data visualization;Equations;Image segmentation;Kernel;Manifolds;Transfer functions;Uncertainty;Hypothesis testing;and multivariate data;data segmentation;extraction of surfaces (isosurfaces;material boundaries);multifield;multimodal;uncertainty visualization.;visual evidence},
doi={10.1109/TVCG.2010.120},
ISSN={1077-2626},}
@ARTICLE{5927292,
author={Cordier, F. and Hyewon Seo and Jinho Park and Junyong Noh},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Sketching of Mirror-Symmetric Shapes},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1650-1662},
abstract={This paper presents a system to create mirror-symmetric surfaces from free-form sketches. The system takes as input a hand-drawn sketch and generates a surface whose silhouette approximately matches the input sketch. The input sketch typically consists of a set of curves connected at their endpoints, forming T-junctions and cusps. Our system is able to identify the skewed-mirror and translational symmetry between the hand-drawn curves and uses this information to reconstruct the occluded parts of the surface and its 3D shape.},
keywords={solid modelling;3D shape;T-junctions;cusps;free form sketches;hand drawn sketch;mirror symmetric shapes;skewed mirror;Image reconstruction;Indexes;Labeling;Shape;Solid modeling;Surface reconstruction;Three dimensional displays;3D modeling;Sketching interface;and mirror-symmetric shape.},
doi={10.1109/TVCG.2010.258},
ISSN={1077-2626},}
@ARTICLE{5674032,
author={Dick, C. and Georgii, J. and Westermann, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Hexahedral Multigrid Approach for Simulating Cuts in Deformable Objects},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1663-1675},
abstract={We present a hexahedral finite element method for simulating cuts in deformable bodies using the corotational formulation of strain at high computational efficiency. Key to our approach is a novel embedding of adaptive element refinements and topological changes of the simulation grid into a geometric multigrid solver. Starting with a coarse hexahedral simulation grid, this grid is adaptively refined at the surface of a cutting tool until a finest resolution level, and the cut is modeled by separating elements along the cell faces at this level. To represent the induced discontinuities on successive multigrid levels, the affected coarse grid cells are duplicated and the resulting connectivity components are distributed to either side of the cut. Drawing upon recent work on octree and multigrid schemes for the numerical solution of partial differential equations, we develop efficient algorithms for updating the systems of equations of the adaptive finite element discretization and the multigrid hierarchy. To construct a surface that accurately aligns with the cuts, we adapt the splitting cubes algorithm to the specific linked voxel representation of the simulation domain we use. The paper is completed by a convergence analysis of the finite element solver and a performance comparison to alternative numerical solution methods. These investigations show that our approach offers high computational efficiency and physical accuracy, and that it enables cutting of deformable bodies at very high resolutions.},
keywords={computational geometry;computer graphics;convergence of numerical methods;mesh generation;octrees;partial differential equations;adaptive finite element discretization;coarse hexahedral simulation grid;convergence analysis;cut simulation;deformable objects;geometric multigrid solver;hexahedral finite element method;hexahedral multigrid approach;multigrid hierarchy;octree;partial differential equations;splitting cubes algorithm;strain corotational formulation;Adaptation model;Computational modeling;Equations;Finite element methods;Materials;Mathematical model;Octrees;Deformable objects;cutting;finite elements;multigrid;octree meshes.},
doi={10.1109/TVCG.2010.268},
ISSN={1077-2626},}
@ARTICLE{5674036,
author={Cheng Chen and Yueting Zhuang and Feiping Nie and Yi Yang and Fei Wu and Jun Xiao},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Learning a 3D Human Pose Distance Metric from Geometric Pose Descriptor},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1676-1689},
abstract={Estimating 3D pose similarity is a fundamental problem on 3D motion data. Most previous work calculates L2-like distance of joint orientations or coordinates, which does not sufficiently reflect the pose similarity of human perception. In this paper, we present a new pose distance metric. First, we propose a new rich pose feature set called Geometric Pose Descriptor (GPD). GPD is more effective in encoding pose similarity by utilizing features on geometric relations among body parts, as well as temporal information such as velocities and accelerations. Based on GPD, we propose a semisupervised distance metric learning algorithm called Regularized Distance Metric Learning with Sparse Representation (RDSR), which integrates information from both unsupervised data relationship and labels. We apply the proposed pose distance metric to applications of motion transition decision and content-based pose retrieval. Quantitative evaluations demonstrate that our method achieves better results with only a small amount of human labels, showing that the proposed pose distance metric is a promising building block for various 3D-motion related applications.},
keywords={content-based retrieval;image representation;motion estimation;pose estimation;sparse matrices;unsupervised learning;3D human pose distance metric;3D motion data;GPD;content-based pose retrieval;encoding pose;geometric pose descriptor;human perception;motion transition decision;pose estimation;regularized distance metric learning;semisupervised distance metric learning;sparse representation;unsupervised data;Approximation methods;Humans;Image reconstruction;Joints;Measurement;Three dimensional displays;Human motion;character animation;distance metric;pose features;semisupervised learning.},
doi={10.1109/TVCG.2010.272},
ISSN={1077-2626},}
@ARTICLE{5674031,
author={Hongen Liao and Dohi, T. and Nomura, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Autostereoscopic 3D Display with Long Visualization Depth Using Referential Viewing Area-Based Integral Photography},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1690-1701},
abstract={We developed an autostereoscopic display for distant viewing of 3D computer graphics (CG) images without using special viewing glasses or tracking devices. The images are created by employing referential viewing area-based CG image generation and pixel distribution algorithm for integral photography (IP) and integral videography (IV) imaging. CG image rendering is used to generate IP/IV elemental images. The images can be viewed from each viewpoint within a referential viewing area and the elemental images are reconstructed from rendered CG images by pixel redistribution and compensation method. The elemental images are projected onto a screen that is placed at the same referential viewing distance from the lens array as in the image rendering. Photographic film is used to record the elemental images through each lens. The method enables 3D images with a long visualization depth to be viewed from relatively long distances without any apparent influence from deviated or distorted lenses in the array. We succeeded in creating an actual autostereoscopic images with an image depth of several meters in front of and behind the display that appear to have 3D even when viewed from a distance.},
keywords={photography;rendering (computer graphics);stereo image processing;three-dimensional displays;video recording;3D computer graphics;CG image rendering;IP/IV elemental images;autostereoscopic 3D display;integral videography imaging;long visualization depth;photographic film;referential viewing area-based integral photography;Arrays;Films;IP networks;Image resolution;Lenses;Pixel;Three dimensional displays;3D;Autostereoscopic display;computer graphics.;integral photography;integral videography;long visualization depth;referential viewing area},
doi={10.1109/TVCG.2010.267},
ISSN={1077-2626},}
@ARTICLE{5669297,
author={Camp, D. and Garth, C. and Childs, H. and Pugmire, D. and Joy, K.I.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Streamline Integration Using MPI-Hybrid Parallelism on a Large Multicore Architecture},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1702-1713},
abstract={Streamline computation in a very large vector field data set represents a significant challenge due to the nonlocal and data-dependent nature of streamline integration. In this paper, we conduct a study of the performance characteristics of hybrid parallel programming and execution as applied to streamline integration on a large, multicore platform. With multicore processors now prevalent in clusters and supercomputers, there is a need to understand the impact of these hybrid systems in order to make the best implementation choice. We use two MPI-based distribution approaches based on established parallelization paradigms, parallelize over seeds and parallelize over blocks, and present a novel MPI-hybrid algorithm for each approach to compute streamlines. Our findings indicate that the work sharing between cores in the proposed MPI-hybrid parallel implementation results in much improved performance and consumes less communication and I/O bandwidth than a traditional, nonhybrid distributed implementation.},
keywords={application program interfaces;message passing;multiprocessing systems;parallel algorithms;parallel architectures;parallel programming;vectors;I/O bandwidth;MPI-based distribution approaches;MPI-hybrid algorithm;MPI-hybrid parallel implementation;MPI-hybrid parallelism;clusters;data-dependent nature;established parallelization paradigms;hybrid parallel programming;hybrid systems;multicore architecture;multicore platform;multicore processors;nonhybrid distributed implementation;parallelize over seeds;performance characteristics;streamline computation;streamline integration;supercomputers;vector field data set;Complexity theory;Data visualization;Distributed databases;Instruction sets;Multicore processing;Parallel processing;Supercomputers;Concurrent programming;display algorithms.;modes of computation;parallel programming;parallelism and concurrency;picture/image generation},
doi={10.1109/TVCG.2010.259},
ISSN={1077-2626},}
@ARTICLE{5674035,
author={Cirio, G. and Marchal, M. and Hillaire, S. and Lecuyer, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Six Degrees-of-Freedom Haptic Interaction with Fluids},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1714-1727},
abstract={We often interact with fluids in our daily life, either through tools such as when holding a glass of water or directly with our body when we swim or we wash our hands. Multimodal interactions with virtual fluids would greatly improve the simulations realism, particularly through haptic interaction. However, achieving realistic, stable, and real-time force feedback from fluids is particularly challenging. In this work, we propose a novel approach that allows real-time six Degrees of Freedom (DoF) haptic interaction with fluids of variable viscosity. Our haptic rendering technique, based on a Smoothed-Particle Hydrodynamics physical model, provides a realistic haptic feedback through physically based forces. 6DoF haptic interaction with fluids is made possible thanks to a new coupling scheme and a unified particle model, allowing the use of arbitrary-shaped rigid bodies. Particularly, fluid containers can be created to hold fluid and hence transmit to the user force feedback coming from fluid stirring, pouring, shaking, and scooping, to name a few. Moreover, we adapted an existing visual rendering algorithm to meet the frame rate requirements of the haptic algorithms. We evaluate and illustrate the main features of our approach through different scenarios, highlighting the 6DoF haptic feedback and the use of containers.},
keywords={computational fluid dynamics;force feedback;haptic interfaces;hydrodynamics;rendering (computer graphics);virtual reality;viscosity;6DoF haptic feedback;6DoF haptic interaction with fluids;arbitrary-shaped rigid body;coupling scheme;fluid containers;fluid stirring;frame rate requirements;haptic algorithms;haptic rendering technique;multimodal interactions;physically based forces;pouring;real-time force feedback;real-time six degrees of freedom haptic interaction with fluids;realistic haptic feedback;scooping;shaking;simulations realism;six degrees-of-freedom haptic interaction;smoothed-particle hydrodynamics physical model;unified particle model;variable viscosity;virtual fluids;visual rendering algorithm;Computational modeling;Haptic interfaces;Mathematical model;Real time systems;Rendering (computer graphics);Smoothing methods;Solid modeling;6DoF haptic interaction;computational fluid dynamics;rigid bodies.;smoothed-particle hydrodynamics},
doi={10.1109/TVCG.2010.271},
ISSN={1077-2626},}
@ARTICLE{5669305,
author={Park, Youngmin and Lepetit, V. and Woontack Woo},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Extended Keyframe Detection with Stable Tracking for Multiple 3D Object Tracking},
year={2011},
month={Nov},
volume={17},
number={11},
pages={1728-1735},
abstract={We present a method that is able to track several 3D objects simultaneously, robustly, and accurately in real time. While many applications need to consider more than one object in practice, the existing methods for single object tracking do not scale well with the number of objects, and a proper way to deal with several objects is required. Our method combines object detection and tracking: frame-to-frame tracking is less computationally demanding but is prone to fail, while detection is more robust but slower. We show how to combine them to take the advantages of the two approaches and demonstrate our method on several real sequences.},
keywords={object detection;object tracking;solid modelling;3D object tracking;extended keyframe detection;frame-to-frame tracking;object detection;Feature extraction;Object detection;Robustness;Solid modeling;Target tracking;Three dimensional displays;Augmented reality;computer vision;object detection.;object tracking},
doi={10.1109/TVCG.2010.262},
ISSN={1077-2626},}
@ARTICLE{6064936,
author={Cheuk Yiu Ip and Varshney, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Saliency-Assisted Navigation of Very Large Landscape Images},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1737-1746},
abstract={The field of visualization has addressed navigation of very large datasets, usually meshes and volumes. Significantly less attention has been devoted to the issues surrounding navigation of very large images. In the last few years the explosive growth in the resolution of camera sensors and robotic image acquisition techniques has widened the gap between the display and image resolutions to three orders of magnitude or more. This paper presents the first steps towards navigation of very large images, particularly landscape images, from an interactive visualization perspective. The grand challenge in navigation of very large images is identifying regions of potential interest. In this paper we outline a three-step approach. In the first step we use multi-scale saliency to narrow down the potential areas of interest. In the second step we outline a method based on statistical signatures to further cull out regions of high conformity. In the final step we allow a user to interactively identify the exceptional regions of high interest that merit further attention. We show that our approach of progressive elicitation is fast and allows rapid identification of regions of interest. Unlike previous work in this area, our approach is scalable and computationally reasonable on very large images. We validate the results of our approach by comparing them to user-tagged regions of interest on several very large landscape images from the Internet.},
keywords={data acquisition;data visualisation;geophysical image processing;image resolution;image sensors;statistical analysis;Internet;camera sensors;image resolution;interactive visualization;landscape images;robotic image acquisition;saliency assisted navigation;statistical signatures;Data visualization;Image color analysis;Image resolution;Navigation;Anomaly Detection;Guided Interaction.;Image Saliency;Interactive Visualization;Scene Perception;Very Large Scale Images},
doi={10.1109/TVCG.2011.231},
ISSN={1077-2626},}
@ARTICLE{6064937,
author={Parry, M.L. and Legg, P.A. and Chung, D.H.S. and Griffiths, I.W. and Chen, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Hierarchical Event Selection for Video Storyboards with a Case Study on Snooker Video Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1747-1756},
abstract={Video storyboard, which is a form of video visualization, summarizes the major events in a video using illustrative visualization. There are three main technical challenges in creating a video storyboard, (a) event classification, (b) event selection and (c) event illustration. Among these challenges, (a) is highly application-dependent and requires a significant amount of application specific semantics to be encoded in a system or manually specified by users. This paper focuses on challenges (b) and (c). In particular, we present a framework for hierarchical event representation, and an importance-based selection algorithm for supporting the creation of a video storyboard from a video. We consider the storyboard to be an event summarization for the whole video, whilst each individual illustration on the board is also an event summarization but for a smaller time window. We utilized a 3D visualization template for depicting and annotating events in illustrations. To demonstrate the concepts and algorithms developed, we use Snooker video visualization as a case study, because it has a concrete and agreeable set of semantic definitions for events and can make use of existing techniques of event detection and 3D reconstruction in a reliable manner. Nevertheless, most of our concepts and algorithms developed for challenges (b) and (c) can be applied to other application areas.},
keywords={data visualisation;image reconstruction;object detection;video signal processing;3D reconstruction;3D visualization template;application specific semantics;event classification;event illustration;hierarchical event representation;hierarchical event selection;illustrative visualization;importance based selection algorithm;snooker video visualization;video storyboards;Context;Data visualization;Multimedia communication;Semantics;Three dimensional displays;Time series analysis;Illustrative visualization.;Multimedia visualization;Time series data},
doi={10.1109/TVCG.2011.208},
ISSN={1077-2626},}
@ARTICLE{6064938,
author={Giusti, A. and Taddei, P. and Corani, G. and Gambardella, L. and Magli, C. and Gianaroli, L.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Artificial Defocus for Displaying Markers in Microscopy Z-Stacks},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1757-1764},
abstract={As microscopes have a very shallow depth of field, Z-stacks (i.e. sets of images shot at different focal planes) are often acquired to fully capture a thick sample. Such stacks are viewed by users by navigating them through the mouse wheel. We propose a new technique of visualizing 3D point, line or area markers in such focus stacks, by displaying them with a depth-dependent defocus, simulating the microscope's optics; this leverages on the microscopists' ability to continuously twiddle focus, while implicitly performing a shape-from-focus reconstruction of the 3D structure of the sample. User studies confirm that the approach is effective, and can complement more traditional techniques such as color-based cues. We provide two implementations, one of which computes defocus in real time on the GPU, and examples of their application.},
keywords={computer graphic equipment;computerised instrumentation;coprocessors;data visualisation;image colour analysis;image reconstruction;microscopy;3D point visualization;3D structure;GPU;artificial defocus;color based cues;marker display;microscopy z-stacks;mouse wheel;shape from focus reconstruction;Data visualization;Image color analysis;Image segmentation;Microscopy;Optical microscopy;Three dimensional displays;Depth of field;Focus stacks.;Microscopy;Animals;Computer Graphics;Computer Systems;Depth Perception;Humans;Imaging, Three-Dimensional;Mice;Microscopy;Siphonaptera;User-Computer Interface},
doi={10.1109/TVCG.2011.168},
ISSN={1077-2626},}
@ARTICLE{6064939,
author={Tricoche, X. and Garth, C. and Sanderson, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization of Topological Structures in Area-Preserving Maps},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1765-1774},
abstract={Area-preserving maps are found across a wide range of scientific and engineering problems. Their study is made challenging by the significant computational effort typically required for their inspection but more fundamentally by the fractal complexity of salient structures. The visual inspection of these maps reveals a remarkable topological picture consisting of fixed (or periodic) points embedded in so-called island chains, invariant manifolds, and regions of ergodic behavior. This paper is concerned with the effective visualization and precise topological analysis of area-preserving maps with two degrees of freedom from numerical or analytical data. Specifically, a method is presented for the automatic extraction and characterization of fixed points and the computation of their invariant manifolds, also known as separatrices, to yield a complete picture of the structures present within the scale and complexity bounds selected by the user. This general approach offers a significant improvement over the visual representations that are so far available for area-preserving maps. The technique is demonstrated on a numerical simulation of magnetic confinement in a fusion reactor.},
keywords={Poincare mapping;computational complexity;data visualisation;ergonomics;feature extraction;fractals;fusion reactors;inspection;plasma toroidal confinement;topology;area-preserving map;automatic extraction;engineering problem;ergodic behavior;fractal complexity;fusion reactor;invariant manifold;island chain;numerical data;scientific problem;topological picture;topological structure visualization;visual inspection;visual representation;Chaos theory;Data visualization;Fusion reactors;Manifolds;Topology;Poincaré map;area-preserving maps;chaos;dynamical systems;invariant manifolds.;topology},
doi={10.1109/TVCG.2011.254},
ISSN={1077-2626},}
@ARTICLE{6064940,
author={Lundstrom, C. and Rydell, T. and Forsell, C. and Persson, A. and Ynnerman, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Multi-Touch Table System for Medical Visualization: Application to Orthopedic Surgery Planning},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1775-1784},
abstract={Medical imaging plays a central role in a vast range of healthcare practices. The usefulness of 3D visualizations has been demonstrated for many types of treatment planning. Nevertheless, full access to 3D renderings outside of the radiology department is still scarce even for many image-centric specialties. Our work stems from the hypothesis that this under-utilization is partly due to existing visualization systems not taking the prerequisites of this application domain fully into account. We have developed a medical visualization table intended to better fit the clinical reality. The overall design goals were two-fold: similarity to a real physical situation and a very low learning threshold. This paper describes the development of the visualization table with focus on key design decisions. The developed features include two novel interaction components for touch tables. A user study including five orthopedic surgeons demonstrates that the system is appropriate and useful for this application domain.},
keywords={data visualisation;interactive systems;medical image processing;orthopaedics;rendering (computer graphics);surgery;touch sensitive screens;3D rendering;3D visualization;healthcare;medical imaging;medical visualization table;multitouch table system;orthopedic surgery planning;treatment planning;Biomedical image processing;Orthopedic surgery;Surgery;Three dimensional displays;Medical visualization;multitouch;tabletop display;treatment planning.;Autopsy;Computer Graphics;Humans;Imaging, Three-Dimensional;Orthopedic Procedures;Therapy, Computer-Assisted;User-Computer Interface},
doi={10.1109/TVCG.2011.224},
ISSN={1077-2626},}
@ARTICLE{6064941,
author={Nouanesengsy, B. and Teng-Yok Lee and Han-Wei Shen},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Load-Balanced Parallel Streamline Generation on Large Scale Vector Fields},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1785-1794},
abstract={Because of the ever increasing size of output data from scientific simulations, supercomputers are increasingly relied upon to generate visualizations. One use of supercomputers is to generate field lines from large scale flow fields. When generating field lines in parallel, the vector field is generally decomposed into blocks, which are then assigned to processors. Since various regions of the vector field can have different flow complexity, processors will require varying amounts of computation time to trace their particles, causing load imbalance, and thus limiting the performance speedup. To achieve load-balanced streamline generation, we propose a workload-aware partitioning algorithm to decompose the vector field into partitions with near equal workloads. Since actual workloads are unknown beforehand, we propose a workload estimation algorithm to predict the workload in the local vector field. A graph-based representation of the vector field is employed to generate these estimates. Once the workloads have been estimated, our partitioning algorithm is hierarchically applied to distribute the workload to all partitions. We examine the performance of our workload estimation and workload-aware partitioning algorithm in several timings studies, which demonstrates that by employing these methods, better scalability can be achieved with little overhead.},
keywords={data visualisation;graph theory;parallel processing;resource allocation;flow complexity;graph based representation;large scale vector fields;load balanced parallel streamline generation;load imbalance;workload aware partitioning algorithm;workload estimation algorithm;Cost function;Mathematical model;Partitioning algorithms;3D vector field visualization;Flow visualization;Parallel processing;Streamlines.},
doi={10.1109/TVCG.2011.219},
ISSN={1077-2626},}
@ARTICLE{6064942,
author={Schlegel, P. and Makhinya, M. and Pajarola, Renato},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Extinction-Based Shading and Illumination in GPU Volume Ray-Casting},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1795-1802},
abstract={Direct volume rendering has become a popular method for visualizing volumetric datasets. Even though computers are continually getting faster, it remains a challenge to incorporate sophisticated illumination models into direct volume rendering while maintaining interactive frame rates. In this paper, we present a novel approach for advanced illumination in direct volume rendering based on GPU ray-casting. Our approach features directional soft shadows taking scattering into account, ambient occlusion and color bleeding effects while achieving very competitive frame rates. In particular, multiple dynamic lights and interactive transfer function changes are fully supported. Commonly, direct volume rendering is based on a very simplified discrete version of the original volume rendering integral, including the development of the original exponential extinction into a-blending. In contrast to a-blending forming a product when sampling along a ray, the original exponential extinction coefficient is an integral and its discretization a Riemann sum. The fact that it is a sum can cleverly be exploited to implement volume lighting effects, i.e. soft directional shadows, ambient occlusion and color bleeding. We will show how this can be achieved and how it can be implemented on the GPU.},
keywords={computer graphic equipment;coprocessors;light scattering;lighting;ray tracing;rendering (computer graphics);α-blending;GPU volume ray casting;Riemann sum;ambient occlusion;color bleeding effects;direct volume rendering;directional soft shadows;dynamic lights;extinction-based shading;interactive frame rates;interactive transfer function;sophisticated illumination models;volume rendering integral;volumetric dataset visualisation;Graphics processing unit;Image color analysis;Light sources;Rendering (computer graphics);Scattering;Ambient Occlusion;Exponential Extinction.;GPU Ray-Casting;Shadows;Volume Rendering},
doi={10.1109/TVCG.2011.198},
ISSN={1077-2626},}
@ARTICLE{6064943,
author={Nelson, B. and Haimes, R. and Kirby, R.M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-Based Interactive Cut-Surface Extraction From High-Order Finite Element Fields},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1803-1811},
abstract={We present a GPU-based ray-tracing system for the accurate and interactive visualization of cut-surfaces through 3D simulations of physical processes created from spectral/hp high-order finite element methods. When used by the numerical analyst to debug the solver, the ability for the imagery to precisely reflect the data is critical. In practice, the investigator interactively selects from a palette of visualization tools to construct a scene that can answer a query of the data. This is effective as long as the implicit contract of image quality between the individual and the visualization system is upheld. OpenGL rendering of scientific visualizations has worked remarkably well for exploratory visualization for most solver results. This is due to the consistency between the use of first-order representations in the simulation and the linear assumptions inherent in OpenGL (planar fragments and color-space interpolation). Unfortunately, the contract is broken when the solver discretization is of higher-order. There have been attempts to mitigate this through the use of spatial adaptation and/or texture mapping. These methods do a better job of approximating what the imagery should be but are not exact and tend to be view-dependent. This paper introduces new rendering mechanisms that specifically deal with the kinds of native data generated by high-order finite element solvers. The exploratory visualization tools are reassessed and cast in this system with the focus on image accuracy. This is accomplished in a GPU setting to ensure interactivity.},
keywords={data visualisation;finite element analysis;image processing;ray tracing;rendering (computer graphics);solid modelling;3D simulation;GPU-based interactive cut-surface extraction;GPU-based ray-tracing system;OpenGL rendering;high-order finite element field;high-order finite element method;image accuracy;image quality;imagery;interactive visualization;scientific visualization;texture mapping;visualization system;visualization tool;Data visualization;Finite element methods;Graphics processing unit;Image color analysis;Linear approximation;Tensile stress;GPU ray-tracing;GPU-based root-finding;High-order finite elements;cut-plane extraction;cutsurface extraction.;spectral/hp elements},
doi={10.1109/TVCG.2011.206},
ISSN={1077-2626},}
@ARTICLE{6064944,
author={Rieder, C. and Kroeger, T. and Schumann, C. and Hahn, H.K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={GPU-based Real-Time Approximation of the Ablation Zone for Radiofrequency Ablation},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1812-1821},
abstract={Percutaneous radiofrequency ablation (RFA) is becoming a standard minimally invasive clinical procedure for the treatment of liver tumors. However, planning the applicator placement such that the malignant tissue is completely destroyed, is a demanding task that requires considerable experience. In this work, we present a fast GPU-based real-time approximation of the ablation zone incorporating the cooling effect of liver vessels. Weighted distance fields of varying RF applicator types are derived from complex numerical simulations to allow a fast estimation of the ablation zone. Furthermore, the heat-sink effect of the cooling blood flow close to the applicator's electrode is estimated by means of a preprocessed thermal equilibrium representation of the liver parenchyma and blood vessels. Utilizing the graphics card, the weighted distance field incorporating the cooling blood flow is calculated using a modular shader framework, which facilitates the real-time visualization of the ablation zone in projected slice views and in volume rendering. The proposed methods are integrated in our software assistant prototype for planning RFA therapy. The software allows the physician to interactively place virtual RF applicator models. The real-time visualization of the corresponding approximated ablation zone facilitates interactive evaluation of the tumor coverage in order to optimize the applicator's placement such that all cancer cells are destroyed by the ablation.},
keywords={approximation theory;biomedical electrodes;blood vessels;cancer;cellular biophysics;computer graphic equipment;coprocessors;data visualisation;haemodynamics;interactive systems;liver;medical image processing;numerical analysis;patient treatment;physiological models;rendering (computer graphics);tumours;GPU based real time approximation;RFA therapy;applicator placement planning;blood vessels;cancer cells;cooling blood flow;graphic card;heat sink effect;invasive clinical procedure;liver parenchyma;liver tumor treatment;liver vessels;malignant tissue;modular shader framework;numerical simulation;percutaneous radiofrequency ablation zone;projected slice views;real time visualization;rendering;software assistant prototype;thermal equilibrium representation;weighted distance field;Ablation;Blood flow;Electrodes;Graphics processing unit;Heat sinks;Mathematical model;Radio frequency;Rendering (computer graphics);GPU;Radiofrequency ablation;ablation zone visualization;distance field;interaction.;volume rendering;Catheter Ablation;Computer Graphics;Computer Simulation;Computer Systems;Humans;Liver Neoplasms;Mathematical Concepts;Software;Surgery, Computer-Assisted},
doi={10.1109/TVCG.2011.207},
ISSN={1077-2626},}
@ARTICLE{6064945,
author={Bennett, J.C. and Krishnamoorthy, V. and Shusen Liu and Grout, R.W. and Hawkes, E.R. and Chen, J.H. and Shepherd, J. and Pascucci, V. and Bremer, P.-T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Feature-Based Statistical Analysis of Combustion Simulation Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1822-1831},
abstract={We present a new framework for feature-based statistical analysis of large-scale scientific data and demonstrate its effectiveness by analyzing features from Direct Numerical Simulations (DNS) of turbulent combustion. Turbulent flows are ubiquitous and account for transport and mixing processes in combustion, astrophysics, fusion, and climate modeling among other disciplines. They are also characterized by coherent structure or organized motion, i.e. nonlocal entities whose geometrical features can directly impact molecular mixing and reactive processes. While traditional multi-point statistics provide correlative information, they lack nonlocal structural information, and hence, fail to provide mechanistic causality information between organized fluid motion and mixing and reactive processes. Hence, it is of great interest to capture and track flow features and their statistics together with their correlation with relevant scalar quantities, e.g. temperature or species concentrations. In our approach we encode the set of all possible flow features by pre-computing merge trees augmented with attributes, such as statistical moments of various scalar fields, e.g. temperature, as well as length-scales computed via spectral analysis. The computation is performed in an efficient streaming manner in a pre-processing step and results in a collection of meta-data that is orders of magnitude smaller than the original simulation data. This meta-data is sufficient to support a fully flexible and interactive analysis of the features, allowing for arbitrary thresholds, providing per-feature statistics, and creating various global diagnostics such as Cumulative Density Functions (CDFs), histograms, or time-series. We combine the analysis with a rendering of the features in a linked-view browser that enables scientists to interactively explore, visualize, and analyze the equivalent of one terabyte of simulation data. We highlight the utility of this new framework for combustion s- ience; however, it is applicable to many other science domains.},
keywords={chemically reactive flow;combustion;flow simulation;interactive systems;meta data;mixing;numerical analysis;rendering (computer graphics);statistical analysis;turbulence;astrophysics;climate modeling;combustion science;combustion simulation data;cumulative density function;data streaming;direct numerical simulation;feature based statistical analysis;geometrical features;histograms;interactive analysis;large scale scientific data;linked view browser;merge trees;meta data collection;molecular mixing process;molecular reactive process;nonlocal entities;spectral analysis;time series;transport process;turbulent combustion;turbulent flow;Data mining;Data models;Feature extraction;Information analysis;Statistical analysis;Data analysis;Data exploration;Multi-variate Data.;Statistics;Topology;Visualization in Physical Sciences and Engineering},
doi={10.1109/TVCG.2011.199},
ISSN={1077-2626},}
@ARTICLE{6064946,
author={Mirzargar, M. and Entezari, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Quasi Interpolation With Voronoi Splines},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1832-1841},
abstract={We present a quasi interpolation framework that attains the optimal approximation-order of Voronoi splines for reconstruction of volumetric data sampled on general lattices. The quasi interpolation framework of Voronoi splines provides an unbiased reconstruction method across various lattices. Therefore this framework allows us to analyze and contrast the sampling-theoretic performance of general lattices, using signal reconstruction, in an unbiased manner. Our quasi interpolation methodology is implemented as an efficient FIR filter that can be applied online or as a preprocessing step. We present visual and numerical experiments that demonstrate the improved accuracy of reconstruction across lattices, using the quasi interpolation framework.},
keywords={FIR filters;computational geometry;interpolation;signal reconstruction;signal sampling;splines (mathematics);FIR filter;Voronoi splines;quasi interpolation;sampling theory;signal reconstruction;unbiased reconstruction method;volumetric data struction;Convolution;Image reconstruction;Interpolation;Spline;Box spline.;Quasi Interpolation;Volume Visualization;Voronoi Spline},
doi={10.1109/TVCG.2011.230},
ISSN={1077-2626},}
@ARTICLE{6064947,
author={Correa, C. and Lindstrom, P. and Bremer, P.-T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Topological Spines: A Structure-preserving Visual Representation of Scalar Fields},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1842-1851},
abstract={We present topological spines-a new visual representation that preserves the topological and geometric structure of a scalar field. This representation encodes the spatial relationships of the extrema of a scalar field together with the local volume and nesting structure of the surrounding contours. Unlike other topological representations, such as contour trees, our approach preserves the local geometric structure of the scalar field, including structural cycles that are useful for exposing symmetries in the data. To obtain this representation, we describe a novel mechanism based on the extraction of extremum graphs-sparse subsets of the Morse-Smale complex that retain the important structural information without the clutter and occlusion problems that arise from visualizing the entire complex directly. Extremum graphs form a natural multiresolution structure that allows the user to suppress noise and enhance topological features via the specification of a persistence range. Applications of our approach include the visualization of 3D scalar fields without occlusion artifacts, and the exploratory analysis of high-dimensional functions.},
keywords={computational geometry;data visualisation;graph theory;natural sciences computing;Morse-Smale complex;clutter problems;contour trees;extremum graphs;geometric structure;occlusion problems;scalar fields;structure preserving visual representation;topological spines;Approximation methods;Data visualization;Manifolds;Topology;Morse-Smale complex.;Scalar field topology;extremum graph;topological spine},
doi={10.1109/TVCG.2011.244},
ISSN={1077-2626},}
@ARTICLE{6064948,
author={Correa, C. and Lindstrom, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Towards Robust Topology of Sparsely Sampled Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1852-1861},
abstract={Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods - a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.},
keywords={data analysis;data visualisation;gradient methods;graph theory;mesh generation;pattern clustering;sampling methods;set theory;Delaunay triangulation;empty region graph;gradient estimation;high dimensional data set;high dimensional signal;k-nearest neighbor;low dimensional data set;neighborhood connection;neighborhood graph;neighborhood strategy;neighborhood-based analysis tool;robust data analysis;scalar function visualization;sparse irregular sampling;sparsely sampled data;spurious connection;topological clustering;topological decomposition;Data mining;Noise measurement;Robustness;Topology;Neighborhood graphs;sparsely sampled data.;topology},
doi={10.1109/TVCG.2011.245},
ISSN={1077-2626},}
@ARTICLE{6064949,
author={Moran, P.J. and Ellsworth, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1862-1871},
abstract={We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C0 continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates "stitching cells" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.},
keywords={data visualisation;hydrodynamics;interpolation;3D domain;AMR data visualization;cell-centered adaptive mesh refinement;gridded hydrodynamic data;multi-level dual-mesh interpolation;ray-cast visualizations;Adaptation models;Image edge detection;Interpolation;Isosurfaces;Rendering (computer graphics);AMR;Adaptive mesh refinement;Enzo;dual meshes;interpolation;isosurfaces;ray casting;stitching cells.},
doi={10.1109/TVCG.2011.252},
ISSN={1077-2626},}
@ARTICLE{6064950,
author={Waser, J. and Ribicic, H. and Fuchs, R. and Hirsch, C. and Schindler, B. and Bloschl, G. and Groller, M.E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Nodes on Ropes: A Comprehensive Data and Control Flow for Steering Ensemble Simulations},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1872-1881},
abstract={Flood disasters are the most common natural risk and tremendous efforts are spent to improve their simulation and management. However, simulation-based investigation of actions that can be taken in case of flood emergencies is rarely done. This is in part due to the lack of a comprehensive framework which integrates and facilitates these efforts. In this paper, we tackle several problems which are related to steering a flood simulation. One issue is related to uncertainty. We need to account for uncertain knowledge about the environment, such as levee-breach locations. Furthermore, the steering process has to reveal how these uncertainties in the boundary conditions affect the confidence in the simulation outcome. Another important problem is that the simulation setup is often hidden in a black-box. We expose system internals and show that simulation steering can be comprehensible at the same time. This is important because the domain expert needs to be able to modify the simulation setup in order to include local knowledge and experience. In the proposed solution, users steer parameter studies through the World Lines interface to account for input uncertainties. The transport of steering information to the underlying data-flow components is handled by a novel meta-flow. The meta-flow is an extension to a standard data-flow network, comprising additional nodes and ropes to abstract parameter control. The meta-flow has a visual representation to inform the user about which control operations happen. Finally, we present the idea to use the data-flow diagram itself for visualizing steering information and simulation results. We discuss a case-study in collaboration with a domain expert who proposes different actions to protect a virtual city from imminent flooding. The key to choosing the best response strategy is the ability to compare different regions of the parameter space while retaining an understanding of what is happening inside the data-flow system.},
keywords={data flow computing;data mining;data visualisation;digital simulation;disasters;emergency services;floods;risk management;World Lines interface;abstract parameter control;boundary conditions;data flow components;data flow diagram;flood disaster management;flood emergency response strategy;flood simulation;meta flow;natural risk;standard data flow network;steering ensemble simulation;steering information transmission;steering information visualization;virtual city;visual knowledge discovery;visual representation;Control systems;Data visualization;Disaster management;Emergency services;Navigation;Data-Flow;Emergency/Disaster Management;Meta-Flow;Parameter Study;Uncertainty;Visual Knowledge Discovery;Visualization System and Toolkit Design;Visualization of Control.},
doi={10.1109/TVCG.2011.225},
ISSN={1077-2626},}
@ARTICLE{6064951,
author={Oeltze, S. and Freiler, W. and Hillert, R. and Doleisch, H. and Preim, B. and Schubert, W.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1882-1891},
abstract={In Toponomics, the function protein pattern in cells or tissue (the toponome) is imaged and analyzed for applications in toxicology, new drug development and patient-drug-interaction. The most advanced imaging technique is robot-driven multi-parameter fluorescence microscopy. This technique is capable of co-mapping hundreds of proteins and their distribution and assembly in protein clusters across a cell or tissue sample by running cycles of fluorescence tagging with monoclonal antibodies or other affinity reagents, imaging, and bleaching in situ. The imaging results in complex multi-parameter data composed of one slice or a 3D volume per affinity reagent. Biologists are particularly interested in the localization of co-occurring proteins, the frequency of co-occurrence and the distribution of co-occurring proteins across the cell. We present an interactive visual analysis approach for the evaluation of multi-parameter fluorescence microscopy data in toponomics. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The feature specification result is linked to all views establishing a focus+context visualization in 3D. In a new attribute view, we integrate techniques from graph visualization. Each node in the graph represents an affinity reagent while each edge represents two co-occurring affinity reagent bindings. The graph visualization is enhanced by glyphs which encode specific properties of the binding. The graph view is equipped with brushing facilities. By brushing in the spatial and attribute domain, the biologist achieves a better understanding of the function protein patterns of a cell. Furthermore, an interactive table view is integrated which summarizes unique fluorescence patterns. We discuss our approach with respect to a cell probe containing lymphocytes and a prostate tissue section.},
keywords={biological tissues;biology computing;data visualisation;drugs;graph theory;interactive systems;proteins;toxicology;advanced imaging technique;cells;drug development;focus+context visualization;function protein pattern;glyphs;graph visualization;graph-based visual analysis;high-dimensional fluorescence microscopy data;interactive analysis;interactive visual analysis;lymphocytes;multi-parameter fluorescence microscopy data;patient-drug-interaction;prostate tissue;protein clusters;reagent bindings;robot-driven multi-parameter fluorescence microscopy;toponomics;toxicology;Biological information theory;Fluorescence;Graphics;Image color analysis;Microscopy;Three dimensional displays;Fluorescence Microscopy;Graph Visualization.;Protein Interaction;Toponomics;Visual Analytics;Computer Graphics;Data Interpretation, Statistical;Humans;Imaging, Three-Dimensional;Lymphocytes;Male;Microscopy, Fluorescence;Neoplasm Proteins;Prostatic Neoplasms;Proteomics},
doi={10.1109/TVCG.2011.217},
ISSN={1077-2626},}
@ARTICLE{6064952,
author={Torsney-Weir, T. and Saad, A. and Moller, T. and Hege, H.-C. and Weber, B. and Verbavatz, J. and Bergner, S.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Tuner: Principled Parameter Finding for Image Segmentation Algorithms Using Visual Response Surface Exploration},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1892-1901},
abstract={In this paper we address the difficult problem of parameter-finding in image segmentation. We replace a tedious manual process that is often based on guess-work and luck by a principled approach that systematically explores the parameter space. Our core idea is the following two-stage technique: We start with a sparse sampling of the parameter space and apply a statistical model to estimate the response of the segmentation algorithm. The statistical model incorporates a model of uncertainty of the estimation which we use in conjunction with the actual estimate in (visually) guiding the user towards areas that need refinement by placing additional sample points. In the second stage the user navigates through the parameter space in order to determine areas where the response value (goodness of segmentation) is high. In our exploration we rely on existing ground-truth images in order to evaluate the "goodness" of an image segmentation technique. We evaluate its usefulness by demonstrating this technique on two image segmentation algorithms: a three parameter model to detect microtubules in electron tomograms and an eight parameter model to identify functional regions in dynamic Positron Emission Tomography scans.},
keywords={Gaussian processes;data visualisation;image sampling;image segmentation;statistical analysis;dynamic positron emission tomography;electron tomogram;ground-truth image;image segmentation;parameter finding;parameter model;parameter space;response value;segmentation algorithm;sparse sampling;statistical model;visual analysis tool;visual response surface exploration;Computational modeling;Gaussian processes;Image segmentation;Response surface methodology;Uncertainty;Gaussian Process Model.;Image segmentation;Parameter exploration;Algorithms;Brain;Computer Graphics;Computer Simulation;Electron Microscope Tomography;Humans;Image Interpretation, Computer-Assisted;Image Processing, Computer-Assisted;Microtubules;Models, Statistical;Positron-Emission Tomography;Software},
doi={10.1109/TVCG.2011.248},
ISSN={1077-2626},}
@ARTICLE{6064953,
author={Bei Wang and Summa, B. and Pascucci, V. and Vejdemo-Johansson, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Branching and Circular Features in High Dimensional Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1902-1911},
abstract={Large observations and simulations in scientific research give rise to high-dimensional data sets that present many challenges and opportunities in data analysis and visualization. Researchers in application domains such as engineering, computational biology, climate study, imaging and motion capture are faced with the problem of how to discover compact representations of highdimensional data while preserving their intrinsic structure. In many applications, the original data is projected onto low-dimensional space via dimensionality reduction techniques prior to modeling. One problem with this approach is that the projection step in the process can fail to preserve structure in the data that is only apparent in high dimensions. Conversely, such techniques may create structural illusions in the projection, implying structure not present in the original high-dimensional data. Our solution is to utilize topological techniques to recover important structures in high-dimensional data that contains non-trivial topology. Specifically, we are interested in high-dimensional branching structures. We construct local circle-valued coordinate functions to represent such features. Subsequently, we perform dimensionality reduction on the data while ensuring such structures are visually preserved. Additionally, we study the effects of global circular structures on visualizations. Our results reveal never-before-seen structures on real-world data sets from a variety of applications.},
keywords={computational geometry;data analysis;data structures;data visualisation;topology;circular features;computational biology;data analysis;data visualization;dimensionality reduction techniques;global circular structures;high dimensional data sets;high-dimensional branching structures;high-dimensional data representation;local circle-valued coordinate functions;motion capture;nontrivial topology;topological techniques;Algorithm design and analysis;Approximation methods;Data visualization;Feature extraction;Topology;Dimensionality reduction;circular coordinates;topological analysis.;visualization;Algorithms;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Humans;Imaging, Three-Dimensional;Motion;Nonlinear Dynamics},
doi={10.1109/TVCG.2011.177},
ISSN={1077-2626},}
@ARTICLE{6064954,
author={Lehmann, D.J. and Theisel, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Features in Continuous Parallel Coordinates},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1912-1921},
abstract={Continuous Parallel Coordinates (CPC) are a contemporary visualization technique in order to combine several scalar fields, given over a common domain. They facilitate a continuous view for parallel coordinates by considering a smooth scalar field instead of a finite number of straight lines. We show that there are feature curves in CPC which appear to be the dominant structures of a CPC. We present methods to extract and classify them and demonstrate their usefulness to enhance the visualization of CPCs. In particular, we show that these feature curves are related to discontinuities in Continuous Scatterplots (CSP). We show this by exploiting a curve-curve duality between parallel and Cartesian coordinates, which is a generalization of the well-known point-line duality. Furthermore, we illustrate the theoretical considerations. Concluding, we discuss relations and aspects of the CPC's/CSP's features concerning the data analysis.},
keywords={curve fitting;data visualisation;duality (mathematics);CPC;CSP;Cartesian coordinate;contemporary visualization technique;continuous parallel coordinates;continuous scatterplot;curve-curve duality;feature curve;smooth scalar field;Data visualization;Feature extraction;Mathematical model;Three dimensional displays;Vectors;Visualization;Features;Parallel Coordinates;Topology;Visualization.},
doi={10.1109/TVCG.2011.200},
ISSN={1077-2626},}
@ARTICLE{6064955,
author={Lindemann, F. and Ropinski, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={About the Influence of Illumination Models on Image Comprehension in Direct Volume Rendering},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1922-1931},
abstract={In this paper, we present a user study in which we have investigated the influence of seven state-of-the-art volumetric illumination models on the spatial perception of volume rendered images. Within the study, we have compared gradient-based shading with half angle slicing, directional occlusion shading, multidirectional occlusion shading, shadow volume propagation, spherical harmonic lighting as well as dynamic ambient occlusion. To evaluate these models, users had to solve three tasks relying on correct depth as well as size perception. Our motivation for these three tasks was to find relations between the used illumination model, user accuracy and the elapsed time. In an additional task, users had to subjectively judge the output of the tested models. After first reviewing the models and their features, we will introduce the individual tasks and discuss their results. We discovered statistically significant differences in the testing performance of the techniques. Based on these findings, we have analyzed the models and extracted those features which are possibly relevant for the improved spatial comprehension in a relational task. We believe that a combination of these distinctive features could pave the way for a novel illumination model, which would be optimized based on our findings.},
keywords={gradient methods;lighting;rendering (computer graphics);depth perception;direct volume rendering;directional occlusion shading;dynamic ambient occlusion;gradient based shading;half angle slicing;image comprehension;multidirectional occlusion shading;shadow volume propagation;size perception;spatial comprehension;spherical harmonic lighting;volumetric illumination models;Computational modeling;Harmonic analysis;Image color analysis;Light sources;Rendering (computer graphics);Solid modeling;Volumetric illumination;spatial comprehension.;volume rendering},
doi={10.1109/TVCG.2011.161},
ISSN={1077-2626},}
@ARTICLE{6064956,
author={Ruiz, M. and Bardera, A. and Boada, I. and Viola, I. and Feixas, M. and Sbert, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Automatic Transfer Functions Based on Informational Divergence},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1932-1941},
abstract={In this paper we present a framework to define transfer functions from a target distribution provided by the user. A target distribution can reflect the data importance, or highly relevant data value interval, or spatial segmentation. Our approach is based on a communication channel between a set of viewpoints and a set of bins of a volume data set, and it supports 1D as well as 2D transfer functions including the gradient information. The transfer functions are obtained by minimizing the informational divergence or Kullback-Leibler distance between the visibility distribution captured by the viewpoints and a target distribution selected by the user. The use of the derivative of the informational divergence allows for a fast optimization process. Different target distributions for 1D and 2D transfer functions are analyzed together with importance-driven and view-based techniques.},
keywords={optical transfer function;optimisation;rendering (computer graphics);visibility;1D transfer functions;2D transfer functions;Kullback-Leibler distance;automatic transfer functions;communication channel;data value interval;informational divergence;optimization process;spatial segmentation;target distribution;visibility distribution;Data visualization;Information analysis;Mutual information;Probability distribution;Transfer functions;Information theory;Informational divergence;Kullback-Leibler distance.;Transfer function},
doi={10.1109/TVCG.2011.173},
ISSN={1077-2626},}
@ARTICLE{6064957,
author={Bartram, L. and Cheung, B. and Stone, M.C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={The Effect of Colour and Transparency on the Perception of Overlaid Grids},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1942-1948},
abstract={Overlaid reference elements need to be sufficiently visible to effectively relate to the underlying information, but not so obtrusive that they clutter the presentation. We seek to create guidelines for presenting such structures through experimental studies to define boundary conditions for visual intrusiveness. We base our work on the practice of designers, who use transparency to integrate overlaid grids with their underlying imagery. Previous work discovered a useful range of alpha values for black or white grids overlayed on scatterplot images rendered in shades of gray over gray backgrounds of different lightness values. This work compares black grids to blue and red ones on different image types of scatterplots and maps. We expected that the coloured grids over grayscale images would be more visually salient than black ones, resulting in lower alpha values. Instead, we found that there was no significant difference between the boundaries set for red and black grids, but that the boundaries for blue grids were set consistently higher (more opaque). As in our previous study, alpha values are affected by image density rather than image type, and are consistently lower than many default settings. These results have implications for the design of subtle reference structures.},
keywords={data visualisation;rendering (computer graphics);alpha value;boundary condition;colour effect;grayscale image;image density;lightness value;overlaid grid;visual intrusiveness;Complexity theory;Data visualization;Educational institutions;Image color analysis;Information visualization;applied perception;automated presentation;computational aesthetics.;visual design},
doi={10.1109/TVCG.2011.242},
ISSN={1077-2626},}
@ARTICLE{6064958,
author={Hlawatsch, M. and Leube, P. and Nowak, W. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Flow Radar Glyphs amp;#8212;Static Visualization of Unsteady Flow with Uncertainty},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1949-1958},
abstract={A new type of glyph is introduced to visualize unsteady flow with static images, allowing easier analysis of time-dependent phenomena compared to animated visualization. Adopting the visual metaphor of radar displays, this glyph represents flow directions by angles and time by radius in spherical coordinates. Dense seeding of flow radar glyphs on the flow domain naturally lends itself to multi-scale visualization: zoomed-out views show aggregated overviews, zooming-in enables detailed analysis of spatial and temporal characteristics. Uncertainty visualization is supported by extending the glyph to display possible ranges of flow directions. The paper focuses on 2D flow, but includes a discussion of 3D flow as well. Examples from CFD and the field of stochastic hydrogeology show that it is easy to discriminate regions of different spatiotemporal flow behavior and regions of different uncertainty variations in space and time. The examples also demonstrate that parameter studies can be analyzed because the glyph design facilitates comparative visualization. Finally, different variants of interactive GPU-accelerated implementations are discussed.},
keywords={computational fluid dynamics;computer graphic equipment;coprocessors;data visualisation;hydrology;interactive systems;2D flow;3D flow;CFD;animated visualization;different spatiotemporal flow behavior;flow radar glyphs;interactive GPU accelerated implementations;radar displays;static images;static unsteady flow visualization;stochastic hydrogeology;visual metaphor;zoomed out views;Data visualization;Radar imaging;Three dimensional displays;Uncertainty;Vectors;Visualization;glyph;uncertainty;unsteady flow.},
doi={10.1109/TVCG.2011.203},
ISSN={1077-2626},}
@ARTICLE{6064959,
author={Ziyi Zheng and Ahmed, N. and Mueller, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1959-1968},
abstract={The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.},
keywords={data visualisation;entropy;optimisation;pattern clustering;set theory;2D entropy map;entropy-based viewpoint selection criteria;feature clustering framework;feature-clustering;gradient variation;iView;informative views;interactive track-ball interface;k-means;normal variation;salient composite feature detection;set-cover optimization algorithm;summary presentation;unguided visual exploration;viewpoint suggestion pipeline;visibility-based transfer function;volume rendering;volume visualization;volumetric data;Clustering algorithms;Entropy;Feature extraction;Rendering (computer graphics);Transfer functions;Direct volume rendering;ant colony optimization.;entropy;k-means;set-cover problem;view suggestion;Algorithms;Animals;Ants;Cluster Analysis;Computer Graphics;Computer Simulation;Databases, Factual;Humans;Imaging, Three-Dimensional;Tooth},
doi={10.1109/TVCG.2011.218},
ISSN={1077-2626},}
@ARTICLE{6064960,
author={Haidacher, M. and Bruckner, S. and Groller, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Volume Analysis Using Multimodal Surface Similarity},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1969-1978},
abstract={The combination of volume data acquired by multiple modalities has been recognized as an important but challenging task. Modalities often differ in the structures they can delineate and their joint information can be used to extend the classification space. However, they frequently exhibit differing types of artifacts which makes the process of exploiting the additional information non-trivial. In this paper, we present a framework based on an information-theoretic measure of isosurface similarity between different modalities to overcome these problems. The resulting similarity space provides a concise overview of the differences between the two modalities, and also serves as the basis for an improved selection of features. Multimodal classification is expressed in terms of similarities and dissimilarities between the isosurfaces of individual modalities, instead of data value combinations. We demonstrate that our approach can be used to robustly extract features in applications such as dual energy computed tomography of parts in industrial manufacturing.},
keywords={computerised tomography;data visualisation;pattern classification;classification space;data value combinations;dual energy computed tomography;industrial manufacturing;information theoretic measure;isosurface similarity;multimodal classification;multimodal surface similarity;volume analysis;Computed tomography;Histograms;Isosurfaces;Mutual information;Transfer functions;Multimodal data;surface similarity.;volume visualization;Angiography;Brain;Computer Graphics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Tomography, X-Ray Computed},
doi={10.1109/TVCG.2011.258},
ISSN={1077-2626},}
@ARTICLE{6064961,
author={Guoning Chen and Palke, D. and Zhongzang Lin and Yeh, H. and Vincent, P. and Laramee, R.S. and Zhang, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Asymmetric Tensor Field Visualization for Surfaces},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1979-1988},
abstract={Asymmetric tensor field visualization can provide important insight into fluid flows and solid deformations. Existing techniques for asymmetric tensor fields focus on the analysis, and simply use evenly-spaced hyperstreamlines on surfaces following eigenvectors and dual-eigenvectors in the tensor field. In this paper, we describe a hybrid visualization technique in which hyperstreamlines and elliptical glyphs are used in real and complex domains, respectively. This enables a more faithful representation of flow behaviors inside complex domains. In addition, we encode tensor magnitude, an important quantity in tensor field analysis, using the density of hyperstreamlines and sizes of glyphs. This allows colors to be used to encode other important tensor quantities. To facilitate quick visual exploration of the data from different viewpoints and at different resolutions, we employ an efficient image-space approach in which hyperstreamlines and glyphs are generated quickly in the image plane. The combination of these techniques leads to an efficient tensor field visualization system for domain scientists. We demonstrate the effectiveness of our visualization technique through applications to complex simulated engine fluid flow and earthquake deformation data. Feedback from domain expert scientists, who are also co-authors, is provided.},
keywords={computational fluid dynamics;data visualisation;deformation;earthquake engineering;geophysics computing;asymmetric tensor field visualization;complex simulated engine fluid flow;dual eigenvectors;earthquake deformation data;elliptical glyphs;evenly spaced hyperstreamlines;fluid flows;hybrid visualization technique;solid deformations;tensor field analysis;tensor magnitude;Data visualization;Eigenvalues and eigenfunctions;Manifolds;Tensile stress;Visualization;Tensor field visualization;asymmetric tensor fields;earthquakeengineering;fluid dynamics;glyph packing;hyperstreamline placement;solid deformation;vector field visualization;view-dependent visualization.},
doi={10.1109/TVCG.2011.170},
ISSN={1077-2626},}
@ARTICLE{6064962,
author={Pietroni, N. and Massimiliano, C. and Cignoni, P. and Scopigno, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={An Interactive Local Flattening Operator to Support Digital Investigations on Artwork Surfaces},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1989-1996},
abstract={Analyzing either high-frequency shape detail or any other 2D fields (scalar or vector) embedded over a 3D geometry is a complex task, since detaching the detail from the overall shape can be tricky. An alternative approach is to move to the 2D space, resolving shape reasoning to easier image processing techniques. In this paper we propose a novel framework for the analysis of 2D information distributed over 3D geometry, based on a locally smooth parametrization technique that allows us to treat local 3D data in terms of image content. The proposed approach has been implemented as a sketch-based system that allows to design with a few gestures a set of (possibly overlapping) parameterizations of rectangular portions of the surface. We demonstrate that, due to the locality of the parametrization, the distortion is under an acceptable threshold, while discontinuities can be avoided since the parametrized geometry is always homeomorphic to a disk. We show the effectiveness of the proposed technique to solve specific Cultural Heritage (CH) tasks: the analysis of chisel marks over the surface of a unfinished sculpture and the local comparison of multiple photographs mapped over the surface of an artwork. For this very difficult task, we believe that our framework and the corresponding tool are the first steps toward a computer-based shape reasoning system, able to support CH scholars with a medium they are more used to.},
keywords={art;history;image restoration;inference mechanisms;interactive systems;shape recognition;2D fields;2D information analysis;3D geometry;artwork surfaces;chisel marks analysis;computer-based shape reasoning system;cultural heritage;high-frequency shape detail;image content;image processing technique;interactive local flattening operator;local 3D data;locally smooth parametrization technique;multiple photographs;sketch-based system;unfinished sculpture;Geometry;Image processing;Length measurement;Shape analysis;Solid modeling;Surface treatment;Three dimensional displays;Cultural Heritage;Surface characterization;image processing.;interactive inspection;mesh parameterization},
doi={10.1109/TVCG.2011.165},
ISSN={1077-2626},}
@ARTICLE{6064963,
author={Marino, J. and Wei Zeng and Xianfeng Gu and Kaufman, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Context Preserving Maps of Tubular Structures},
year={2011},
month={Dec},
volume={17},
number={12},
pages={1997-2004},
abstract={When visualizing tubular 3D structures, external representations are often used for guidance and display, and such views in 2D can often contain occlusions. Virtual dissection methods have been proposed where the entire 3D structure can be mapped to the 2D plane, though these will lose context by straightening curved sections. We present a new method of creating maps of 3D tubular structures that yield a succinct view while preserving the overall geometric structure. Given a dominant view plane for the structure, its curve skeleton is first projected to a 2D skeleton. This 2D skeleton is adjusted to account for distortions in length, modified to remove intersections, and optimized to preserve the shape of the original 3D skeleton. Based on this shaped 2D skeleton, a boundary for the map of the object is obtained based on a slicing path through the structure and the radius around the skeleton. The sliced structure is conformally mapped to a rectangle and then deformed via harmonic mapping to match the boundary placement. This flattened map preserves the general geometric context of a 3D object in a 2D display, and rendering of this flattened map can be accomplished using volumetric ray casting. We have evaluated our method on real datasets of human colon models.},
keywords={biology computing;computer displays;data visualisation;orthopaedics;ray tracing;rendering (computer graphics);shape recognition;solid modelling;2D skeleton display;3D skeleton shape;boundary placement;context preserving map;flattened map;geometric structure;harmonic mapping;human colon model;path slicing;sliced structure;tubular 3D structure visualization;tubular structure;virtual dissection method;volumetric ray casting;Geometry;Navigation;Shape analysis;Three dimensional displays;Volume measurement;Geometry-based technique;biomedical visualization;conformal mapping.;medical visualization;volume rendering;Colon;Colonography, Computed Tomographic;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional},
doi={10.1109/TVCG.2011.182},
ISSN={1077-2626},}
@ARTICLE{6064964,
author={Guangyu Zou and Jiaxi Hu and Xianfeng Gu and Jing Hua},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Authalic Parameterization of General Surfaces Using Lie Advection},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2005-2014},
abstract={Parameterization of complex surfaces constitutes a major means of visualizing highly convoluted geometric structures as well as other properties associated with the surface. It also enables users with the ability to navigate, orient, and focus on regions of interest within a global view and overcome the occlusions to inner concavities. In this paper, we propose a novel area-preserving surface parameterization method which is rigorous in theory, moderate in computation, yet easily extendable to surfaces of non-disc and closed-boundary topologies. Starting from the distortion induced by an initial parameterization, an area restoring diffeomorphic flow is constructed as a Lie advection of differential 2-forms along the manifold, which yields equality of the area elements between the domain and the original surface at its final state. Existence and uniqueness of result are assured through an analytical derivation. Based upon a triangulated surface representation, we also present an efficient algorithm in line with discrete differential modeling. As an exemplar application, the utilization of this method for the effective visualization of brain cortical imaging modalities is presented. Compared with conformal methods, our method can reveal more subtle surface patterns in a quantitative manner. It, therefore, provides a competitive alternative to the existing parameterization techniques for better surface-based analysis in various scenarios.},
keywords={computational geometry;data visualisation;Lie advection;area-preserving surface parameterization;authalic parameterization;brain cortical imaging modality;complex surface parameterization;diffeomorphic flow;discrete differential modeling;general surface;geometric structure;triangulated surface representation;Boundary conditions;Geometry;Manifolds;Measurement;Surface treatment;Vectors;Area-preserving surface parameterization;Lie advection;differential forms;surface visualization.;Algorithms;Brain;Computer Graphics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Positron-Emission Tomography},
doi={10.1109/TVCG.2011.171},
ISSN={1077-2626},}
@ARTICLE{6064965,
author={Yi Gu and Chaoli Wang},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={TransGraph: Hierarchical Exploration of Transition Relationships in Time-Varying Volumetric Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2015-2024},
abstract={A fundamental challenge for time-varying volume data analysis and visualization is the lack of capability to observe and track data change or evolution in an occlusion-free, controllable, and adaptive fashion. In this paper, we propose to organize a timevarying data set into a hierarchy of states. By deriving transition probabilities among states, we construct a global map that captures the essential transition relationships in the time-varying data. We introduce the TransGraph, a graph-based representation to visualize hierarchical state transition relationships. The TransGraph not only provides a visual mapping that abstracts data evolution over time in different levels of detail, but also serves as a navigation tool that guides data exploration and tracking. The user interacts with the TransGraph and makes connection to the volumetric data through brushing and linking. A set of intuitive queries is provided to enable knowledge extraction from time-varying data. We test our approach with time-varying data sets of different characteristics and the results show that the TransGraph can effectively augment our ability in understanding time-varying data.},
keywords={data analysis;data mining;data structures;data visualisation;graph theory;probability;TransGraph;data visualization;graph based representation;hierarchical state transition relationships;knowledge extraction;navigation tool;occlusion free;time-varying volumetric data analysis;transition probability;visual mapping;Data mining;Data visualization;Hierarchical systems;Histograms;User interfaces;Time-varying data visualization;hierarchical representation;states;transition relationship;user interface.},
doi={10.1109/TVCG.2011.246},
ISSN={1077-2626},}
@ARTICLE{6064966,
author={Lindow, N. and Baum, D. and Hege, H.-C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Voronoi-Based Extraction and Visualization of Molecular Paths},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2025-2034},
abstract={Visual analysis is widely used to study the behavior of molecules. Of particular interest are the analysis of molecular interactions and the investigation of binding sites. For large molecules, however, it is difficult to detect possible binding sites and paths leading to these sites by pure visual inspection. In this paper, we present new methods for the computation and visualization of potential molecular paths. Using a novel filtering method, we extract the significant paths from the Voronoi diagram of spheres. For the interactive visualization of molecules and their paths, we present several methods using deferred shading and other state-of-theart techniques. To allow for a fast overview of reachable regions of the molecule, we illuminate the molecular surface using a large number of light sources placed on the extracted paths. We also provide a method to compute the extension surface of selected paths and visualize it using the skin surface. Furthermore, we use the extension surface to clip the molecule to allow easy visual tracking of even deeply buried paths. The methods are applied to several proteins to demonstrate their usefulness.},
keywords={computational geometry;data visualisation;feature extraction;information filtering;inspection;interactive systems;lighting;molecular biophysics;skin;Voronoi-based extraction;binding site detection;deferred shading technique;filtering method;interactive molecule visualization;light sources;molecular interaction;molecular path visualization;molecular surface illumination;skin surface;visual analysis;visual inspection;visual tracking;Atomic measurements;Cavity resonators;Filtering theory;Logic gates;Molecular computing;Topology;Molecular visualization;data filtering;geometry-based techniques;view-dependent visualization.;Algorithms;Binding Sites;Computer Graphics;Computer Simulation;Models, Molecular;Protein Interaction Domains and Motifs;Proteins;Surface Properties},
doi={10.1109/TVCG.2011.259},
ISSN={1077-2626},}
@ARTICLE{6064967,
author={Thomas, D.M. and Natarajan, V.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Symmetry in Scalar Field Topology},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2035-2044},
abstract={Study of symmetric or repeating patterns in scalar fields is important in scientific data analysis because it gives deep insights into the properties of the underlying phenomenon. Though geometric symmetry has been well studied within areas like shape processing, identifying symmetry in scalar fields has remained largely unexplored due to the high computational cost of the associated algorithms. We propose a computationally efficient algorithm for detecting symmetric patterns in a scalar field distribution by analysing the topology of level sets of the scalar field. Our algorithm computes the contour tree of a given scalar field and identifies subtrees that are similar. We define a robust similarity measure for comparing subtrees of the contour tree and use it to group similar subtrees together. Regions of the domain corresponding to subtrees that belong to a common group are extracted and reported to be symmetric. Identifying symmetry in scalar fields finds applications in visualization, data exploration, and feature detection. We describe two applications in detail: symmetry-aware transfer function design and symmetry-aware isosurface extraction.},
keywords={data analysis;data visualisation;topology;trees (mathematics);contour tree;data exploration;feature detection;geometric symmetry;repeating pattern;robust similarity measure;scalar field distribution;scalar field topology;scientific data analysis;shape processing;symmetric pattern;symmetry-aware isosurface extraction;symmetry-aware transfer function design;visualization;Level set;Robustness;Shape analysis;Topology;Transfer functions;Vectors;Scalar field symmetry;contour tree;isosurface extraction;persistence;similarity measure;transfer function design.},
doi={10.1109/TVCG.2011.236},
ISSN={1077-2626},}
@ARTICLE{6064968,
author={Reininghaus, J. and Kotava, N. and Gunther, D. and Kasten, J. and Hagen, H. and Hotz, I.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Scale Space Based Persistence Measure for Critical Points in 2D Scalar Fields},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2045-2052},
abstract={This paper introduces a novel importance measure for critical points in 2D scalar fields. This measure is based on a combination of the deep structure of the scale space with the well-known concept of homological persistence. We enhance the noise robust persistence measure by implicitly taking the hill-, ridge- and outlier-like spatial extent of maxima and minima into account. This allows for the distinction between different types of extrema based on their persistence at multiple scales. Our importance measure can be computed efficiently in an out-of-core setting. To demonstrate the practical relevance of our method we apply it to a synthetic and a real-world data set and evaluate its performance and scalability.},
keywords={data analysis;natural sciences computing;solid modelling;2D scalar fields;critical points;extrema;homological persistence;noise robust persistence measure;out-of-core setting;scale space based persistence measure;Feature extraction;Laplace equations;Noise measurement;Noise robustness;Scalability;Scale space;discrete Morse theory.;persistence},
doi={10.1109/TVCG.2011.159},
ISSN={1077-2626},}
@ARTICLE{6064969,
author={Livingston, M.A. and Decker, J.W.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Evaluation of Trend Localization with Multi-Variate Visualizations},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2053-2062},
abstract={Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn't require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.},
keywords={data visualisation;image colour analysis;Oriented Slivers technique;brush strokes technique;color blending technique;data-driven spots technique;dimensional stacking;juxtaposed grayscale map;multiple data value comparison;multivalued data sets;multivariate visualization technique;trend localization evaluation;Data visualization;Gray-scale;Image color analysis;Shape analysis;User study;multi-variate visualization;visual analytics.;visual task design},
doi={10.1109/TVCG.2011.194},
ISSN={1077-2626},}
@ARTICLE{6064970,
author={Angelelli, P. and Hauser, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Straightening Tubular Flow for Side-by-Side Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2063-2070},
abstract={Flows through tubular structures are common in many fields, including blood flow in medicine and tubular fluid flows in engineering. The analysis of such flows is often done with a strong reference to the main flow direction along the tubular boundary. In this paper we present an approach for straightening the visualization of tubular flow. By aligning the main reference direction of the flow, i.e., the center line of the bounding tubular structure, with one axis of the screen, we are able to natively juxtapose (1.) different visualizations of the same flow, either utilizing different flow visualization techniques, or by varying parameters of a chosen approach such as the choice of seeding locations for integration-based flow visualization, (2.) the different time steps of a time-dependent flow, (3.) different projections around the center line , and (4.) quantitative flow visualizations in immediate spatial relation to the more qualitative classical flow visualization. We describe how to utilize this approach for an informative interactive visual analysis. We demonstrate the potential of our approach by visualizing two datasets from two different fields: an arterial blood flow measurement and a tubular gas flow simulation from the automotive industry.},
keywords={computational fluid dynamics;data visualisation;flow visualisation;pipe flow;arterial blood flow measurement;automotive industry;engineering;informative interactive visual analysis;integration-based flow visualization;medicine;quantitative flow visualization;side-by-side visualization;spatial relation;time-dependent flow;tubular boundary;tubular flow visualization;tubular fluid flows;tubular gas flow simulation;Data models;Data visualization;Flow visualization;Three dimensional displays;Vectors;Comparative Visualization.;Data Reformation;Flow Visualization;Aorta;Blood Flow Velocity;Computer Graphics;Computer Simulation;Databases, Factual;Hemorheology;Humans;Imaging, Three-Dimensional;Magnetic Resonance Angiography;Models, Cardiovascular;Rheology},
doi={10.1109/TVCG.2011.235},
ISSN={1077-2626},}
@ARTICLE{6064971,
author={Koehler, C and Wischgoll, T. and Haibo Dong and Gaston, Z.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Vortex Visualization in Ultra Low Reynolds Number Insect Flight},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2071-2079},
abstract={We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to qua- wing insects.},
keywords={biology computing;computational fluid dynamics;computer animation;data visualisation;flow visualisation;vortices;wakes;zoology;CFD simulation;automatic camera animation method;deformable flapping wing;down-stroke;dragonfly;flapping flight theory;geometric flow lines;insect flight;integration-based flow lines;interactive seed placement method;leading edge vortex;occlusion issues;parametric surfaces;perceptual challenges;photogrammetry setup;seed curve generation;ultra low Reynolds number;unsteady 3D flow domain;unsteady flight mechanism;up-stroke;visual analysis;visualization method;vortex detection;vortex visualization;wake;wing reconstruction;Data visualization;Feature extraction;Flow visualization;Insects;Three dimensional displays;Trajectory;Flow visualization;flowing seed points;insect flight;streak lines;streamlines;unsteady flow.;vortex visualization;Animals;Computer Graphics;Computer Simulation;Flight, Animal;Hydrodynamics;Imaging, Three-Dimensional;Insects;Models, Biological},
doi={10.1109/TVCG.2011.260},
ISSN={1077-2626},}
@ARTICLE{6064972,
author={Kasten, J. and Reininghaus, J. and Hotz, I. and Hege, H.-C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Two-Dimensional Time-Dependent Vortex Regions Based on the Acceleration Magnitude},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2080-2087},
abstract={Acceleration is a fundamental quantity of flow fields that captures Galilean invariant properties of particle motion. Considering the magnitude of this field, minima represent characteristic structures of the flow that can be classified as saddle- or vortex-like. We made the interesting observation that vortex-like minima are enclosed by particularly pronounced ridges. This makes it possible to define boundaries of vortex regions in a parameter-free way. Utilizing scalar field topology, a robust algorithm can be designed to extract such boundaries. They can be arbitrarily shaped. An efficient tracking algorithm allows us to display the temporal evolution of vortices. Various vortex models are used to evaluate the method. We apply our method to two-dimensional model systems from computational fluid dynamics and compare the results to those arising from existing definitions.},
keywords={computational fluid dynamics;vortices;Galilean invariant property;acceleration magnitude;computational fluid dynamics;flow field;particle motion;scalar field topology;two-dimensional model system;two-dimensional time-dependent vortex region;vortex model;vortex-like minima;vortices temporal evolution;Feature extraction;Flow visualization;Navier-Stokes equations;Shape analysis;Topology;Vortex regions;feature extraction.;time-dependent flow fields},
doi={10.1109/TVCG.2011.249},
ISSN={1077-2626},}
@ARTICLE{6064973,
author={Williams, S. and Petersen, M. and Bremer, P.-T. and Hecht, M. and Pascucci, V. and Ahrens, J. and Hlawitschka, M. and Hamann, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Adaptive Extraction and Quantification of Geophysical Vortices},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2088-2095},
abstract={We consider the problem of extracting discrete two-dimensional vortices from a turbulent flow. In our approach we use a reference model describing the expected physics and geometry of an idealized vortex. The model allows us to derive a novel correlation between the size of the vortex and its strength, measured as the square of its strain minus the square of its vorticity. For vortex detection in real models we use the strength parameter to locate potential vortex cores, then measure the similarity of our ideal analytical vortex and the real vortex core for different strength thresholds. This approach provides a metric for how well a vortex core is modeled by an ideal vortex. Moreover, this provides insight into the problem of choosing the thresholds that identify a vortex. By selecting a target coefficient of determination (i.e., statistical confidence), we determine on a per-vortex basis what threshold of the strength parameter would be required to extract that vortex at the chosen confidence. We validate our approach on real data from a global ocean simulation and derive from it a map of expected vortex strengths over the global ocean.},
keywords={digital simulation;geometry;geophysics computing;oceanography;turbulence;vortices;discrete two dimensional vortex extraction;geometry;geophysical vortices quantification;global ocean simulation;physics;reference model;turbulent flow;vortex strengths;Atmospheric modeling;Data mining;Data models;Data visualization;Feature extraction;Information analysis;Vortex extraction;feature extraction;statistical data analysis.},
doi={10.1109/TVCG.2011.162},
ISSN={1077-2626},}
@ARTICLE{6064974,
author={Lipsa, D.R. and Laramee, R.S. and Cox, S.J. and Davies, I.T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={FoamVis: Visualization of 2D Foam Simulation Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2096-2105},
abstract={Research in the field of complex fluids such as polymer solutions, particulate suspensions and foams studies how the flow of fluids with different material parameters changes as a result of various constraints. Surface Evolver, the standard solver software used to generate foam simulations, provides large, complex, time-dependent data sets with hundreds or thousands of individual bubbles and thousands of time steps. However this software has limited visualization capabilities, and no foam specific visualization software exists. We describe the foam research application area where, we believe, visualization has an important role to play. We present a novel application that provides various techniques for visualization, exploration and analysis of time-dependent 2D foam simulation data. We show new features in foam simulation data and new insights into foam behavior discovered using our application.},
keywords={computational fluid dynamics;data visualisation;flow simulation;flow visualisation;foams;polymer solutions;set theory;suspensions;2D foam simulation data visualization capability;complex fluid flow;foam behavior;foam specific visualization software;large complex time dependent data set;material parameter;particulate suspension;polymer solution;standard solver software;surface evolver;time dependent 2D foam simulation data;Analytical models;Computational modeling;Data models;Data visualization;Image color analysis;Visualization;Surface Evolver;bubble-scale simulation;time-dependent visualizations.},
doi={10.1109/TVCG.2011.204},
ISSN={1077-2626},}
@ARTICLE{6064975,
author={Hanqi Guo and Ningyu Mao and Xiaoru Yuan},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={WYSIWYG (What You See is What You Get) Volume Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2106-2114},
abstract={In this paper, we propose a volume visualization system that accepts direct manipulation through a sketch-based What You See Is What You Get (WYSIWYG) approach. Similar to the operations in painting applications for 2D images, in our system, a full set of tools have been developed to enable direct volume rendering manipulation of color, transparency, contrast, brightness, and other optical properties by brushing a few strokes on top of the rendered volume image. To be able to smartly identify the targeted features of the volume, our system matches the sparse sketching input with the clustered features both in image space and volume space. To achieve interactivity, both special algorithms to accelerate the input identification and feature matching have been developed and implemented in our system. Without resorting to tuning transfer function parameters, our proposed system accepts sparse stroke inputs and provides users with intuitive, flexible and effective interaction during volume data exploration and visualization.},
keywords={brightness;colour;data visualisation;feature extraction;rendering (computer graphics);transfer functions;2D images;WYSIWYG volume visualization system;direct volume rendering manipulation;feature clustering;feature identification;feature matching;optical properties;painting applications;sketch-based What You See Is What You Get approach;sparse sketching;transfer function parameter tuning;volume data exploration;volume data visualization;Data visualization;Image color analysis;Real time systems;Rendering (computer graphics);Semantics;Transfer functions;Feature space.;Human-computer interaction;Sketching input;Transfer functions;Volume rendering;Algorithms;Animals;Computer Graphics;Humans;Imaging, Three-Dimensional;Software;User-Computer Interface},
doi={10.1109/TVCG.2011.261},
ISSN={1077-2626},}
@ARTICLE{6064976,
author={Muigg, P. and Hadwiger, M. and Doleisch, H. and Groller, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Volume Visualization of General Polyhedral Grids},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2115-2124},
abstract={This paper presents a novel framework for visualizing volumetric data specified on complex polyhedral grids, without the need to perform any kind of a priori tetrahedralization. These grids are composed of polyhedra that often are non-convex and have an arbitrary number of faces, where the faces can be non-planar with an arbitrary number of vertices. The importance of such grids in state-of-the-art simulation packages is increasing rapidly. We propose a very compact, face-based data structure for representing such meshes for visualization, called two-sided face sequence lists (TSFSL), as well as an algorithm for direct GPU-based ray-casting using this representation. The TSFSL data structure is able to represent the entire mesh topology in a 1D TSFSL data array of face records, which facilitates the use of efficient 1D texture accesses for visualization. In order to scale to large data sizes, we employ a mesh decomposition into bricks that can be handled independently, where each brick is then composed of its own TSFSL array. This bricking enables memory savings and performance improvements for large meshes. We illustrate the feasibility of our approach with real-world application results, by visualizing highly complex polyhedral data from commercial state-of-the-art simulation packages.},
keywords={data structures;data visualisation;interactive systems;simulation;GPU-based ray casting;TSFSL;a priori tetrahedralization;face-based data structure;general polyhedral grids;interactive volume visualization;simulation packages;two-sided face sequence lists;volumetric data visualization;Data visualization;Geometry;Graphics processing unit;Rendering (computer graphics);GPU-based visualization.;Volume rendering;polyhedral grids;unstructured grids},
doi={10.1109/TVCG.2011.216},
ISSN={1077-2626},}
@ARTICLE{6064977,
author={Sunden, E. and Ynnerman, A. and Ropinski, T.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Image Plane Sweep Volume Illumination},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2125-2134},
abstract={In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.},
keywords={computer graphic equipment;coprocessors;image processing;ray tracing;rendering (computer graphics);GPU;IPSVI;image comprehension;image plane sweep volume illumination;image quality;lighting effects;ray casting process;volume rendering technique;volumetric illumination models;Equations;Light sources;Mathematical model;Rendering (computer graphics);Synchronization;Advanced illumination.;GPU-based ray-casting;Interactive volume rendering;Algorithms;Animals;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;Lighting;Models, Anatomic;Spheniscidae;Tomography, X-Ray Computed;User-Computer Interface},
doi={10.1109/TVCG.2011.211},
ISSN={1077-2626},}
@ARTICLE{6064978,
author={Suter, S.K. and Iglesias Guitian, J.A. and Marton, F. and Agus, M. and Elsener, A. and Zollikofer, C.P.E. and Gopi, M. and Gobbetti, E. and Pajarola, Renato},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2135-2143},
abstract={Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.},
keywords={computer graphic equipment;coprocessors;data visualisation;interactive systems;natural sciences computing;rendering (computer graphics);CUDA;GPU accelerated out-of-core multiresolution rendering framework;GPU accelerated tensor reconstruction;computational simulations;constrained memory footprint;data transfer bandwidth;gigabyte sized microtomographic volumes;hierarchical brick tensor decomposition approach;high resolution 3D imaging devices;interactive multiscale tensor reconstruction;interactive visual analysis;multiresolution volume visualization;out-of-core memory footprint;tensor approximation;Approximation methods;Graphics processing unit;Instruction sets;Quantization;Rendering (computer graphics);Tensile stress;GPU/CUDA;interactive volume visualization;multiresolution rendering.;multiscale;tensor reconstruction;Algorithms;Animals;Computer Graphics;Computer Simulation;Databases, Factual;Hominidae;Imaging, Three-Dimensional;Lizards;Models, Anatomic;Molar;X-Ray Microtomography},
doi={10.1109/TVCG.2011.214},
ISSN={1077-2626},}
@ARTICLE{6064979,
author={Weifeng Chen and Wei Chen and Hujun Bao},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={An Efficient Direct Volume Rendering Approach for Dichromats},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2144-2152},
abstract={Color vision deficiency (CVD) affects a high percentage of the population worldwide. When seeing a volume visualization result, persons with CVD may be incapable of discriminating the classification information expressed in the image if the color transfer function or the color blending used in the direct volume rendering is not appropriate. Conventional methods used to address this problem adopt advanced image recoloring techniques to enhance the rendering results frame-by-frame; unfortunately, problematic perceptual results may still be generated. This paper proposes an alternative solution that complements the image recoloring scheme by reconfiguring the components of the direct volume rendering (DVR) pipeline. Our approach optimizes the mapped colors of a transfer function to simulate CVD-friendly effect that is generated by applying the image recoloring to the results with the initial transfer function. The optimization process has a low computational complexity, and only needs to be performed once for a given transfer function. To achieve detail-preserving and perceptually natural semi-transparent effects, we introduce a new color composition mode that works in the color space of dichromats. Experimental results and a pilot study demonstrates that our approach can yield dichromats-friendly and consistent volume visualization in real-time.},
keywords={colour vision;data visualisation;image classification;image colour analysis;image enhancement;rendering (computer graphics);transfer functions;vision defects;CVD friendly effect;classification information;color blending;color composition mode;color transfer function;color vision deficiency;computational complexity;dichromats;direct volume rendering;image enhancement;image recoloring techniques;Data visualization;Image color analysis;Linear systems;Rendering (computer graphics);Transfer functions;Volume measurement;Dichromacy;direct volume rendering;image recoloring.;volume classification;Algorithms;Color;Color Vision Defects;Computer Graphics;Databases, Factual;Humans;Imaging, Three-Dimensional;Phantoms, Imaging;User-Computer Interface},
doi={10.1109/TVCG.2011.164},
ISSN={1077-2626},}
@ARTICLE{6064980,
author={van Pelt, R. and Olivan Bescos, J. and Breeuwer, M. and Clough, R.E. and Groller, M.E. and ter Haar Romeny, B. and Vilanova, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Interactive Virtual Probing of 4D MRI Blood-Flow},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2153-2162},
abstract={Better understanding of hemodynamics conceivably leads to improved diagnosis and prognosis of cardiovascular diseases. Therefore, an elaborate analysis of the blood-flow in heart and thoracic arteries is essential. Contemporary MRI techniques enable acquisition of quantitative time-resolved flow information, resulting in 4D velocity fields that capture the blood-flow behavior. Visual exploration of these fields provides comprehensive insight into the unsteady blood-flow behavior, and precedes a quantitative analysis of additional blood-flow parameters. The complete inspection requires accurate segmentation of anatomical structures, encompassing a time-consuming and hard-to-automate process, especially for malformed morphologies. We present a way to avoid the laborious segmentation process in case of qualitative inspection, by introducing an interactive virtual probe. This probe is positioned semi-automatically within the blood-flow field, and serves as a navigational object for visual exploration. The difficult task of determining position and orientation along the view-direction is automated by a fitting approach, aligning the probe with the orientations of the velocity field. The aligned probe provides an interactive seeding basis for various flow visualization approaches. We demonstrate illustration-inspired particles, integral lines and integral surfaces, conveying distinct characteristics of the unsteady blood-flow. Lastly, we present the results of an evaluation with domain experts, valuing the practical use of our probe and flow visualization techniques.},
keywords={biomedical MRI;blood;blood vessels;data visualisation;flow instability;flow visualisation;haemodynamics;virtual reality;4D MRI blood-flow behaviour;4D velocity field;anatomical structure;anatomical structure segmentation;blood-flow parameter;cardiovascular disease;flow visualization approach;hard-to-automate process;hemodynamics;interactive virtual probing;laborious segmentation process;malformed morphology;object navigation;thoracic artery;time-resolved flow information;visual exploration;Blood flow;Data visualization;Magnetic resonance imaging;Three dimensional displays;Flow visualization;Illustrative visualization;Multivalued images;Phase-contrast cine MRI.;Probing;Blood Flow Velocity;Cardiovascular Diseases;Computer Graphics;Computer Simulation;Hemodynamics;Humans;Imaging, Three-Dimensional;Magnetic Resonance Angiography;User-Computer Interface},
doi={10.1109/TVCG.2011.215},
ISSN={1077-2626},}
@ARTICLE{6064981,
author={Khlebnikov, R. and Kainz, B. and Muehl, J. and Schmalstieg, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Crepuscular Rays for Tumor Accessibility Planning},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2163-2172},
abstract={In modern clinical practice, planning access paths to volumetric target structures remains one of the most important and most complex tasks, and a physician's insufficient experience in this can lead to severe complications or even the death of the patient. In this paper, we present a method for safety evaluation and the visualization of access paths to assist physicians during preoperative planning. As a metaphor for our method, we employ a well-known, and thus intuitively perceivable, natural phenomenon that is usually called crepuscular rays. Using this metaphor, we propose several ways to compute the safety of paths from the region of interest to all tumor voxels and show how this information can be visualized in real-time using a multi-volume rendering system. Furthermore, we show how to estimate the extent of connected safe areas to improve common medical 2D multi-planar reconstruction (MPR) views. We evaluate our method by means of expert interviews, an online survey, and a retrospective evaluation of 19 real abdominal radio-frequency ablation (RFA) interventions, with expert decisions serving as a gold standard. The evaluation results show clear evidence that our method can be successfully applied in clinical practice without introducing substantial overhead work for the acting personnel. Finally, we show that our method is not limited to medical applications and that it can also be useful in other fields.},
keywords={data visualisation;image reconstruction;medical computing;patient care;ray tracing;rendering (computer graphics);safety;tumours;abdominal radiofrequency ablation intervention;access path visualization;clinical practice;crepuscular ray;medical 2D multiplanar reconstruction view;multivolume rendering system;patient death;physician insufficient experience;preoperative planning;safety evaluation;tumor accessibility planning;tumor voxel;volumetric target structure;Biomedical image processing;Rendering (computer graphics);Three dimensional displays;Tumors;Accessibility;medical visualization.;ray casting;Algorithms;Animals;Catheter Ablation;Computer Graphics;Computer Simulation;Computer Systems;Humans;Imaging, Three-Dimensional;Light;Neoplasms;Retrospective Studies;Scattering, Radiation;Surgery, Computer-Assisted;Swine},
doi={10.1109/TVCG.2011.184},
ISSN={1077-2626},}
@ARTICLE{6064982,
author={Dick, C. and Burgkart, R. and Westermann, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Distance Visualization for Interactive 3D Implant Planning},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2173-2182},
abstract={An instant and quantitative assessment of spatial distances between two objects plays an important role in interactive applications such as virtual model assembly, medical operation planning, or computational steering. While some research has been done on the development of distance-based measures between two objects, only very few attempts have been reported to visualize such measures in interactive scenarios. In this paper we present two different approaches for this purpose, and we investigate the effectiveness of these approaches for intuitive 3D implant positioning in a medical operation planning system. The first approach uses cylindrical glyphs to depict distances, which smoothly adapt their shape and color to changing distances when the objects are moved. This approach computes distances directly on the polygonal object representations by means of ray/triangle mesh intersection. The second approach introduces a set of slices as additional geometric structures, and uses color coding on surfaces to indicate distances. This approach obtains distances from a precomputed distance field of each object. The major findings of the performed user study indicate that a visualization that can facilitate an instant and quantitative analysis of distances between two objects in interactive 3D scenarios is demanding, yet can be achieved by including additional monocular cues into the visualization.},
keywords={data visualisation;interactive systems;medical computing;color coding;cylindrical glyphs;distance visualization;distance-based measures;interactive 3D implant planning;medical operation planning system;polygonal object representations;ray-triangle mesh intersection;Biomedical image processing;Distance measurement;Image color analysis;Implants;Rendering (computer graphics);Distance visualization;biomedical visualization;distance fields.;glyphs;implant planning;Computer Graphics;Computer Simulation;Hip Prosthesis;Humans;Imaging, Three-Dimensional;Prostheses and Implants;Prosthesis Implantation;Surgery, Computer-Assisted;User-Computer Interface},
doi={10.1109/TVCG.2011.189},
ISSN={1077-2626},}
@ARTICLE{6064983,
author={Gasteiger, R. and Neugebauer, M. and Beuing, O. and Preim, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2183-2192},
abstract={Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.},
keywords={data visualisation;haemodynamics;medical computing;rendering (computer graphics);4D PC-MRI measurement;CFD;FLOWLENS;WSS;anatomic scope;blood flow exploration;cerebral aneurysms;flexible visual filtering;focus-and-context visualization;hemodynamic attribute;inflow jet;occlusion;visual cluttering;visual exploration;wall shear stress;Aneurysm;Data visualization;Flow visualization;Hemodynamics;Rendering (computer graphics);Shape analysis;Aneurysm.;Flow Visualization;Focus-and-Context;Illustrative Rendering;Cerebrovascular Circulation;Computer Graphics;Computer Simulation;Hemodynamics;Humans;Imaging, Three-Dimensional;Intracranial Aneurysm;Models, Cardiovascular;Models, Neurological;Regional Blood Flow;Software},
doi={10.1109/TVCG.2011.243},
ISSN={1077-2626},}
@ARTICLE{6064984,
author={Amirkhanov, A. and Heinzl, C. and Reiter, M. and Kastner, J. and Groller, E.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Projection-Based Metal-Artifact Reduction for Industrial 3D X-ray Computed Tomography},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2193-2202},
abstract={Multi-material components, which contain metal parts surrounded by plastic materials, are highly interesting for inspection using industrial 3D X-ray computed tomography (3DXCT). Examples of this application scenario are connectors or housings with metal inlays in the electronic or automotive industry. A major problem of this type of components is the presence of metal, which causes streaking artifacts and distorts the surrounding media in the reconstructed volume. Streaking artifacts and dark-band artifacts around metal components significantly influence the material characterization (especially for the plastic components). In specific cases these artifacts even prevent a further analysis. Due to the nature and the different characteristics of artifacts, the development of an efficient artifact-reduction technique in reconstruction-space is rather complicated. In this paper we present a projection-space pipeline for metal-artifacts reduction. The proposed technique first segments the metal in the spatial domain of the reconstructed volume in order to separate it from the other materials. Then metal parts are forward-projected on the set of projections in a way that metal-projection regions are treated as voids. Subsequently the voids, which are left by the removed metal, are interpolated in the 2D projections. Finally, the metal is inserted back into the reconstructed 3D volume during the fusion stage. We present a visual analysis tool, allowing for interactive parameter estimation of the metal segmentation. The results of the proposed artifact-reduction technique are demonstrated on a test part as well as on real world components. For these specimens we achieve a significant reduction of metal artifacts, allowing an enhanced material characterization.},
keywords={computerised tomography;data visualisation;interpolation;3D volume;3DXCT;artifact-reduction technique;dark-band artifact;industrial 3D X-ray computed tomography;interactive parameter estimation;metal segmentation;multimaterial components;plastic material;projection-based metal-artifact reduction;projection-space pipeline;streaking artifact;visual analysis tool;Computed tomography;Image reconstruction;Information analysis;Interpolation;Three dimensional displays;3D X-ray computed tomography.;Metal-artifact reduction;multi-material components;visual analysis},
doi={10.1109/TVCG.2011.228},
ISSN={1077-2626},}
@ARTICLE{6064985,
author={Bertini, E. and Tatu, A. and Keim, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Quality Metrics in High-Dimensional Data Visualization: An Overview and Systematization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2203-2212},
abstract={In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration of meaningful patterns in high-dimensional data. In a number of recent papers, different quality metrics are proposed to automate the demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the user to concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach has witnessed a remarkable development but few reflections exist on how these methods are related to each other and how the approach can be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional data visualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a set of factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through a reworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it to several existing approaches that use quality metrics, and we provide reflections on implications of our model for future research.},
keywords={data visualisation;alternative visualizations;high-dimensional data visualization;information visualization pipeline;quality metrics;Data visualization;Measurements;High-Dimensional Data Visualization.;Quality Metrics},
doi={10.1109/TVCG.2011.229},
ISSN={1077-2626},}
@ARTICLE{6064986,
author={Hullman, J. and Adar, E. and Shah, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Benefitting InfoVis with Visual Difficulties},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2213-2222},
abstract={Many well-cited theories for visualization design state that a visual representation should be optimized for quick and immediate interpretation by a user. Distracting elements like decorative "chartjunk" or extraneous information are avoided so as not to slow comprehension. Yet several recent studies in visualization research provide evidence that non-efficient visual elements may benefit comprehension and recall on the part of users. Similarly, findings from studies related to learning from visual displays in various subfields of psychology suggest that introducing cognitive difficulties to visualization interaction can improve a user's understanding of important information. In this paper, we synthesize empirical results from cross-disciplinary research on visual information representations, providing a counterpoint to efficiency-based design theory with guidelines that describe how visual difficulties can be introduced to benefit comprehension and recall. We identify conditions under which the application of visual difficulties is appropriate based on underlying factors in visualization interaction like active processing and engagement. We characterize effective graph design as a trade-off between efficiency and learning difficulties in order to provide Information Visualization (InfoVis) researchers and practitioners with a framework for organizing explorations of graphs for which comprehension and recall are crucial. We identify implications of this view for the design and evaluation of information visualizations.},
keywords={cognition;data visualisation;psychology;InfoVis practitioners;InfoVis researchers;cognitive difficulty;cross-disciplinary research;decorative chartjunk;distracting elements;efficiency-based design theory;extraneous information;graph design;information visualization practitioners;information visualization researchers;information visualizations;nonefficient visual elements;psychology;user understanding;visual difficulty;visual displays;visual information representations;visual representation;visualization design;visualization interaction;well-cited theory;Cognition;Data visualization;Psychology;Time factors;Desirable difficulites;active processing;cognitive efficiency;engagement;individual differences.;Cognition;Comprehension;Computer Graphics;Humans;Learning;Models, Psychological;User-Computer Interface;Visual Perception},
doi={10.1109/TVCG.2011.175},
ISSN={1077-2626},}
@ARTICLE{6064987,
author={Wickham, H. and Hofmann, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Product Plots},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2223-2230},
abstract={We propose a new framework for visualising tables of counts, proportions and probabilities. We call our framework product plots, alluding to the computation of area as a product of height and width, and the statistical concept of generating a joint distribution from the product of conditional and marginal distributions. The framework, with extensions, is sufficient to encompass over 20 visualisations previously described in fields of statistical graphics and infovis, including bar charts, mosaic plots, treemaps, equal area plots and fluctuation diagrams.},
keywords={bar charts;data visualisation;statistical distributions;bar charts;equal area plots;fluctuation diagrams;infovis;joint distribution;marginal distributions;mosaic plots;product plots;statistical graphics;table visualisation;treemaps;Data visualization;Image color analysis;Probability;Statistical analysis;Statistics;bar chart;conditional distribution;joint distribution;mosaic plot.;treemap},
doi={10.1109/TVCG.2011.227},
ISSN={1077-2626},}
@ARTICLE{6064988,
author={Hullman, J. and Diakopoulos, N.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization Rhetoric: Framing Effects in Narrative Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2231-2240},
abstract={Narrative visualizations combine conventions of communicative and exploratory information visualization to convey an intended story. We demonstrate visualization rhetoric as an analytical framework for understanding how design techniques that prioritize particular interpretations in visualizations that "tell a story" can significantly affect end-user interpretation. We draw a parallel between narrative visualization interpretation and evidence from framing studies in political messaging, decision-making, and literary studies. Devices for understanding the rhetorical nature of narrative information visualizations are presented, informed by the rigorous application of concepts from critical theory, semiotics, journalism, and political theory. We draw attention to how design tactics represent additions or omissions of information at various levels-the data, visual representation, textual annotations, and interactivity-and how visualizations denote and connote phenomena with reference to unstated viewing conventions and codes. Classes of rhetorical techniques identified via a systematic analysis of recent narrative visualizations are presented, and characterized according to their rhetorical contribution to the visualization. We describe how designers and researchers can benefit from the potentially positive aspects of visualization rhetoric in designing engaging, layered narrative visualizations and how our framework can shed light on how a visualization design prioritizes specific interpretations. We identify areas where future inquiry into visualization rhetoric can improve understanding of visualization interpretation.},
keywords={data visualisation;decision making;communicative information visualization;critical theory;decision making;design tactics;end-user interpretation;exploratory information visualization;framing effects;journalism;literary study;narrative information visualization;political messaging;political theory;semiotics;textual annotation;visual representation;visualization rhetoric;Data visualization;Rhetoric;Semiotics;Rhetoric;connotation.;denotation;framing effects;narrative visualization;semiotics},
doi={10.1109/TVCG.2011.255},
ISSN={1077-2626},}
@ARTICLE{6064989,
author={Dasgupta, A. and Kosara, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Adaptive Privacy-Preserving Visualization Using Parallel Coordinates},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2241-2248},
abstract={Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.},
keywords={data mining;data privacy;data visualisation;adaptive privacy-preserving visualization;data mining;information visualization techniques;parallel coordinates;privacy protection;privacy-preserving data publishing;screen-space privacy metrics;Clustering algorithms;Data privacy;Data visualization;Privacy;Parallel coordinates;clustering.;privacy},
doi={10.1109/TVCG.2011.163},
ISSN={1077-2626},}
@ARTICLE{6064990,
author={Steinberger, M. and Waldner, M. and Streit, M. and Lex, A. and Schmalstieg, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Context-Preserving Visual Links},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2249-2258},
abstract={Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.},
keywords={data analysis;data visualisation;complex visualizations;context preserving visual links;image based analysis;information intensive work;information occlusion;synchronized visual highlighting;visual data analysis;visual interference;visual saliency;Data visualization;Histograms;Image color analysis;Visual links;connectedness;highlighting;image-based;routing;saliency.},
doi={10.1109/TVCG.2011.183},
ISSN={1077-2626},}
@ARTICLE{6064991,
author={Alper, B. and Riche, N.H. and Ramos, G. and Czerwinski, Mary},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Design Study of LineSets, a Novel Set Visualization Technique},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2259-2267},
abstract={Computing and visualizing sets of elements and their relationships is one of the most common tasks one performs when analyzing and organizing large amounts of data. Common representations of sets such as convex or concave geometries can become cluttered and difficult to parse when these sets overlap in multiple or complex ways, e.g., when multiple elements belong to multiple sets. In this paper, we present a design study of a novel set visual representation, LineSets, consisting of a curve connecting all of the set's elements. Our approach to design the visualization differs from traditional methodology used by the InfoVis community. We first explored the potential of the visualization concept by running a controlled experiment comparing our design sketches to results from the state-of-the-art technique. Our results demonstrated that LineSets are advantageous for certain tasks when compared to concave shapes. We discuss an implementation of LineSets based on simple heuristics and present a study demonstrating that our generated curves do as well as human-drawn ones. Finally, we present two applications of our technique in the context of search tasks on a map and community analysis tasks in social networks.},
keywords={cartography;data visualisation;geometry;set theory;community analysis task;concave geometry;convex geometry;heuristics;information visualization;linesets;map;search tasks;set visual representation;set visualization;social network;Accuracy;Data visualization;Geometry;Shape analysis;Social network services;Set visualization;clustering;faceted data visualization;graph visualization.},
doi={10.1109/TVCG.2011.186},
ISSN={1077-2626},}
@ARTICLE{6064992,
author={Juhee Bae and Watson, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Developing and Evaluating Quilts for the Depiction of Large Layered Graphs},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2268-2275},
abstract={Traditional layered graph depictions such as flow charts are in wide use. Yet as graphs grow more complex, these depictions can become difficult to understand. Quilts are matrix-based depictions for layered graphs designed to address this problem. In this research, we first improve Quilts by developing three design alternatives, and then compare the best of these alternatives to better-known node-link and matrix depictions. A primary weakness in Quilts is their depiction of skip links, links that do not simply connect to a succeeding layer. Therefore in our first study, we compare Quilts using color-only, text-only, and mixed (color and text) skip link depictions, finding that path finding with the color-only depiction is significantly slower and less accurate, and that in certain cases, the mixed depiction offers an advantage over the text-only depiction. In our second study, we compare Quilts using the mixed depiction to node-link diagrams and centered matrices. Overall results show that users can find paths through graphs significantly faster with Quilts (46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams. This speed advantage is still greater in large graphs (e.g. in 200 node graphs, 55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).},
keywords={flowcharting;graphs;matrix algebra;color-only depiction;flow charts;layered graph depiction;matrix depiction;matrix diagrams;node-link diagrams;quilts;skip link depiction;text-only depiction;Analysis of variance;Atmospheric measurements;Graphics;Particle measurements;Time measurement;Graph drawing;layered graphs;matrix based depiction;node-link diagram.},
doi={10.1109/TVCG.2011.187},
ISSN={1077-2626},}
@ARTICLE{6064993,
author={Talbot, J. and Gerth, J. and Hanrahan, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Arc Length-Based Aspect Ratio Selection},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2276-2282},
abstract={The aspect ratio of a plot has a dramatic impact on our ability to perceive trends and patterns in the data. Previous approaches for automatically selecting the aspect ratio have been based on adjusting the orientations or angles of the line segments in the plot. In contrast, we recommend a simple, effective method for selecting the aspect ratio: minimize the arc length of the data curve while keeping the area of the plot constant. The approach is parameterization invariant, robust to a wide range of inputs, preserves visual symmetries in the data, and is a compromise between previously proposed techniques. Further, we demonstrate that it can be effectively used to select the aspect ratio of contour plots. We believe arc length should become the default aspect ratio selection method.},
keywords={computational geometry;data analysis;data visualisation;arc length based aspect ratio selection;data curve;line segments;parameterization invariant approach;visual data symmetries;Length measurement;Ratio selection;Time series analysis;Aspect ratio selection;Banking to 45 degrees;Orientation resolution.},
doi={10.1109/TVCG.2011.167},
ISSN={1077-2626},}
@ARTICLE{6064994,
author={Brandes, U. and Nick, B.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Asymmetric Relations in Longitudinal Social Networks},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2283-2290},
abstract={In modeling and analysis of longitudinal social networks, visual exploration is used in particular to complement and inform other methods. The most common graphical representations for this purpose appear to be animations and small multiples of intermediate states, depending on the type of media available. We present an alternative approach based on matrix representation of gestaltlines (a combination of Tufte's sparklines with glyphs based on gestalt theory). As a result, we obtain static, compact, yet data-rich diagrams that support specifically the exploration of evolving dyadic relations and persistent group structure, although at the expense of cross-sectional network views and indirect linkages.},
keywords={data mining;matrix algebra;social networking (online);Tufte's sparklines;asymmetric relation;cross-sectional network;data rich diagram;dyadic relation;gestalt theory;gestaltlines;glyphs;graphical representation;indirect linkages;intermediate state;longitudinal social network;matrix representation;persistent group structure;visual exploration;Data visualization;Image color analysis;Social network services;Glyphbased Techniques.;Network Visualization;Social Networks;Time Series Data;Visual Knowledge Discovery and Representation},
doi={10.1109/TVCG.2011.169},
ISSN={1077-2626},}
@ARTICLE{6064995,
author={Lex, A. and Schulz, H. and Streit, M. and Partl, C. and Schmalstieg, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={VisBricks: Multiform Visualization of Large, Inhomogeneous Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2291-2300},
abstract={Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.},
keywords={data visualisation;medical computing;VisBricks visualization concept;biomedicine field;data visualization;inhomogeneous data;statistical method;Data visualization;Nonhomogeneous media;Semantics;Inhomogeneous data;multiform visualization.;multiple coordinated views;Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Humans;User-Computer Interface},
doi={10.1109/TVCG.2011.250},
ISSN={1077-2626},}
@ARTICLE{6064996,
author={Bostock, M. and Ogievetsky, V. and Heer, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={D #x0B3; Data-Driven Documents},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2301-2309},
abstract={Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
keywords={Web sites;computer animation;data visualisation;document handling;user interfaces;Web visualization;animation;data-driven documents;document elements;dynamic transforms;native representation;representation-transparent approach;representational transparency;scene graph;standard document object model;toolkit-specific abstraction;Cascading style sheets;Data visualization;Debugging;Image color analysis;Information analysis;2D graphics.;Information visualization;toolkits;user interfaces},
doi={10.1109/TVCG.2011.185},
ISSN={1077-2626},}
@ARTICLE{6064997,
author={Claessen, J.H.T. and van Wijk, J.J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Flexible Linked Axes for Multivariate Data Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2310-2316},
abstract={Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.},
keywords={data visualisation;PCP;custom visualizations;flexible linked axes;hyperboxes;multivariate data visualization;parallel coordinate displays;parallel coordinates plot-style;radar charts;scatter plot matrices;timewheels;Data visualization;Histograms;Image color analysis;Scattering parameters;Multivariate data;Parallel Coordinates Plot.;scatter plot;visualization},
doi={10.1109/TVCG.2011.201},
ISSN={1077-2626},}
@ARTICLE{6064998,
author={Albuquerque, G. and Lowe, T. and Magnor, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Synthetic Generation of High-Dimensional Datasets},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2317-2324},
abstract={Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.},
keywords={data handling;graphical user interfaces;pattern classification;pattern clustering;statistical distributions;classified datasets;complex nonorthogonal trends;graphical user interface;multidimensional clusters;multidimensional correlations;multidimensional outliers;orthogonal projection planes;statistical distributions;synthetic high dimensional datasets generation;user defined parameters;Correlation;Data processing;Probability density function;Scattering parameters;Synthetic data generation;high-dimensional data;interaction.;multivariate data},
doi={10.1109/TVCG.2011.237},
ISSN={1077-2626},}
@ARTICLE{6064999,
author={Alper, B. and Hollerer, T. and Kuchera-Morin, J. and Forbes, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Stereoscopic Highlighting: 2D Graph Visualization on Stereo Displays},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2325-2333},
abstract={In this paper we present a new technique and prototype graph visualization system, stereoscopic highlighting, to help answer accessibility and adjacency queries when interacting with a node-link diagram. Our technique utilizes stereoscopic depth to highlight regions of interest in a 2D graph by projecting these parts onto a plane closer to the viewpoint of the user. This technique aims to isolate and magnify specific portions of the graph that need to be explored in detail without resorting to other highlighting techniques like color or motion, which can then be reserved to encode other data attributes. This mechanism of stereoscopic highlighting also enables focus+context views by juxtaposing a detailed image of a region of interest with the overall graph, which is visualized at a further depth with correspondingly less detail. In order to validate our technique, we ran a controlled experiment with 16 subjects comparing static visual highlighting to stereoscopic highlighting on 2D and 3D graph layouts for a range of tasks. Our results show that while for most tasks the difference in performance between stereoscopic highlighting alone and static visual highlighting is not statistically significant, users performed better when both highlighting methods were used concurrently. In more complicated tasks, 3D layout with static visual highlighting outperformed 2D layouts with a single highlighting method. However, it did not outperform the 2D layout utilizing both highlighting techniques simultaneously. Based on these results, we conclude that stereoscopic highlighting is a promising technique that can significantly enhance graph visualizations for certain use cases.},
keywords={data visualisation;graph theory;three-dimensional displays;2D graph visualization;2D layout;3D layout;data attributes;focus+context views;static visual highlighting;stereo displays;stereoscopic highlighting;Data visualization;Graphics;Image color analysis;Stereo image processing;Two dimensional displays;Graph visualization;stereo displays;virtual reality.},
doi={10.1109/TVCG.2011.234},
ISSN={1077-2626},}
@ARTICLE{6065000,
author={Hadlak, S. and Schulz, H. and Schumann, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={In Situ Exploration of Large Dynamic Networks},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2334-2343},
abstract={The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.},
keywords={data visualisation;graph theory;network theory (graphs);bot nets;dynamic graph visualization;in situ exploration;large dynamic networks;mental map;model versioning;network structure;social networks;visual analysis;visual representations;visualization techniques;wireless mesh networks;Data visualization;Graphics;Dynamic graph data;multi-focus+context.;multiform visualization},
doi={10.1109/TVCG.2011.213},
ISSN={1077-2626},}
@ARTICLE{6065001,
author={Burch, M. and Vehlow, C. and Beck, F. and Diehl, S. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Parallel Edge Splatting for Scalable Dynamic Graph Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2344-2353},
abstract={We present a novel dynamic graph visualization technique based on node-link diagrams. The graphs are drawn side-byside from left to right as a sequence of narrow stripes that are placed perpendicular to the horizontal time line. The hierarchically organized vertices of the graphs are arranged on vertical, parallel lines that bound the stripes; directed edges connect these vertices from left to right. To address massive overplotting of edges in huge graphs, we employ a splatting approach that transforms the edges to a pixel-based scalar field. This field represents the edge densities in a scalable way and is depicted by non-linear color mapping. The visualization method is complemented by interaction techniques that support data exploration by aggregation, filtering, brushing, and selective data zooming. Furthermore, we formalize graph patterns so that they can be interactively highlighted on demand. A case study on software releases explores the evolution of call graphs extracted from the JUnit open source software project. In a second application, we demonstrate the scalability of our approach by applying it to a bibliography dataset containing more than 1.5 million paper titles from 60 years of research history producing a vast amount of relations between title words.},
keywords={data visualisation;graph theory;JUnit open source software project;bibliography dataset;call graph;data exploration;interaction technique;node-link diagram;nonlinear color mapping;parallel edge splatting;scalable dynamic graph visualization;selective data zooming;Data visualization;Encoding;Graphics;Image color analysis;Image edge detection;Software engineering;Dynamic graph visualization;graph splatting;software evolution.;software visualization},
doi={10.1109/TVCG.2011.226},
ISSN={1077-2626},}
@ARTICLE{6065002,
author={Selassie, D. and Heller, B. and Heer, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Divided Edge Bundling for Directional Network Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2354-2363},
abstract={The node-link diagram is an intuitive and venerable way to depict a graph. To reduce clutter and improve the readability of node-link views, Holten & van Wijk's force-directed edge bundling employs a physical simulation to spatially group graph edges. While both useful and aesthetic, this technique has shortcomings: it bundles spatially proximal edges regardless of direction, weight, or graph connectivity. As a result, high-level directional edge patterns are obscured. We present divided edge bundling to tackle these shortcomings. By modifying the forces in the physical simulation, directional lanes appear as an emergent property of edge direction. By considering graph topology, we only bundle edges related by graph structure. Finally, we aggregate edge weights in bundles to enable more accurate visualization of total bundle weights. We compare visualizations created using our technique to standard force-directed edge bundling, matrix diagrams, and clustered graphs; we find that divided edge bundling leads to visualizations that are easier to interpret and reveal both familiar and previously obscured patterns.},
keywords={data visualisation;directed graphs;matrix algebra;pattern clustering;clustered graphs;directed edge bundling;directional edge patterns;directional network data;graph connectivity;graph theory;graph topology;matrix diagrams;node link diagram;visualization;Data visualization;Encoding;Graphics;Image edge detection;Graph visualization;aggregation;edge bundling;node-link diagrams;physical simulation.},
doi={10.1109/TVCG.2011.190},
ISSN={1077-2626},}
@ARTICLE{6065003,
author={Ersoy, O. and Hurter, C. and Paulovich, F.V. and Cantareiro, G. and Telea, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Skeleton-Based Edge Bundling for Graph Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2364-2373},
abstract={In this paper, we present a novel approach for constructing bundled layouts of general graphs. As layout cues for bundles, we use medial axes, or skeletons, of edges which are similar in terms of position information. We combine edge clustering, distance fields, and 2D skeletonization to construct progressively bundled layouts for general graphs by iteratively attracting edges towards the centerlines of level sets of their distance fields. Apart from clustering, our entire pipeline is image-based with an efficient implementation in graphics hardware. Besides speed and implementation simplicity, our method allows explicit control of the emphasis on structure of the bundled layout, i.e. the creation of strongly branching (organic-like) or smooth bundles. We demonstrate our method on several large real-world graphs.},
keywords={data visualisation;graph theory;pattern clustering;2D skeletonization;distance fields;edge clustering;graph visualization;graphics hardware;medial axes;skeleton-based edge bundling;Image edge detection;Image processing;Shape analysis;Smoothing methods;Transforms;Graph layouts;edge bundles;image-based information visualization.},
doi={10.1109/TVCG.2011.233},
ISSN={1077-2626},}
@ARTICLE{6065004,
author={Ferreira, N. and Lins, L. and Fink, D. and Kelling, S. and Wood, C. and Freire, J. and Silva, C.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={BirdVis: Visualizing and Understanding Bird Populations},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2374-2383},
abstract={Birds are unrivaled windows into biotic processes at all levels and are proven indicators of ecological well-being. Understanding the determinants of species distributions and their dynamics is an important aspect of ecology and is critical for conservation and management. Through crowdsourcing, since 2002, the eBird project has been collecting bird observation records. These observations, together with local-scale environmental covariates such as climate, habitat, and vegetation phenology have been a valuable resource for a global community of educators, land managers, ornithologists, and conservation biologists. By associating environmental inputs with observed patterns of bird occurrence, predictive models have been developed that provide a statistical framework to harness available data for predicting species distributions and making inferences about species-habitat associations. Understanding these models, however, is challenging because they require scientists to quantify and compare multiscale spatialtemporal patterns. A large series of coordinated or sequential plots must be generated, individually programmed, and manually composed for analysis. This hampers the exploration and is a barrier to making the cross-species comparisons that are essential for coordinating conservation and extracting important ecological information. To address these limitations, as part of a collaboration among computer scientists, statisticians, biologists and ornithologists, we have developed BirdVis, an interactive visualization system that supports the analysis of spatio-temporal bird distribution models. BirdVis leverages visualization techniques and uses them in a novel way to better assist users in the exploration of interdependencies among model parameters. Furthermore, the system allows for comparative visualization through coordinated views, providing an intuitive interface to identify relevant correlations and patterns. We justify our design decisions and present case s- udies that show how BirdVis has helped scientists obtain new evidence for existing hypotheses, as well as formulate new hypotheses in their domain.},
keywords={data visualisation;ecology;environmental science computing;statistical analysis;zoology;BirdVis;biotic processes;bird observation records;bird population understanding;bird population visualization;climate;conservation biologists;crowdsourcing;eBird project;ecological well being;ecology;habitat;interactive visualization system;land managers;local scale environmental covariates;multiscale spatial temporal patterns;ornithologists;spatio temporal bird distribution models;species-habitat associations;statistical framework;vegetation phenology;Biological system modeling;Data visualization;Ornithology;Predictive models;Spatial databases;Tag clouds;Ornithology;multiscale analysis;spatial data;species distribution models;temporal data.;Animals;Artificial Intelligence;Birds;Computer Graphics;Computer Simulation;Databases, Factual;Ecosystem;Flight, Animal;Models, Biological;Population Dynamics;Software;Songbirds;Species Specificity;User-Computer Interface},
doi={10.1109/TVCG.2011.176},
ISSN={1077-2626},}
@ARTICLE{6065005,
author={Wood, J. and Badawood, D. and Dykes, J. and Slingsby, A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={BallotMaps: Detecting Name Bias in Alphabetically Ordered Ballot Papers},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2384-2391},
abstract={The relationship between candidates' position on a ballot paper and vote rank is explored in the case of 5000 candidates for the UK 2010 local government elections in the Greater London area. This design study uses hierarchical spatially arranged graphics to represent two locations that affect candidates at very different scales: the geographical areas for which they seek election and the spatial location of their names on the ballot paper. This approach allows the effect of position bias to be assessed; that is, the degree to which the position of a candidate's name on the ballot paper influences the number of votes received by the candidate, and whether this varies geographically. Results show that position bias was significant enough to influence rank order of candidates, and in the case of many marginal electoral wards, to influence who was elected to government. Position bias was observed most strongly for Liberal Democrat candidates but present for all major political parties. Visual analysis of classification of candidate names by ethnicity suggests that this too had an effect on votes received by candidates, in some cases overcoming alphabetic name bias. The results found contradict some earlier research suggesting that alphabetic name bias was not sufficiently significant to affect electoral outcome and add new evidence for the geographic and ethnicity influences on voting behaviour. The visual approach proposed here can be applied to a wider range of electoral data and the patterns identified and hypotheses derived from them could have significant implications for the design of ballot papers and the conduct of fair elections.},
keywords={local government;Liberal Democrat candidates;alphabetic name bias detection;ballot papers;ballotmaps;electoral data;electoral outcome;ethnicity;fair election;local government election;marginal electoral wards;political party;position bias;visual analysis;vote rank;voting behaviour;Data visualization;Geospatial analysis;Image color analysis;Local government;Nominations and elections;Voting;bias;democracy;election;geovisualization;governance;governance.;hierarchy;treemaps},
doi={10.1109/TVCG.2011.174},
ISSN={1077-2626},}
@ARTICLE{6065006,
author={Albers, D. and Dewey, C. and Gleicher, M.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Sequence Surveyor: Leveraging Overview for Scalable Genomic Alignment Visualization},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2392-2401},
abstract={In this paper, we introduce overview visualization tools for large-scale multiple genome alignment data. Genome alignment visualization and, more generally, sequence alignment visualization are an important tool for understanding genomic sequence data. As sequencing techniques improve and more data become available, greater demand is being placed on visualization tools to scale to the size of these new datasets. When viewing such large data, we necessarily cannot convey details, rather we specifically design overview tools to help elucidate large-scale patterns. Perceptual science, signal processing theory, and generality provide a framework for the design of such visualizations that can scale well beyond current approaches. We present Sequence Surveyor, a prototype that embodies these ideas for scalable multiple whole-genome alignment overview visualization. Sequence Surveyor visualizes sequences in parallel, displaying data using variable color, position, and aggregation encodings. We demonstrate how perceptual science can inform the design of visualization techniques that remain visually manageable at scale and how signal processing concepts can inform aggregation schemes that highlight global trends, outliers, and overall data distributions as the problem scales. These techniques allow us to visualize alignments with over 100 whole bacterial-sized genomes.},
keywords={biology computing;data visualisation;genomics;signal processing;aggregation schemes;bacterial-sized genomes;generality;genomic sequence data;perceptual science;scalable genomic alignment visualization;sequence alignment visualization;sequence surveyor;signal processing theory;Bioinformatics;Data visualization;Design methodology;Genomics;Image color analysis;Bioinformatics Visualization;Perception Theory;Scalability Issues;Visual Design.;Computer Graphics;Computer Simulation;Databases, Genetic;Evolution, Molecular;Genome, Bacterial;Genomics;Humans;Sequence Alignment;Software;User-Computer Interface;Visual Perception},
doi={10.1109/TVCG.2011.232},
ISSN={1077-2626},}
@ARTICLE{6065007,
author={Pretorius, A.J. and Bray, M.-A.P. and Carpenter, A.E. and Ruddle, R.A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visualization of Parameter Space for Image Analysis},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2402-2411},
abstract={Image analysis algorithms are often highly parameterized and much human input is needed to optimize parameter settings. This incurs a time cost of up to several days. We analyze and characterize the conventional parameter optimization process for image analysis and formulate user requirements. With this as input, we propose a change in paradigm by optimizing parameters based on parameter sampling and interactive visual exploration. To save time and reduce memory load, users are only involved in the first step - initialization of sampling - and the last step - visual analysis of output. This helps users to more thoroughly explore the parameter space and produce higher quality results. We describe a custom sampling plug-in we developed for CellProfiler - a popular biomedical image analysis framework. Our main focus is the development of an interactive visualization technique that enables users to analyze the relationships between sampled input parameters and corresponding output. We implemented this in a prototype called Paramorama. It provides users with a visual overview of parameters and their sampled values. User-defined areas of interest are presented in a structured way that includes image-based output and a novel layout algorithm. To find optimal parameter settings, users can tag high- and low-quality results to refine their search. We include two case studies to illustrate the utility of this approach.},
keywords={data visualisation;image sampling;medical image processing;CellProfiler;Paramorama;biomedical image analysis framework;custom sampling plug-in;interactive visual exploration;interactive visualization;parameter optimization process;parameter sampling;parameter space visualization;visual analysis;Algorithm design and analysis;Image analysis;Information processing;Sampling methods;Information visualization;image analysis;parameter space;sampling.;visual analytics;Algorithms;Androstadienes;Cell Line;Cell Nucleus;Chromones;Computer Graphics;Computer Simulation;Humans;Image Processing, Computer-Assisted;Morpholines;Software;User-Computer Interface},
doi={10.1109/TVCG.2011.253},
ISSN={1077-2626},}
@ARTICLE{6065008,
author={Weiwei Cui and Shixia Liu and Li Tan and Conglei Shi and Yangqiu Song and Zekai Gao and Huamin Qu and Xin Tong},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={TextFlow: Towards Better Understanding of Evolving Topics in Text},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2412-2421},
abstract={Understanding how topics evolve in text data is an important and challenging task. Although much work has been devoted to topic analysis, the study of topic evolution has largely been limited to individual topics. In this paper, we introduce TextFlow, a seamless integration of visualization and topic mining techniques, for analyzing various evolution patterns that emerge from multiple topics. We first extend an existing analysis technique to extract three-level features: the topic evolution trend, the critical event, and the keyword correlation. Then a coherent visualization that consists of three new visual components is designed to convey complex relationships between them. Through interaction, the topic mining model and visualization can communicate with each other to help users refine the analysis result and gain insights into the data progressively. Finally, two case studies are conducted to demonstrate the effectiveness and usefulness of TextFlow in helping users understand the major topic evolution patterns in time-varying text data.},
keywords={data mining;data visualisation;feature extraction;text analysis;TextFlow;coherent visualization;convey complex relationships;critical event;keyword correlation;three-level feature extraction;topic evolution trend;topic mining model;topic mining technique;topics evolution;visualization technique;Data visualization;Image color analysis;Tag clouds;Text analysis;Critical event.;Hierarchical Dirichlet process;Text visualization;Topic evolution},
doi={10.1109/TVCG.2011.239},
ISSN={1077-2626},}
@ARTICLE{6065009,
author={Jian Zhao and Chevalier, F. and Pietriga, E. and Balakrishnan, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Exploratory Analysis of Time-Series with ChronoLenses},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2422-2431},
abstract={Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.},
keywords={data analysis;data visualisation;time series;ChronoLenses;exploratory time-series analysis;on-the-fly data point transformation;visual analysis;visual representation;visualization technique;Data visualization;Lenses;Rendering (computer graphics);Time series analysis;Transforms;Exploratory Visualization;Focus+Context;Interaction Techniques.;Lens;Time-series Data},
doi={10.1109/TVCG.2011.195},
ISSN={1077-2626},}
@ARTICLE{6065010,
author={Krstajic, M. and Bertini, E. and Keim, D.A.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={CloudLines: Compact Display of Event Episodes in Multiple Time-Series},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2432-2439},
abstract={We propose incremental logarithmic time-series technique as a way to deal with time-based representations of large and dynamic event data sets in limited space. Modern data visualization problems in the domains of news analysis, network security and financial applications, require visual analysis of incremental data, which poses specific challenges that are normally not solved by static visualizations. The incremental nature of the data implies that visualizations have to necessarily change their content and still provide comprehensible representations. In particular, in this paper we deal with the need to keep an eye on recent events together with providing a context on the past and to make relevant patterns accessible at any scale. Our technique adapts to the incoming data by taking care of the rate at which data items occur and by using a decay function to let the items fade away according to their relevance. Since access to details is also important, we also provide a novel distortion magnifying lens technique which takes into account the distortions introduced by the logarithmic time scale to augment readability in selected areas of interest. We demonstrate the validity of our techniques by applying them on incremental data coming from online news streams in different time frames.},
keywords={Internet;computer displays;data analysis;data structures;data visualisation;financial management;information resources;security of data;time series;CloudLines;data analysis;data visualization;decay function;event episode compact display;financial service;incremental data sets;interactive distortion;logarithmic time scale;magnifying lens technique;multiple time series visualization technique;network security;online news streams;readability enhancement;temporal context;time-based representation;Data visualization;Estimation;Event detection;Lenses;Time series analysis;Incremental visualization;event based data;lens distortion.},
doi={10.1109/TVCG.2011.179},
ISSN={1077-2626},}
@ARTICLE{6065011,
author={Burch, M. and Konevtsova, N. and Heinrich, J. and Hoeferlin, M. and Weiskopf, D.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Evaluation of Traditional, Orthogonal, and Radial Tree Diagrams by an Eye Tracking Study},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2440-2448},
abstract={Node-link diagrams are an effective and popular visualization approach for depicting hierarchical structures and for showing parent-child relationships. In this paper, we present the results of an eye tracking experiment investigating traditional, orthogonal, and radial node-link tree layouts as a piece of empirical basis for choosing between those layouts. Eye tracking was used to identify visual exploration behaviors of participants that were asked to solve a typical hierarchy exploration task by inspecting a static tree diagram: finding the least common ancestor of a given set of marked leaf nodes. To uncover exploration strategies, we examined fixation points, duration, and saccades of participants' gaze trajectories. For the non-radial diagrams, we additionally investigated the effect of diagram orientation by switching the position of the root node to each of the four main orientations. We also recorded and analyzed correctness of answers as well as completion times in addition to the eye movement data. We found out that traditional and orthogonal tree layouts significantly outperform radial tree layouts for the given task. Furthermore, by applying trajectory analysis techniques we uncovered that participants cross-checked their task solution more often in the radial than in the non-radial layouts.},
keywords={data visualisation;diagrams;trees (mathematics);diagram orientation;eye movement data;eye tracking experiment;eye tracking study;gaze trajectory;hierarchy exploration task;node-link diagrams;nonradial diagrams;nonradial layout;orthogonal diagrams;orthogonal tree layout;parent-child relationship;radial node-link tree layouts;radial tree diagrams;static tree diagram;trajectory analysis;visual exploration behavior;Analysis of variance;Data visualization;Hierarchical systems;Tracking;Trajectory;Upper bound;Hierarchy visualization;eye tracking;node-link layout;user study.;Adult;Algorithms;Computer Graphics;Eye Movement Measurements;Female;Humans;Male;Middle Aged;User-Computer Interface;Visual Perception;Young Adult},
doi={10.1109/TVCG.2011.193},
ISSN={1077-2626},}
@ARTICLE{6065012,
author={Liang Gou and Xiaolong Zhang},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={TreeNetViz: Revealing Patterns of Networks over Tree Structures},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2449-2458},
abstract={Network data often contain important attributes from various dimensions such as social affiliations and areas of expertise in a social network. If such attributes exhibit a tree structure, visualizing a compound graph consisting of tree and network structures becomes complicated. How to visually reveal patterns of a network over a tree has not been fully studied. In this paper, we propose a compound graph model, TreeNet, to support visualization and analysis of a network at multiple levels of aggregation over a tree. We also present a visualization design, TreeNetViz, to offer the multiscale and cross-scale exploration and interaction of a TreeNet graph. TreeNetViz uses a Radial, Space-Filling (RSF) visualization to represent the tree structure, a circle layout with novel optimization to show aggregated networks derived from TreeNet, and an edge bundling technique to reduce visual complexity. Our circular layout algorithm reduces both total edge-crossings and edge length and also considers hierarchical structure constraints and edge weight in a TreeNet graph. These experiments illustrate that the algorithm can reduce visual cluttering in TreeNet graphs. Our case study also shows that TreeNetViz has the potential to support the analysis of a compound graph by revealing multiscale and cross-scale network patterns.},
keywords={computational complexity;data visualisation;graph theory;optimisation;tree data structures;TreeNet graph;TreeNetViz;circle layout;compound graph model;expertise areas;network data;networks patterns;optimization;radial space filling visualization;social affiliations;social network;tree structures;visual cluttering;visual complexity;Algorithm design and analysis;Complexity theory;Data visualization;Graphics;Tree data structures;Compound graph;TreeNetViz;multiscale and cross-scale.;network and tree;visualization},
doi={10.1109/TVCG.2011.247},
ISSN={1077-2626},}
@ARTICLE{6065013,
author={Paiva, J.G. and Florian, L. and Pedrini, H. and Telles, G.P. and Minghim, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Improved Similarity Trees and their Application to Visual Data Classification},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2459-2468},
abstract={An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.},
keywords={data analysis;data mining;image classification;iterative methods;trees (mathematics);image classification;iterative manipulation;multidimensional projection;neighbor joining trees;similarity tree deployment;similarity trees;similarity-based hierarchical data organization;visual classification;visual data analysis;visual data classification;visual data mining;Algorithm design and analysis;Biomedical image processing;Data visualization;Image classification;Phylogeny;Image Classification.;Multidimensional Projections;Similarity Trees},
doi={10.1109/TVCG.2011.212},
ISSN={1077-2626},}
@ARTICLE{6065014,
author={Isenberg, P. and Bezerianos, A. and Dragicevic, P. and Fekete, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={A Study on Dual-Scale Data Charts},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2469-2478},
abstract={We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.},
keywords={charts;data handling;data resolution;design guidelines;dual scale cartesian coordinate data charts;elementary graphical perception task;superimposed charts;Data visualization;Image color analysis;Quantization;Shape analysis;Terminology;Dual-Scale Charts.;Focus+Context;Quantitative Experiment},
doi={10.1109/TVCG.2011.160},
ISSN={1077-2626},}
@ARTICLE{6065015,
author={Borkin, M. and Gajos, K. and Peters, A. and Mitsouras, D. and Melchionna, S. and Rybicki, F. and Feldman, C. and Pfister, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Evaluation of Artery Visualizations for Heart Disease Diagnosis},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2479-2488},
abstract={Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.},
keywords={biomechanics;cardiology;computerised tomography;data visualisation;diseases;haemodynamics;medical image processing;patient diagnosis;patient treatment;tree data structures;2D tree diagram representation;ESS;cardiologist;color maps;coronary artery disease;endothelial shear stress;formal quantitative user;heart disease diagnosis;hemodynamics;interactive visualization;patient treatment;task taxonomy;visualization technique;Arteries;Blood flow;Data visualization;Heart;Image color analysis;Three dimensional displays;Quantitative evaluation;biomedical and medical visualization.;qualitative evaluation;Computer Graphics;Computer Simulation;Coronary Vessels;Diagnosis, Computer-Assisted;Heart Diseases;Hemodynamics;Humans;Imaging, Three-Dimensional;Models, Cardiovascular;User-Computer Interface},
doi={10.1109/TVCG.2011.192},
ISSN={1077-2626},}
@ARTICLE{6065016,
author={Rodgers, J. and Bartram, L.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Exploring Ambient and Artistic Visualization for Residential Energy Use Feedback},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2489-2497},
abstract={Providing effective feedback on resource consumption in the home is a key challenge of environmental conservation efforts. One promising approach for providing feedback about residential energy consumption is the use of ambient and artistic visualizations. Pervasive computing technologies enable the integration of such feedback into the home in the form of distributed point-of-consumption feedback devices to support decision-making in everyday activities. However, introducing these devices into the home requires sensitivity to the domestic context. In this paper we describe three abstract visualizations and suggest four design requirements that this type of device must meet to be effective: pragmatic, aesthetic, ambient, and ecological. We report on the findings from a mixed methods user study that explores the viability of using ambient and artistic feedback in the home based on these requirements. Our findings suggest that this approach is a viable way to provide resource use feedback and that both the aesthetics of the representation and the context of use are important elements that must be considered in this design space.},
keywords={art;building management systems;data visualisation;decision making;energy conservation;feedback;power consumption;power engineering computing;ubiquitous computing;abstract visualizations;ambient visualization;artistic visualization;decision making support;distributed point-of-consumption feedback device;environmental conservation efforts;informative art;pervasive computing technology;residential energy consumption;residential energy use feedback visualization;resource consumption;Art;Data visualization;Feedback;Real time systems;Resource management;Ambient visualization;casual infovis;distributed visualization.;informative art;sustainability},
doi={10.1109/TVCG.2011.196},
ISSN={1077-2626},}
@ARTICLE{6065017,
author={Lloyd, D. and Dykes, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2498-2507},
abstract={Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.},
keywords={data visualisation;geographic information systems;groupware;knowledge acquisition;prototypes;user centred design;HC approach;ISO13407 taxonomy;autoethnography;collaborative engagement;contextual inquiry;data prototype;data sketch;data visualization;data wireframe;digital prototype;exploratory behaviour;geovis application design;geovisualization design;human-centered approach;long-term case study;multiple method investigation;structured task protocol;transient visual artefact;Data visualization;Domain specific languages;Human factors;Taxonomy;Evaluation;context of use;design.;field study;geovisualization;prototypes;requirements;sketching;Computer Graphics;Geography;Humans;User-Computer Interface},
doi={10.1109/TVCG.2011.209},
ISSN={1077-2626},}
@ARTICLE{6065018,
author={Walny, J. and Carpendale, S. and Riche, N.H. and Venolia, G. and Fawcett, P.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Visual Thinking In Action: Visualizations As Used On Whiteboards},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2508-2517},
abstract={While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.},
keywords={data visualisation;psychology;affinity diagramming;data-driven perspective;information visualization;open coding;task-driven perspective;visual thinking;whiteboards;Data visualization;Encoding;Image color analysis;Visualization;diagrams;observational study.;whiteboards},
doi={10.1109/TVCG.2011.251},
ISSN={1077-2626},}
@ARTICLE{6065019,
author={Scheepens, R. and Willems, N. and Van de Wetering, H. and Andrienko, G. and Andrienko, N. and van Wijk, J.J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Composite Density Maps for Multivariate Trajectories},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2518-2527},
abstract={We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.},
keywords={cartography;data visualisation;time series;block diagram;composite density maps;maritime use cases;multiple density fields;multivariate time series;multivariate trajectories;visual analysis;Computational modeling;Computer architecture;Data visualization;Image color analysis;Trajectory;Geographical Information Systems;Kernel Density Estimation;Multivariate Data;Trajectories;and Raster Maps.},
doi={10.1109/TVCG.2011.181},
ISSN={1077-2626},}
@ARTICLE{6065020,
author={Yu-Shuen Wang and Ming-Te Chi},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Focus+Context Metro Maps},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2528-2535},
abstract={We introduce a focus+context method to visualize a complicated metro map of a modern city on a small displaying area. The context of our work is with regard the popularity of mobile devices. The best route to the destination, which can be obtained from the arrival time of trains, is highlighted. The stations on the route enjoy larger spaces, whereas the other stations are rendered smaller and closer to fit the whole map into a screen. To simplify the navigation and route planning for visitors, we formulate various map characteristics such as octilinear transportation lines and regular station distances into energy terms. We then solve for the optimal layout in a least squares sense. In addition, we label the names of stations that are on the route of a passenger according to human preferences, occlusions, and consistencies of label positions using the graph cuts method. Our system achieves real-time performance by being able to report instant information because of the carefully designed energy terms. We apply our method to layout a number of metro maps and show the results and timing statistics to demonstrate the feasibility of our technique.},
keywords={cartography;graph theory;mobile handsets;railways;energy terms;focus+context metro maps;graph cuts method;metro map visualization;mobile devices;modern city;octilinear transportation lines;regular station distances;train arrival time;Graphics;Layout;Nonlinear distortion;Optimization;Focus+context visualization;graph labeling;metro map;octilinear layout;optimization.},
doi={10.1109/TVCG.2011.205},
ISSN={1077-2626},}
@ARTICLE{6065021,
author={Buchin, K. and Speckmann, B. and Verbeek, K.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Flow Map Layout via Spiral Trees},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2536-2544},
abstract={Flow maps are thematic maps that visualize the movement of objects, such as people or goods, between geographic regions. One or more sources are connected to several targets by lines whose thickness corresponds to the amount of flow between a source and a target. Good flow maps reduce visual clutter by merging (bundling) lines smoothly and by avoiding self-intersections. Most flow maps are still drawn by hand and only few automated methods exist. Some of the known algorithms do not support edge-bundling and those that do, cannot guarantee crossing-free flows. We present a new algorithmic method that uses edge-bundling and computes crossing-free flows of high visual quality. Our method is based on so-called spiral trees, a novel type of Steiner tree which uses logarithmic spirals. Spiral trees naturally induce a clustering on the targets and smoothly bundle lines. Our flows can also avoid obstacles, such as map features, region outlines, or even the targets. We demonstrate our approach with extensive experiments.},
keywords={cartography;data visualisation;pattern clustering;trees (mathematics);Steiner tree;flow map layout;good flow maps;logarithmic spirals;object movement;spiral trees;target clustering;thematic maps;Approximation algorithms;Cartography;Cost function;Steiner trees;Tree data structures;Automated Cartography;Flow maps;Spiral Trees.},
doi={10.1109/TVCG.2011.202},
ISSN={1077-2626},}
@ARTICLE{6065022,
author={Slingsby, A. and Dykes, J. and Wood, J.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Exploring Uncertainty in Geodemographics with Interactive Graphics},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2545-2554},
abstract={Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.},
keywords={cartography;data visualisation;demography;interactive systems;local government;pattern classification;OAC classifier;UK population classification;dimension-reducing quality;geodemographic classifier;geographical area categorisation;interactive graphics;local government;open geodemographic classifier;Classification;Data visualization;Demographics;Image color analysis;Visualization;Geodemographics;OAC;cartography;classification;uncertainty.},
doi={10.1109/TVCG.2011.197},
ISSN={1077-2626},}
@ARTICLE{6065023,
author={Haunert, J.-H. and Sering, L.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Drawing Road Networks with Focus Regions},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2555-2562},
abstract={Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.},
keywords={cartography;convex programming;graph theory;mobile computing;polynomials;quadratic programming;real-time systems;traffic information systems;cartographer;convex quadratic program;edge crossings;fish-eye projection;graph drawing;linear inequalities;map distortion;mapping function;mobile maps user;polynomial time solution;prototype tool;real-time system;road networks;user defined focus region;Cartography;Distortion measurement;Graphics;Image analysis;Optimization;Quadratic programming;Visualization;Cartography;fish-eye view;graph drawing;optimization;quadratic programming.;schematic maps},
doi={10.1109/TVCG.2011.191},
ISSN={1077-2626},}
@ARTICLE{6065024,
author={Joia, P. and Paulovich, F.V. and Coimbra, D. and Cuminato, J.A. and Nonato, L.G.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Local Affine Multidimensional Projection},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2563-2571},
abstract={Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP's versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents.},
keywords={affine transforms;data mining;data visualisation;interactive systems;LAMP technique;computational efficiency;local affine multidimensional projection technique;local transformation;orthogonal mapping theory;visual data mining;visualization-oriented fully interactive application;Data mining;Minimization;Robustness;High Dimensional Data;Multidimensional Projection;Visual Data Mining.},
doi={10.1109/TVCG.2011.220},
ISSN={1077-2626},}
@ARTICLE{6065025,
author={Zhao Geng and ZhenMin Peng and Laramee, R.S. and Roberts, J.C. and Walker, R.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2572-2580},
abstract={Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.},
keywords={data visualisation;rendering (computer graphics);angular histogram;attribute curve;data set rendering;frequency-based approach;frequency-based visualization;high dimensional data;linear correlation;multivariate data visualization;overplotting problem;parallel coordinates;visual information seeking mantra;Data visualization;Histograms;Vectors;Angular Histogram;Attribute Curves.;Parallel Coordinates;Algorithms;Animal Migration;Animals;Cluster Analysis;Computer Graphics;Data Interpretation, Statistical;Multivariate Analysis;User-Computer Interface},
doi={10.1109/TVCG.2011.166},
ISSN={1077-2626},}
@ARTICLE{6065026,
author={Nan Cao and Gotz, D. and Jimeng Sun and Huamin Qu},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={DICON: Interactive Visual Analysis of Multidimensional Clusters},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2581-2590},
abstract={Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.},
keywords={data analysis;data structures;data visualisation;embedded systems;interactive systems;pattern clustering;statistical distributions;DICON;cluster quality;clutter reduction;complex data;fundamental data analysis technique;high-level statistical information;icon-based cluster visualization;interactive visual analysis;layout algorithm;multidimensional attribute display;multidimensional cluster;statistical information;user interaction;Algorithm design and analysis;Clustering algorithms;Encoding;Image color analysis;Information analysis;Visualization;Clustering;Information Visualization.;Visual Analysis;Algorithms;Cluster Analysis;Computer Graphics;Data Interpretation, Statistical;Databases, Factual;Humans;User-Computer Interface},
doi={10.1109/TVCG.2011.188},
ISSN={1077-2626},}
@ARTICLE{6065027,
author={Turkay, C. and Filzmoser, P. and Hauser, H.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={Brushing Dimensions - A Dual Visual Analysis Model for High-Dimensional Data},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2591-2599},
abstract={In many application fields, data analysts have to deal with datasets that contain many expressions per item. The effective analysis of such multivariate datasets is dependent on the user's ability to understand both the intrinsic dimensionality of the dataset as well as the distribution of the dependent values with respect to the dimensions. In this paper, we propose a visualization model that enables the joint interactive visual analysis of multivariate datasets with respect to their dimensions as well as with respect to the actual data values. We describe a dual setting of visualization and interaction in items space and in dimensions space. The visualization of items is linked to the visualization of dimensions with brushing and focus+context visualization. With this approach, the user is able to jointly study the structure of the dimensions space as well as the distribution of data items with respect to the dimensions. Even though the proposed visualization model is general, we demonstrate its application in the context of a DNA microarray data analysis.},
keywords={data analysis;data visualisation;lab-on-a-chip;set theory;DNA microarray data analysis;brushing dimensions;data item distribution;dual visual analysis model;high-dimensional data;item space;joint interactive visual analysis;multivariate datasets;Analytical models;Computational modeling;Data models;Data visualization;Principal component analysis;High-dimensional data analysis.;Interactive visual analysis;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Databases, Factual;Humans;Oligonucleotide Array Sequence Analysis;User-Computer Interface},
doi={10.1109/TVCG.2011.178},
ISSN={1077-2626},}
@ARTICLE{6065028,
author={Hurter, C. and Telea, A. and Ersoy, O.},
journal={Visualization and Computer Graphics, IEEE Transactions on},
title={MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots},
year={2011},
month={Dec},
volume={17},
number={12},
pages={2600-2609},
abstract={We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.},
keywords={data handling;data visualisation;graph theory;MoleView;air traffic control;brushing based technique;bundled edge graph layouts;distance based repulsion;graph layout;interactive multivariate relational data exploration;large element based plots;medical imaging;road traffic control;scatter plot;semantic lens;software comprehension;straight line node link graph drawings;Data visualization;Filtering theory;Lenses;Semantics;Shape analysis;Semantic lenses;attribute filtering.;graph bundling;magic lenses;Angiography;Computer Graphics;Computer Simulation;Databases, Factual;Humans;Multivariate Analysis;Semantics;User-Computer Interface},
doi={10.1109/TVCG.2011.223},
ISSN={1077-2626},}